/usr/bin/python2.7 /home/soloice/PycharmProjects/SVM_RC/src2/svm_test_full.py
<type 'numpy.ndarray'>
shape (full): (70000, 784) (70000,)
<type 'numpy.float64'>
(50000, 784) Counter({1.0: 5601, 7.0: 5247, 3.0: 5057, 9.0: 5026, 2.0: 4986, 6.0: 4931, 0.0: 4915, 4.0: 4859, 8.0: 4859, 5.0: 4519})
(20000, 784) Counter({1.0: 2276, 3.0: 2084, 7.0: 2046, 2.0: 2004, 0.0: 1988, 8.0: 1966, 4.0: 1965, 6.0: 1945, 9.0: 1932, 5.0: 1794})
(50000, 784) (50000,)
[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]
Begin training classifier for label 0.0 and label 1.0 at 2016-05-19, 22:00:37
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10516, 784) (10516,)
(10516, 784) (10516,)
     pcost       dcost       gap    pres   dres
 0: -2.9758e+02 -1.8378e+04  1e+05  2e+00  3e-12
 1: -1.8709e+02 -9.1085e+03  2e+04  3e-01  3e-12
 2: -1.0836e+02 -4.2529e+03  7e+03  1e-01  2e-12
 3: -5.0337e+01 -2.0486e+03  3e+03  5e-02  1e-12
 4: -2.2294e+01 -1.2897e+03  2e+03  3e-02  7e-13
 5: -8.9194e+00 -8.0615e+02  1e+03  1e-02  4e-13
 6: -3.4005e+00 -6.5916e+02  1e+03  8e-03  2e-13
 7: -2.9426e-01 -2.1806e+02  3e+02  2e-03  1e-13
 8:  7.3269e-01 -1.0258e+02  2e+02  9e-04  1e-13
 9:  1.0747e+00 -4.1717e+01  6e+01  3e-04  9e-14
10:  5.2535e-01 -1.2499e+01  1e+01  2e-05  9e-14
11: -1.9141e-01 -8.7254e+00  9e+00  1e-05  8e-14
12: -1.2945e-01 -7.8045e+00  8e+00  4e-06  8e-14
13: -3.9699e-01 -6.9311e+00  7e+00  3e-06  7e-14
14: -7.3591e-01 -5.6990e+00  5e+00  7e-07  8e-14
15: -1.3429e+00 -3.9748e+00  3e+00  3e-07  8e-14
16: -1.6275e+00 -3.3015e+00  2e+00  1e-07  8e-14
17: -1.7621e+00 -3.0327e+00  1e+00  4e-08  8e-14
18: -1.8305e+00 -2.8204e+00  1e+00  4e-09  1e-13
19: -1.9823e+00 -2.5778e+00  6e-01  2e-09  9e-14
20: -2.0491e+00 -2.4355e+00  4e-01  2e-15  1e-13
21: -2.1364e+00 -2.3225e+00  2e-01  7e-15  9e-14
22: -2.1888e+00 -2.2538e+00  6e-02  8e-15  1e-13
23: -2.2188e+00 -2.2213e+00  3e-03  2e-14  1e-13
24: -2.2200e+00 -2.2200e+00  3e-05  2e-14  1e-13
25: -2.2200e+00 -2.2200e+00  3e-07  1e-14  1e-13
Optimal solution found.
sv_indices: [104, 262, 395, 488, 1032, 1103, 1291, 1343, 1352, 1393, 1519, 1688, 1689, 1794, 1816, 1913, 2041, 2071, 2116, 2295, 2688, 2698, 2794, 2807, 2813, 2815, 3030, 3291, 3426, 3490, 3496, 3527, 3687, 3887, 3946, 4010, 4037, 4157, 4162, 4304, 4406, 4443, 4483, 4572, 4677, 4679, 5178, 5203, 5369, 5679, 5935, 6055, 6287, 6421, 6451, 6588, 6643, 7262, 7283, 7380, 7464, 7590, 8075, 8117, 8326, 8512, 8530, 8660, 8661, 8704, 8747, 9027, 9280, 9422, 9639, 9791, 9892, 10131]
78 SVs (with labels):
Training time for 0.0-vs-1.0: 771.919220924 seconds
Begin training classifier for label 0.0 and label 2.0 at 2016-05-19, 22:13:29
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9901, 784) (9901,)
(9901, 784) (9901,)
     pcost       dcost       gap    pres   dres
 0: -1.1145e+03 -2.3924e+04  2e+05  3e+00  2e-11
 1: -6.8322e+02 -1.4570e+04  3e+04  5e-01  2e-11
 2: -3.7933e+02 -4.8477e+03  8e+03  1e-01  1e-11
 3: -2.3607e+02 -2.3267e+03  4e+03  5e-02  8e-12
 4: -1.5446e+02 -1.2986e+03  2e+03  2e-02  5e-12
 5: -1.1182e+02 -1.0234e+03  2e+03  2e-02  4e-12
 6: -8.2043e+01 -6.8477e+02  1e+03  9e-03  3e-12
 7: -6.0100e+01 -4.3788e+02  6e+02  4e-03  3e-12
 8: -5.3343e+01 -1.9273e+02  2e+02  1e-03  3e-12
 9: -5.7085e+01 -1.0257e+02  5e+01  2e-13  3e-12
10: -6.1896e+01 -9.3126e+01  3e+01  2e-13  3e-12
11: -6.8983e+01 -7.9060e+01  1e+01  4e-14  3e-12
12: -7.1628e+01 -7.4692e+01  3e+00  1e-14  3e-12
13: -7.2599e+01 -7.3471e+01  9e-01  4e-14  3e-12
14: -7.2963e+01 -7.3030e+01  7e-02  3e-13  3e-12
15: -7.2995e+01 -7.2996e+01  1e-03  2e-13  3e-12
16: -7.2995e+01 -7.2995e+01  1e-05  6e-14  3e-12
Optimal solution found.
sv_indices: [46, 104, 149, 190, 250, 267, 320, 329, 370, 491, 539, 553, 613, 697, 784, 842, 869, 870, 874, 883, 1018, 1035, 1054, 1085, 1103, 1130, 1226, 1244, 1273, 1274, 1287, 1327, 1336, 1339, 1343, 1350, 1393, 1431, 1489, 1546, 1548, 1560, 1590, 1628, 1688, 1703, 1789, 1816, 1913, 1952, 1968, 2041, 2110, 2162, 2191, 2218, 2290, 2295, 2359, 2366, 2388, 2390, 2426, 2444, 2471, 2479, 2599, 2615, 2703, 2724, 2805, 2817, 2820, 2865, 2929, 2967, 2969, 2977, 3008, 3030, 3111, 3137, 3241, 3255, 3291, 3317, 3318, 3365, 3373, 3387, 3425, 3426, 3449, 3490, 3527, 3621, 3668, 3687, 3702, 3713, 3717, 3769, 3785, 3792, 3797, 3806, 3868, 3946, 3973, 3979, 3982, 4010, 4023, 4037, 4110, 4157, 4220, 4251, 4254, 4263, 4297, 4298, 4304, 4350, 4397, 4409, 4443, 4483, 4524, 4556, 4558, 4563, 4572, 4648, 4662, 4674, 4677, 4679, 4687, 4755, 4760, 4794, 4849, 4862, 4867, 4882, 4908, 4935, 4969, 5000, 5025, 5031, 5055, 5116, 5143, 5169, 5242, 5277, 5292, 5319, 5334, 5400, 5408, 5527, 5582, 5588, 5620, 5640, 5688, 5721, 5860, 5885, 5920, 5936, 5967, 6017, 6025, 6065, 6073, 6094, 6099, 6122, 6129, 6161, 6162, 6168, 6228, 6312, 6341, 6395, 6427, 6439, 6458, 6469, 6471, 6525, 6530, 6572, 6614, 6650, 6667, 6678, 6763, 6811, 6829, 6853, 6880, 6904, 6964, 7087, 7144, 7145, 7173, 7174, 7180, 7188, 7249, 7275, 7290, 7294, 7301, 7320, 7333, 7385, 7402, 7413, 7491, 7501, 7503, 7529, 7617, 7630, 7646, 7747, 7763, 7801, 7803, 7836, 7892, 7953, 7999, 8057, 8145, 8165, 8186, 8188, 8196, 8228, 8362, 8409, 8549, 8569, 8618, 8661, 8783, 8810, 8834, 8841, 8853, 8855, 8863, 8905, 8979, 8988, 9034, 9036, 9040, 9096, 9100, 9173, 9182, 9185, 9190, 9374, 9402, 9422, 9508, 9514, 9551, 9589, 9604, 9628, 9680, 9702, 9846, 9867]
286 SVs (with labels):
Training time for 0.0-vs-2.0: 439.990972996 seconds
Begin training classifier for label 0.0 and label 3.0 at 2016-05-19, 22:20:49
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9972, 784) (9972,)
(9972, 784) (9972,)
     pcost       dcost       gap    pres   dres
 0: -9.0244e+02 -2.3539e+04  1e+05  3e+00  2e-11
 1: -5.3869e+02 -1.3984e+04  3e+04  4e-01  2e-11
 2: -2.6831e+02 -4.5563e+03  8e+03  1e-01  9e-12
 3: -1.7203e+02 -2.6459e+03  4e+03  6e-02  6e-12
 4: -1.0162e+02 -1.4624e+03  2e+03  3e-02  4e-12
 5: -5.3710e+01 -1.0847e+03  2e+03  2e-02  3e-12
 6: -3.2824e+01 -7.4799e+02  1e+03  1e-02  2e-12
 7: -1.4211e+01 -4.2739e+02  6e+02  4e-03  1e-12
 8: -1.1085e+01 -1.8962e+02  3e+02  2e-03  1e-12
 9: -1.1500e+01 -5.9074e+01  5e+01  3e-14  1e-12
10: -1.6730e+01 -4.7955e+01  3e+01  1e-13  1e-12
11: -1.9697e+01 -4.0739e+01  2e+01  2e-13  1e-12
12: -2.1484e+01 -3.5883e+01  1e+01  1e-13  1e-12
13: -2.5010e+01 -3.0082e+01  5e+00  2e-13  1e-12
14: -2.6076e+01 -2.8151e+01  2e+00  2e-13  1e-12
15: -2.6944e+01 -2.7137e+01  2e-01  7e-14  1e-12
16: -2.7032e+01 -2.7037e+01  4e-03  3e-14  2e-12
17: -2.7034e+01 -2.7035e+01  5e-05  2e-13  2e-12
18: -2.7034e+01 -2.7034e+01  5e-07  1e-13  2e-12
Optimal solution found.
sv_indices: [73, 108, 149, 176, 208, 262, 334, 370, 488, 576, 600, 883, 902, 908, 968, 1023, 1032, 1042, 1054, 1073, 1130, 1164, 1179, 1226, 1291, 1339, 1343, 1358, 1556, 1560, 1682, 1688, 1703, 1789, 1794, 1816, 1823, 1913, 2018, 2041, 2087, 2162, 2186, 2295, 2366, 2388, 2416, 2439, 2615, 2626, 2739, 2813, 2817, 2929, 2965, 2983, 2985, 3030, 3033, 3051, 3121, 3132, 3234, 3317, 3426, 3490, 3505, 3527, 3717, 3795, 3806, 3847, 4023, 4033, 4111, 4162, 4176, 4251, 4275, 4282, 4298, 4350, 4443, 4572, 4648, 4677, 4679, 4760, 4776, 4849, 4882, 4932, 4940, 5125, 5258, 5289, 5327, 5341, 5368, 5379, 5415, 5455, 5461, 5489, 5532, 5573, 5802, 5865, 5925, 5946, 6000, 6002, 6005, 6017, 6026, 6078, 6162, 6349, 6377, 6429, 6491, 6505, 6701, 6789, 6801, 6829, 6871, 6908, 6912, 6937, 7013, 7020, 7093, 7145, 7234, 7336, 7404, 7405, 7483, 7545, 7564, 7572, 7575, 7603, 7613, 7782, 7801, 7845, 7865, 7909, 7931, 7944, 7958, 8039, 8057, 8076, 8132, 8150, 8158, 8176, 8228, 8231, 8294, 8303, 8310, 8456, 8496, 8548, 8564, 8689, 8710, 8717, 8786, 8796, 8853, 8871, 8922, 8932, 8975, 8976, 9127, 9136, 9139, 9186, 9208, 9358, 9453, 9539, 9544, 9672, 9687, 9689, 9694, 9701, 9705, 9751, 9753, 9760, 9834, 9899, 9929, 9966]
202 SVs (with labels):
Training time for 0.0-vs-3.0: 499.97706604 seconds
Begin training classifier for label 0.0 and label 4.0 at 2016-05-19, 22:29:10
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9774, 784) (9774,)
(9774, 784) (9774,)
     pcost       dcost       gap    pres   dres
 0: -6.4766e+02 -1.8285e+04  1e+05  3e+00  9e-12
 1: -3.8347e+02 -9.5401e+03  2e+04  3e-01  8e-12
 2: -1.8267e+02 -2.9464e+03  5e+03  9e-02  5e-12
 3: -1.1287e+02 -2.0084e+03  3e+03  5e-02  3e-12
 4: -5.9166e+01 -1.2993e+03  2e+03  3e-02  2e-12
 5: -3.6763e+01 -8.5909e+02  1e+03  2e-02  1e-12
 6: -1.7133e+01 -5.6214e+02  9e+02  8e-03  1e-12
 7: -9.5241e+00 -3.3204e+02  5e+02  4e-03  7e-13
 8: -4.1010e+00 -2.3206e+02  3e+02  2e-03  6e-13
 9: -3.5901e+00 -8.3214e+01  1e+02  7e-04  5e-13
10: -2.8427e+00 -4.0483e+01  4e+01  4e-05  5e-13
11: -6.0194e+00 -2.8270e+01  2e+01  2e-05  5e-13
12: -6.7519e+00 -2.4668e+01  2e+01  4e-06  5e-13
13: -9.4388e+00 -1.7492e+01  8e+00  6e-07  5e-13
14: -1.0357e+01 -1.5663e+01  5e+00  2e-07  5e-13
15: -1.1528e+01 -1.3577e+01  2e+00  3e-08  6e-13
16: -1.2054e+01 -1.2723e+01  7e-01  2e-14  6e-13
17: -1.2321e+01 -1.2408e+01  9e-02  6e-14  6e-13
18: -1.2362e+01 -1.2363e+01  2e-03  1e-13  7e-13
19: -1.2363e+01 -1.2363e+01  3e-05  8e-14  7e-13
20: -1.2363e+01 -1.2363e+01  4e-07  5e-15  7e-13
Optimal solution found.
sv_indices: [60, 104, 120, 342, 553, 616, 751, 764, 786, 870, 874, 970, 1054, 1103, 1381, 1393, 1431, 1489, 1691, 1971, 2008, 2041, 2159, 2295, 2366, 2698, 2703, 2900, 2967, 2974, 3030, 3121, 3241, 3317, 3365, 3426, 3492, 3641, 3649, 3666, 3769, 3792, 3797, 3843, 3880, 3946, 4010, 4059, 4119, 4157, 4251, 4254, 4261, 4298, 4304, 4350, 4385, 4475, 4496, 4524, 4572, 4625, 4679, 4725, 4734, 4756, 4760, 4794, 4862, 4882, 4984, 5018, 5097, 5137, 5173, 5175, 5204, 5229, 5241, 5247, 5262, 5405, 5408, 5534, 5549, 5668, 5678, 5696, 5778, 5808, 5809, 5836, 6002, 6017, 6066, 6077, 6104, 6298, 6354, 6371, 6408, 6549, 6569, 6592, 6758, 6803, 6807, 6809, 6905, 6966, 6977, 7055, 7079, 7112, 7119, 7154, 7167, 7182, 7210, 7233, 7368, 7437, 7445, 7446, 7557, 7582, 7646, 7649, 7650, 7679, 7745, 7802, 7843, 7941, 7952, 8013, 8028, 8043, 8096, 8135, 8226, 8233, 8240, 8280, 8290, 8514, 8571, 8722, 8771, 8843, 8847, 9089, 9107, 9114, 9116, 9148, 9168, 9221, 9240, 9322, 9338, 9510, 9746]
163 SVs (with labels):
Training time for 0.0-vs-4.0: 519.946719885 seconds
Begin training classifier for label 0.0 and label 5.0 at 2016-05-19, 22:37:50
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9434, 784) (9434,)
(9434, 784) (9434,)
     pcost       dcost       gap    pres   dres
 0: -1.1191e+03 -2.5267e+04  2e+05  4e+00  2e-11
 1: -6.7798e+02 -1.5797e+04  3e+04  5e-01  2e-11
 2: -4.0150e+02 -6.0973e+03  1e+04  2e-01  1e-11
 3: -2.6259e+02 -2.6501e+03  4e+03  6e-02  9e-12
 4: -1.8877e+02 -1.5320e+03  2e+03  3e-02  6e-12
 5: -1.4547e+02 -8.9189e+02  1e+03  1e-02  4e-12
 6: -1.2285e+02 -5.4263e+02  6e+02  6e-03  4e-12
 7: -1.1642e+02 -2.5794e+02  2e+02  1e-03  4e-12
 8: -1.2551e+02 -1.8612e+02  7e+01  2e-04  4e-12
 9: -1.2871e+02 -1.6915e+02  4e+01  7e-05  4e-12
10: -1.3622e+02 -1.5347e+02  2e+01  2e-05  4e-12
11: -1.3918e+02 -1.4682e+02  8e+00  2e-13  4e-12
12: -1.4156e+02 -1.4386e+02  2e+00  3e-13  4e-12
13: -1.4238e+02 -1.4287e+02  5e-01  2e-14  4e-12
14: -1.4261e+02 -1.4262e+02  1e-02  2e-13  4e-12
15: -1.4261e+02 -1.4261e+02  2e-04  3e-13  4e-12
16: -1.4261e+02 -1.4261e+02  3e-06  3e-13  4e-12
Optimal solution found.
sv_indices: [58, 60, 73, 84, 104, 108, 176, 190, 235, 248, 271, 289, 320, 329, 342, 355, 395, 401, 488, 542, 547, 576, 583, 614, 638, 662, 671, 687, 690, 703, 726, 811, 861, 883, 968, 976, 1032, 1054, 1067, 1087, 1101, 1112, 1266, 1280, 1291, 1343, 1349, 1352, 1381, 1386, 1489, 1495, 1524, 1529, 1548, 1554, 1555, 1580, 1582, 1688, 1691, 1703, 1705, 1711, 1754, 1786, 1789, 1794, 1812, 1845, 1857, 1888, 1913, 1952, 1956, 1977, 2002, 2041, 2043, 2071, 2144, 2203, 2227, 2295, 2313, 2366, 2380, 2384, 2416, 2435, 2437, 2501, 2550, 2580, 2599, 2615, 2688, 2698, 2703, 2719, 2756, 2805, 2806, 2807, 2808, 2813, 2974, 2985, 3026, 3030, 3048, 3051, 3121, 3201, 3230, 3291, 3346, 3371, 3398, 3407, 3410, 3490, 3513, 3527, 3542, 3545, 3613, 3683, 3702, 3714, 3773, 3795, 3797, 3810, 3824, 3835, 3875, 3887, 3946, 3949, 3973, 3982, 4010, 4023, 4037, 4095, 4111, 4141, 4157, 4162, 4251, 4275, 4298, 4304, 4334, 4350, 4394, 4443, 4475, 4482, 4483, 4572, 4592, 4648, 4677, 4679, 4721, 4755, 4756, 4794, 4849, 4882, 4908, 4920, 4928, 4943, 4999, 5039, 5068, 5072, 5083, 5133, 5162, 5199, 5258, 5259, 5309, 5313, 5354, 5372, 5380, 5395, 5408, 5440, 5473, 5476, 5489, 5505, 5513, 5560, 5582, 5629, 5650, 5680, 5693, 5718, 5768, 5770, 5772, 5802, 5836, 5862, 5891, 5907, 5926, 5948, 5953, 5971, 5980, 6012, 6025, 6028, 6071, 6075, 6087, 6104, 6107, 6114, 6222, 6290, 6293, 6350, 6378, 6507, 6517, 6599, 6642, 6662, 6691, 6692, 6722, 6724, 6732, 6754, 6764, 6780, 6811, 6851, 6874, 6884, 6889, 6910, 7010, 7022, 7036, 7038, 7062, 7072, 7083, 7162, 7223, 7272, 7295, 7314, 7406, 7409, 7421, 7460, 7472, 7476, 7521, 7543, 7590, 7655, 7665, 7693, 7710, 7733, 7741, 7751, 7764, 7771, 7793, 7848, 7875, 7893, 7897, 7902, 7912, 7923, 7941, 7967, 7998, 8000, 8019, 8055, 8075, 8100, 8106, 8112, 8131, 8143, 8146, 8166, 8231, 8246, 8268, 8272, 8274, 8287, 8353, 8370, 8389, 8398, 8463, 8476, 8480, 8495, 8501, 8503, 8506, 8520, 8524, 8525, 8542, 8567, 8605, 8731, 8748, 8768, 8782, 8811, 8846, 8918, 8919, 8931, 8968, 8971, 8979, 8987, 9009, 9011, 9042, 9047, 9055, 9077, 9080, 9091, 9109, 9112, 9144, 9159, 9182, 9217, 9231, 9256, 9259, 9262, 9280, 9284, 9291, 9412]
362 SVs (with labels):
Training time for 0.0-vs-5.0: 382.241405964 seconds
Begin training classifier for label 0.0 and label 6.0 at 2016-05-19, 22:44:12
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9846, 784) (9846,)
(9846, 784) (9846,)
     pcost       dcost       gap    pres   dres
 0: -1.0196e+03 -2.0177e+04  1e+05  3e+00  2e-11
 1: -6.2242e+02 -1.1353e+04  2e+04  4e-01  2e-11
 2: -3.2266e+02 -3.4122e+03  5e+03  9e-02  1e-11
 3: -2.0523e+02 -1.8048e+03  3e+03  4e-02  7e-12
 4: -1.4564e+02 -1.1635e+03  2e+03  2e-02  5e-12
 5: -1.0746e+02 -7.4601e+02  1e+03  1e-02  4e-12
 6: -8.5436e+01 -4.4718e+02  6e+02  6e-03  3e-12
 7: -7.2321e+01 -2.8601e+02  3e+02  3e-03  3e-12
 8: -6.6207e+01 -1.6151e+02  1e+02  1e-03  3e-12
 9: -6.8981e+01 -9.2608e+01  3e+01  1e-04  3e-12
10: -7.2083e+01 -8.1680e+01  1e+01  2e-05  3e-12
11: -7.4541e+01 -7.6991e+01  2e+00  1e-13  3e-12
12: -7.5455e+01 -7.5920e+01  5e-01  8e-14  3e-12
13: -7.5670e+01 -7.5680e+01  1e-02  6e-14  3e-12
14: -7.5675e+01 -7.5675e+01  1e-04  4e-15  3e-12
15: -7.5675e+01 -7.5675e+01  1e-06  2e-13  3e-12
Optimal solution found.
sv_indices: [17, 60, 84, 104, 108, 119, 146, 186, 224, 361, 370, 380, 440, 470, 513, 557, 630, 646, 695, 728, 751, 764, 870, 883, 909, 916, 921, 927, 970, 1103, 1115, 1179, 1216, 1240, 1373, 1381, 1401, 1431, 1459, 1475, 1489, 1524, 1549, 1572, 1585, 1624, 1628, 1688, 1722, 1746, 1754, 1848, 1888, 1910, 1938, 1971, 1997, 2008, 2041, 2064, 2164, 2203, 2273, 2366, 2371, 2416, 2420, 2471, 2501, 2508, 2510, 2543, 2579, 2666, 2685, 2692, 2703, 2770, 2813, 2820, 2948, 2969, 2991, 3030, 3031, 3047, 3121, 3203, 3231, 3281, 3297, 3360, 3361, 3459, 3588, 3649, 3671, 3682, 3683, 3769, 3795, 3797, 3877, 3973, 3988, 3990, 4013, 4023, 4119, 4217, 4245, 4251, 4304, 4350, 4378, 4394, 4397, 4443, 4475, 4480, 4483, 4492, 4496, 4524, 4572, 4641, 4649, 4674, 4677, 4679, 4727, 4756, 4760, 4761, 4880, 4944, 5018, 5094, 5119, 5155, 5174, 5243, 5319, 5321, 5331, 5357, 5360, 5400, 5421, 5437, 5481, 5534, 5563, 5570, 5573, 5611, 5619, 5650, 5665, 5677, 5745, 5774, 5835, 5862, 5899, 5911, 5930, 6060, 6085, 6160, 6177, 6185, 6193, 6227, 6233, 6239, 6268, 6276, 6286, 6313, 6321, 6441, 6557, 6583, 6592, 6603, 6610, 6617, 6632, 6684, 6690, 6799, 6862, 6876, 6915, 6946, 7019, 7038, 7154, 7207, 7217, 7232, 7279, 7286, 7287, 7339, 7342, 7343, 7388, 7401, 7414, 7422, 7527, 7572, 7675, 7756, 7808, 7812, 7865, 7953, 7968, 8069, 8113, 8119, 8128, 8141, 8149, 8152, 8179, 8226, 8263, 8265, 8312, 8338, 8346, 8379, 8385, 8426, 8538, 8555, 8567, 8571, 8638, 8687, 8857, 8862, 8898, 8909, 8918, 8942, 9002, 9095, 9117, 9126, 9170, 9194, 9235, 9272, 9300, 9387, 9465, 9470, 9522, 9550, 9599, 9631, 9634, 9668, 9671, 9677, 9686, 9698, 9724, 9749, 9773]
275 SVs (with labels):
Training time for 0.0-vs-6.0: 404.43317008 seconds
Begin training classifier for label 0.0 and label 7.0 at 2016-05-19, 22:50:56
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10162, 784) (10162,)
(10162, 784) (10162,)
     pcost       dcost       gap    pres   dres
 0: -7.1204e+02 -2.0237e+04  1e+05  3e+00  9e-12
 1: -4.1370e+02 -1.1039e+04  2e+04  4e-01  8e-12
 2: -1.8319e+02 -3.2748e+03  6e+03  9e-02  4e-12
 3: -8.9734e+01 -1.4222e+03  2e+03  4e-02  3e-12
 4: -5.4407e+01 -8.8604e+02  1e+03  2e-02  2e-12
 5: -2.8506e+01 -6.4228e+02  1e+03  1e-02  1e-12
 6: -1.4461e+01 -4.9338e+02  8e+02  8e-03  7e-13
 7: -6.6890e+00 -1.9873e+02  3e+02  3e-03  5e-13
 8: -4.0039e+00 -6.0015e+01  8e+01  6e-04  3e-13
 9: -3.2810e+00 -2.6534e+01  3e+01  1e-04  3e-13
10: -5.0950e+00 -1.6698e+01  1e+01  3e-05  3e-13
11: -4.9005e+00 -1.5748e+01  1e+01  1e-05  3e-13
12: -6.7342e+00 -1.1645e+01  5e+00  4e-06  3e-13
13: -7.3706e+00 -1.0244e+01  3e+00  9e-07  3e-13
14: -8.0244e+00 -9.1443e+00  1e+00  2e-07  4e-13
15: -8.3702e+00 -8.6566e+00  3e-01  2e-08  4e-13
16: -8.4939e+00 -8.5019e+00  8e-03  2e-10  4e-13
17: -8.4977e+00 -8.4978e+00  9e-05  2e-12  4e-13
18: -8.4977e+00 -8.4977e+00  9e-07  4e-14  4e-13
Optimal solution found.
sv_indices: [104, 149, 267, 271, 304, 320, 342, 584, 616, 684, 697, 825, 947, 1042, 1067, 1226, 1258, 1339, 1343, 1393, 1489, 1492, 1546, 1555, 1560, 1580, 1683, 1772, 1939, 1971, 2008, 2041, 2110, 2227, 2295, 2366, 2435, 2703, 2756, 2808, 3030, 3155, 3229, 3317, 3371, 3426, 3492, 3496, 3505, 3666, 3702, 3795, 3820, 3946, 4072, 4111, 4119, 4162, 4176, 4251, 4261, 4270, 4304, 4355, 4458, 4524, 4572, 4677, 4687, 4760, 4794, 4862, 4882, 4929, 5107, 5127, 5274, 5385, 5440, 5637, 5679, 5747, 5785, 5966, 6011, 6033, 6044, 6054, 6087, 6121, 6191, 6213, 6314, 6376, 6620, 6653, 6692, 6867, 6875, 6952, 7158, 7217, 7353, 7375, 7443, 7449, 7603, 7635, 7648, 7731, 7736, 7775, 7808, 7836, 7895, 7907, 7953, 8094, 8171, 8347, 8433, 8457, 8537, 8593, 8662, 8683, 8772, 8813, 8814, 8862, 8935, 9007, 9096, 9139, 9148, 9157, 9173, 9224, 9265, 9288, 9374, 9420, 9422, 9442, 9583, 9639, 9730, 9804, 9840, 10026]
150 SVs (with labels):
Training time for 0.0-vs-7.0: 507.010048866 seconds
Begin training classifier for label 0.0 and label 8.0 at 2016-05-19, 22:59:24
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9774, 784) (9774,)
(9774, 784) (9774,)
     pcost       dcost       gap    pres   dres
 0: -7.9509e+02 -2.3563e+04  2e+05  3e+00  1e-11
 1: -4.9555e+02 -1.3628e+04  3e+04  4e-01  2e-11
 2: -3.1328e+02 -5.6074e+03  9e+03  1e-01  9e-12
 3: -2.1531e+02 -2.9362e+03  5e+03  6e-02  6e-12
 4: -1.4548e+02 -2.1531e+03  3e+03  4e-02  5e-12
 5: -1.0560e+02 -1.4939e+03  2e+03  2e-02  4e-12
 6: -7.4810e+01 -1.1594e+03  2e+03  1e-02  3e-12
 7: -5.6015e+01 -8.2337e+02  1e+03  8e-03  3e-12
 8: -4.5452e+01 -3.4426e+02  4e+02  2e-03  2e-12
 9: -5.0555e+01 -2.0235e+02  2e+02  7e-04  2e-12
10: -5.2277e+01 -1.5229e+02  1e+02  8e-05  3e-12
11: -6.0964e+01 -1.2068e+02  6e+01  4e-05  2e-12
12: -6.5773e+01 -1.0610e+02  4e+01  1e-05  2e-12
13: -7.1444e+01 -9.1391e+01  2e+01  3e-06  3e-12
14: -7.4451e+01 -8.4657e+01  1e+01  3e-07  3e-12
15: -7.7186e+01 -8.0565e+01  3e+00  6e-08  3e-12
16: -7.8112e+01 -7.9208e+01  1e+00  8e-09  3e-12
17: -7.8523e+01 -7.8700e+01  2e-01  2e-13  3e-12
18: -7.8607e+01 -7.8610e+01  3e-03  2e-13  3e-12
19: -7.8608e+01 -7.8608e+01  5e-05  3e-14  3e-12
Optimal solution found.
sv_indices: [60, 73, 104, 136, 176, 190, 271, 320, 329, 488, 491, 517, 551, 564, 606, 613, 614, 630, 649, 663, 671, 687, 700, 825, 869, 883, 902, 1025, 1032, 1035, 1091, 1103, 1127, 1171, 1179, 1343, 1348, 1349, 1352, 1381, 1393, 1431, 1433, 1453, 1489, 1495, 1546, 1560, 1616, 1628, 1688, 1746, 1786, 1789, 1816, 1913, 2008, 2041, 2071, 2219, 2227, 2259, 2290, 2334, 2366, 2384, 2388, 2390, 2416, 2435, 2492, 2518, 2626, 2697, 2703, 2724, 2756, 2794, 2807, 2876, 2900, 3030, 3031, 3106, 3137, 3251, 3255, 3271, 3335, 3425, 3426, 3449, 3490, 3527, 3564, 3641, 3646, 3687, 3785, 3792, 3795, 3887, 3960, 3973, 3982, 4010, 4023, 4037, 4051, 4221, 4294, 4350, 4355, 4425, 4443, 4483, 4493, 4539, 4572, 4592, 4607, 4662, 4677, 4679, 4721, 4725, 4780, 4846, 4849, 4882, 4959, 4962, 5011, 5015, 5064, 5077, 5105, 5123, 5133, 5135, 5146, 5193, 5222, 5258, 5263, 5308, 5312, 5322, 5358, 5362, 5419, 5446, 5453, 5513, 5542, 5550, 5609, 5616, 5656, 5696, 5700, 5711, 5729, 5760, 5793, 5969, 5970, 5980, 5989, 6006, 6041, 6069, 6091, 6099, 6137, 6142, 6159, 6161, 6199, 6244, 6273, 6286, 6293, 6311, 6340, 6341, 6358, 6411, 6541, 6571, 6577, 6586, 6644, 6734, 6735, 6760, 6762, 6804, 6818, 6860, 6907, 6945, 6963, 7034, 7079, 7113, 7121, 7154, 7203, 7208, 7211, 7229, 7236, 7271, 7293, 7365, 7409, 7412, 7414, 7511, 7513, 7565, 7590, 7624, 7641, 7680, 7715, 7717, 7724, 7786, 7817, 7822, 7832, 7905, 7932, 7933, 7945, 8000, 8131, 8240, 8268, 8279, 8295, 8327, 8379, 8419, 8422, 8483, 8585, 8660, 8686, 8692, 8695, 8710, 8714, 8750, 8799, 8825, 8843, 8893, 8895, 8928, 8940, 9013, 9037, 9055, 9075, 9130, 9136, 9139, 9147, 9199, 9240, 9248, 9269, 9310, 9314, 9342, 9371, 9398, 9402, 9403, 9430, 9436, 9521, 9598, 9602, 9615, 9685, 9760]
290 SVs (with labels):
Training time for 0.0-vs-8.0: 496.107206106 seconds
Begin training classifier for label 0.0 and label 9.0 at 2016-05-19, 23:07:40
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9941, 784) (9941,)
(9941, 784) (9941,)
     pcost       dcost       gap    pres   dres
 0: -7.1973e+02 -1.9945e+04  1e+05  3e+00  1e-11
 1: -4.3513e+02 -1.0795e+04  2e+04  4e-01  1e-11
 2: -2.2239e+02 -3.4114e+03  6e+03  9e-02  7e-12
 3: -1.4588e+02 -1.9938e+03  3e+03  5e-02  4e-12
 4: -8.9137e+01 -1.1985e+03  2e+03  3e-02  3e-12
 5: -5.2768e+01 -7.3482e+02  1e+03  1e-02  2e-12
 6: -3.3695e+01 -4.9565e+02  7e+02  7e-03  2e-12
 7: -2.1601e+01 -2.9194e+02  4e+02  4e-03  1e-12
 8: -1.4206e+01 -1.0978e+02  1e+02  6e-04  1e-12
 9: -1.9477e+01 -5.7532e+01  4e+01  2e-04  1e-12
10: -2.1000e+01 -4.1488e+01  2e+01  3e-06  1e-12
11: -2.4590e+01 -3.4692e+01  1e+01  1e-06  1e-12
12: -2.5752e+01 -3.2271e+01  7e+00  2e-07  1e-12
13: -2.7457e+01 -2.9804e+01  2e+00  6e-08  1e-12
14: -2.8118e+01 -2.8819e+01  7e-01  7e-14  2e-12
15: -2.8442e+01 -2.8460e+01  2e-02  2e-14  2e-12
16: -2.8450e+01 -2.8451e+01  3e-04  9e-14  2e-12
17: -2.8451e+01 -2.8451e+01  3e-06  2e-13  2e-12
Optimal solution found.
sv_indices: [17, 73, 78, 149, 236, 267, 271, 320, 342, 395, 519, 564, 584, 613, 623, 625, 784, 806, 870, 873, 1032, 1068, 1164, 1226, 1266, 1291, 1334, 1339, 1349, 1350, 1381, 1393, 1401, 1433, 1468, 1489, 1492, 1529, 1546, 1551, 1560, 1580, 1691, 1718, 1780, 1835, 1977, 2007, 2008, 2041, 2047, 2082, 2087, 2110, 2195, 2280, 2284, 2295, 2366, 2458, 2467, 2569, 2624, 2626, 2698, 2703, 2756, 2808, 3030, 3106, 3208, 3317, 3371, 3426, 3449, 3492, 3505, 3527, 3578, 3618, 3641, 3649, 3698, 3769, 3795, 3887, 3932, 3946, 3990, 3992, 4012, 4023, 4059, 4072, 4111, 4157, 4261, 4304, 4355, 4358, 4371, 4429, 4443, 4480, 4524, 4572, 4677, 4689, 4725, 4734, 4760, 4762, 4862, 4882, 4972, 4974, 4980, 5017, 5099, 5113, 5125, 5340, 5477, 5601, 5649, 5659, 5670, 5787, 5807, 5866, 5891, 5893, 5896, 5955, 6233, 6282, 6306, 6337, 6377, 6681, 6724, 6837, 6850, 6940, 6962, 6975, 7033, 7080, 7215, 7253, 7306, 7325, 7330, 7348, 7424, 7431, 7433, 7453, 7521, 7539, 7583, 7631, 7776, 7778, 7840, 7853, 7931, 7984, 8012, 8054, 8059, 8151, 8165, 8175, 8286, 8369, 8453, 8503, 8537, 8581, 8605, 8703, 8732, 8841, 8926, 8966, 8987, 9091, 9130, 9151, 9179, 9186, 9269, 9277, 9327, 9350, 9359, 9378, 9503, 9537, 9559, 9607, 9609, 9637, 9763, 9862, 9891]
207 SVs (with labels):
Training time for 0.0-vs-9.0: 471.446549892 seconds
Begin training classifier for label 1.0 and label 2.0 at 2016-05-19, 23:15:31
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10587, 784) (10587,)
(10587, 784) (10587,)
     pcost       dcost       gap    pres   dres
 0: -1.1510e+03 -2.8094e+04  2e+05  4e+00  2e-11
 1: -6.9714e+02 -1.8211e+04  4e+04  6e-01  1e-11
 2: -4.1637e+02 -7.6158e+03  1e+04  2e-01  1e-11
 3: -2.7679e+02 -3.8399e+03  6e+03  8e-02  6e-12
 4: -2.0479e+02 -2.7520e+03  4e+03  5e-02  5e-12
 5: -1.5506e+02 -1.9627e+03  3e+03  3e-02  4e-12
 6: -1.1393e+02 -1.4413e+03  2e+03  2e-02  3e-12
 7: -8.8131e+01 -1.0958e+03  2e+03  1e-02  2e-12
 8: -6.5273e+01 -7.3047e+02  1e+03  6e-03  2e-12
 9: -4.9485e+01 -5.2835e+02  7e+02  3e-03  2e-12
10: -5.2093e+01 -3.0325e+02  3e+02  1e-03  2e-12
11: -5.3114e+01 -2.3145e+02  2e+02  5e-04  2e-12
12: -6.7455e+01 -1.5496e+02  9e+01  2e-04  2e-12
13: -7.0733e+01 -1.3574e+02  7e+01  5e-05  2e-12
14: -7.8652e+01 -1.1534e+02  4e+01  2e-05  2e-12
15: -8.2434e+01 -1.0448e+02  2e+01  5e-06  2e-12
16: -8.6409e+01 -9.7174e+01  1e+01  1e-06  2e-12
17: -8.8182e+01 -9.3936e+01  6e+00  3e-13  3e-12
18: -8.9846e+01 -9.1947e+01  2e+00  6e-13  2e-12
19: -9.0607e+01 -9.1034e+01  4e-01  2e-13  3e-12
20: -9.0802e+01 -9.0815e+01  1e-02  2e-13  3e-12
21: -9.0808e+01 -9.0809e+01  2e-04  5e-14  3e-12
22: -9.0808e+01 -9.0808e+01  2e-06  3e-13  3e-12
Optimal solution found.
sv_indices: [17, 36, 68, 82, 89, 117, 132, 162, 175, 263, 345, 386, 397, 454, 499, 504, 568, 573, 654, 715, 764, 861, 948, 953, 971, 993, 1002, 1005, 1014, 1020, 1067, 1140, 1149, 1182, 1192, 1212, 1250, 1339, 1372, 1382, 1444, 1506, 1536, 1539, 1593, 1598, 1621, 1728, 1752, 1836, 1848, 1973, 1989, 2159, 2181, 2222, 2233, 2337, 2368, 2376, 2465, 2522, 2589, 2660, 2675, 2693, 2712, 2776, 2812, 2830, 2856, 2866, 2880, 2882, 2989, 3025, 3123, 3160, 3161, 3202, 3321, 3348, 3392, 3411, 3626, 3644, 3666, 3739, 3745, 3746, 3809, 3832, 3940, 4071, 4075, 4112, 4211, 4261, 4287, 4291, 4347, 4395, 4399, 4434, 4439, 4537, 4565, 4612, 4644, 4720, 4784, 4810, 4876, 4949, 5188, 5249, 5311, 5317, 5420, 5425, 5517, 5532, 5556, 5653, 5709, 5720, 5728, 5729, 5793, 5828, 5839, 5855, 5909, 5910, 5917, 5927, 5934, 5956, 5965, 5982, 6054, 6139, 6205, 6244, 6247, 6268, 6270, 6371, 6394, 6430, 6520, 6557, 6606, 6619, 6653, 6695, 6715, 6731, 6780, 6846, 6848, 6879, 6910, 6919, 6940, 6951, 6984, 6993, 7083, 7085, 7096, 7113, 7119, 7128, 7135, 7136, 7142, 7145, 7178, 7209, 7386, 7400, 7437, 7465, 7534, 7555, 7564, 7567, 7574, 7584, 7597, 7611, 7658, 7660, 7776, 7822, 7827, 7891, 7950, 7967, 7979, 8017, 8029, 8031, 8076, 8091, 8132, 8148, 8188, 8273, 8301, 8303, 8329, 8349, 8352, 8438, 8503, 8539, 8569, 8587, 8590, 8597, 8659, 8717, 8724, 8787, 8919, 8922, 8936, 8958, 8995, 9018, 9071, 9078, 9137, 9154, 9371, 9390, 9425, 9477, 9518, 9571, 9585, 9590, 9680, 9726, 9797, 9812, 9929, 9940, 9960, 9990, 10029, 10086, 10100, 10108, 10122, 10183, 10200, 10221, 10255, 10281, 10314, 10320, 10346, 10366, 10377, 10384, 10445, 10470, 10474, 10486, 10520, 10558]
274 SVs (with labels):
Training time for 1.0-vs-2.0: 696.223483086 seconds
Begin training classifier for label 1.0 and label 3.0 at 2016-05-19, 23:27:08
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10658, 784) (10658,)
(10658, 784) (10658,)
     pcost       dcost       gap    pres   dres
 0: -7.4227e+02 -2.2072e+04  1e+05  3e+00  9e-12
 1: -4.6206e+02 -1.2501e+04  3e+04  4e-01  9e-12
 2: -2.8058e+02 -5.3332e+03  9e+03  1e-01  6e-12
 3: -1.7675e+02 -2.7339e+03  4e+03  6e-02  4e-12
 4: -1.2401e+02 -1.7789e+03  3e+03  4e-02  3e-12
 5: -8.0813e+01 -1.1449e+03  2e+03  2e-02  2e-12
 6: -6.5132e+01 -8.8117e+02  1e+03  1e-02  2e-12
 7: -4.7464e+01 -6.3295e+02  9e+02  7e-03  2e-12
 8: -3.8133e+01 -3.3706e+02  4e+02  2e-03  1e-12
 9: -3.5832e+01 -2.4199e+02  3e+02  1e-03  1e-12
10: -3.6466e+01 -1.7784e+02  2e+02  4e-04  1e-12
11: -4.4048e+01 -1.3488e+02  1e+02  2e-04  1e-12
12: -4.3911e+01 -1.1832e+02  8e+01  2e-05  2e-12
13: -5.4393e+01 -8.8514e+01  3e+01  7e-06  1e-12
14: -5.7241e+01 -8.2061e+01  2e+01  4e-06  1e-12
15: -6.0427e+01 -7.4991e+01  1e+01  1e-06  2e-12
16: -6.3039e+01 -7.0119e+01  7e+00  3e-07  2e-12
17: -6.4149e+01 -6.7948e+01  4e+00  2e-13  2e-12
18: -6.5505e+01 -6.6303e+01  8e-01  2e-13  2e-12
19: -6.5800e+01 -6.5962e+01  2e-01  1e-13  2e-12
20: -6.5869e+01 -6.5882e+01  1e-02  2e-13  2e-12
21: -6.5875e+01 -6.5875e+01  2e-04  1e-14  2e-12
22: -6.5875e+01 -6.5875e+01  2e-06  3e-13  2e-12
Optimal solution found.
sv_indices: [10, 17, 36, 53, 169, 178, 263, 345, 382, 397, 436, 439, 451, 454, 504, 568, 644, 649, 654, 715, 788, 948, 993, 1020, 1078, 1303, 1319, 1340, 1354, 1372, 1440, 1506, 1536, 1578, 1593, 1642, 1673, 1728, 1756, 1836, 1855, 1928, 2122, 2149, 2158, 2161, 2164, 2266, 2347, 2353, 2368, 2387, 2412, 2415, 2465, 2571, 2589, 2635, 2660, 2675, 2710, 2736, 2812, 2822, 2879, 2901, 2903, 3025, 3053, 3068, 3122, 3160, 3202, 3255, 3352, 3597, 3660, 3745, 3746, 3789, 3832, 3983, 4005, 4075, 4094, 4100, 4112, 4182, 4184, 4198, 4212, 4250, 4253, 4287, 4347, 4365, 4395, 4399, 4435, 4473, 4485, 4537, 4565, 4658, 4661, 4720, 4791, 4857, 4876, 4949, 4977, 5030, 5107, 5129, 5216, 5286, 5360, 5382, 5425, 5517, 5556, 5607, 5610, 5651, 5691, 5738, 5753, 5843, 5925, 5982, 5999, 6072, 6085, 6179, 6209, 6214, 6217, 6218, 6345, 6388, 6535, 6571, 6645, 6668, 6676, 6688, 6727, 6762, 6789, 6803, 6863, 6882, 6891, 6928, 6952, 7006, 7064, 7065, 7115, 7152, 7186, 7247, 7307, 7404, 7484, 7524, 7540, 7557, 7593, 7654, 7672, 7673, 7725, 7754, 7787, 7891, 7894, 7908, 7936, 7971, 8038, 8073, 8127, 8155, 8197, 8250, 8352, 8389, 8407, 8423, 8455, 8486, 8522, 8551, 8556, 8567, 8686, 8737, 8742, 8760, 8797, 8818, 8840, 8926, 8986, 8994, 9079, 9105, 9106, 9183, 9191, 9231, 9247, 9325, 9337, 9372, 9393, 9399, 9463, 9503, 9516, 9577, 9667, 9679, 9700, 9723, 9724, 9813, 9845, 9850, 9877, 9928, 9938, 9996, 10048, 10148, 10157, 10238, 10275, 10316, 10363, 10420, 10469, 10491, 10513, 10517, 10520, 10539, 10558, 10579, 10615, 10625]
252 SVs (with labels):
Training time for 1.0-vs-3.0: 705.287758827 seconds
Begin training classifier for label 1.0 and label 4.0 at 2016-05-19, 23:38:53
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10460, 784) (10460,)
(10460, 784) (10460,)
     pcost       dcost       gap    pres   dres
 0: -4.7040e+02 -2.3212e+04  1e+05  3e+00  4e-12
 1: -2.8715e+02 -1.3335e+04  3e+04  4e-01  4e-12
 2: -1.3859e+02 -4.0540e+03  7e+03  1e-01  3e-12
 3: -8.7065e+01 -2.1749e+03  3e+03  5e-02  2e-12
 4: -5.0977e+01 -1.1743e+03  2e+03  2e-02  1e-12
 5: -3.3547e+01 -7.3052e+02  1e+03  1e-02  8e-13
 6: -2.1145e+01 -4.3902e+02  7e+02  6e-03  6e-13
 7: -1.3728e+01 -1.9631e+02  3e+02  2e-03  5e-13
 8: -1.1132e+01 -1.2703e+02  2e+02  1e-03  4e-13
 9: -1.1506e+01 -6.7470e+01  7e+01  3e-04  4e-13
10: -1.3094e+01 -3.9411e+01  3e+01  3e-06  5e-13
11: -1.6047e+01 -3.2059e+01  2e+01  1e-06  5e-13
12: -1.7934e+01 -2.6986e+01  9e+00  2e-13  6e-13
13: -1.9521e+01 -2.4232e+01  5e+00  8e-14  5e-13
14: -2.0057e+01 -2.3043e+01  3e+00  1e-13  6e-13
15: -2.0877e+01 -2.2004e+01  1e+00  4e-14  5e-13
16: -2.1210e+01 -2.1566e+01  4e-01  4e-14  6e-13
17: -2.1367e+01 -2.1397e+01  3e-02  4e-14  6e-13
18: -2.1381e+01 -2.1382e+01  5e-04  5e-14  6e-13
19: -2.1381e+01 -2.1381e+01  7e-06  8e-15  6e-13
Optimal solution found.
sv_indices: [6, 17, 62, 175, 397, 413, 527, 568, 608, 684, 711, 730, 744, 764, 784, 788, 915, 960, 1020, 1041, 1074, 1186, 1340, 1441, 1498, 1539, 1626, 1642, 1673, 1738, 1997, 2100, 2122, 2159, 2347, 2368, 2465, 2488, 2866, 2876, 2902, 2915, 2945, 3068, 3277, 3352, 3392, 3411, 3613, 3626, 3745, 3832, 4005, 4244, 4280, 4365, 4434, 4537, 4559, 4565, 4741, 4854, 4876, 4934, 4977, 5069, 5107, 5161, 5166, 5216, 5308, 5369, 5387, 5640, 5678, 5706, 5710, 5783, 5823, 5910, 5915, 6002, 6003, 6088, 6094, 6112, 6163, 6192, 6199, 6342, 6542, 6560, 6569, 6752, 6805, 6809, 6865, 7030, 7040, 7068, 7265, 7355, 7379, 7391, 7404, 7472, 7495, 7722, 7787, 7820, 7853, 7896, 7991, 8024, 8029, 8057, 8074, 8077, 8100, 8135, 8254, 8298, 8308, 8482, 8530, 8537, 8611, 8641, 8773, 8839, 8919, 8966, 8995, 9079, 9095, 9139, 9327, 9340, 9392, 9412, 9422, 9490, 9497, 9501, 9640, 9777, 9834, 9881, 9928, 9966, 10374, 10376]
152 SVs (with labels):
Training time for 1.0-vs-4.0: 577.447369099 seconds
Begin training classifier for label 1.0 and label 5.0 at 2016-05-19, 23:48:31
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10120, 784) (10120,)
(10120, 784) (10120,)
     pcost       dcost       gap    pres   dres
 0: -5.5428e+02 -2.4624e+04  2e+05  3e+00  5e-12
 1: -3.4429e+02 -1.4345e+04  3e+04  4e-01  6e-12
 2: -2.1375e+02 -6.2185e+03  1e+04  1e-01  3e-12
 3: -1.3049e+02 -3.4856e+03  6e+03  7e-02  2e-12
 4: -8.6643e+01 -2.5046e+03  4e+03  5e-02  2e-12
 5: -4.9142e+01 -1.3953e+03  2e+03  2e-02  1e-12
 6: -2.3025e+01 -8.2843e+02  1e+03  1e-02  8e-13
 7: -7.7842e+00 -6.0319e+02  9e+02  6e-03  6e-13
 8: -4.2906e+00 -1.9961e+02  3e+02  1e-03  5e-13
 9: -4.2180e+00 -1.0480e+02  1e+02  3e-04  5e-13
10: -9.7855e+00 -6.4822e+01  6e+01  1e-04  4e-13
11: -1.3015e+01 -5.0924e+01  4e+01  3e-05  5e-13
12: -1.7448e+01 -3.6631e+01  2e+01  9e-06  5e-13
13: -1.9591e+01 -3.1176e+01  1e+01  3e-06  5e-13
14: -2.1056e+01 -2.7885e+01  7e+00  7e-07  5e-13
15: -2.2223e+01 -2.5570e+01  3e+00  5e-14  6e-13
16: -2.3383e+01 -2.4068e+01  7e-01  7e-14  6e-13
17: -2.3661e+01 -2.3724e+01  6e-02  1e-13  6e-13
18: -2.3691e+01 -2.3692e+01  1e-03  2e-13  7e-13
19: -2.3691e+01 -2.3691e+01  2e-05  1e-13  6e-13
Optimal solution found.
sv_indices: [6, 17, 36, 143, 263, 295, 365, 397, 418, 451, 454, 654, 684, 724, 730, 747, 764, 788, 827, 948, 1013, 1019, 1020, 1140, 1221, 1339, 1340, 1372, 1506, 1525, 1536, 1539, 1572, 1593, 1673, 1723, 1724, 1728, 1738, 1796, 1848, 2159, 2412, 2465, 2496, 2510, 2675, 2880, 2945, 3025, 3160, 3201, 3202, 3352, 3364, 3392, 3411, 3745, 3746, 3789, 3832, 4099, 4112, 4291, 4347, 4365, 4434, 4493, 4507, 4525, 4537, 4559, 4724, 4876, 4894, 5006, 5069, 5151, 5157, 5161, 5216, 5259, 5603, 5622, 5624, 5652, 5709, 5711, 5743, 5783, 5819, 5850, 5859, 5861, 5942, 5999, 6072, 6179, 6183, 6226, 6297, 6316, 6340, 6352, 6389, 6408, 6689, 6732, 6749, 6763, 6837, 6853, 6922, 6946, 6970, 6979, 7102, 7104, 7135, 7152, 7155, 7161, 7170, 7214, 7335, 7393, 7406, 7431, 7436, 7446, 7454, 7494, 7564, 7671, 7778, 7791, 7812, 7838, 7874, 7907, 7909, 7944, 7945, 7956, 8001, 8008, 8032, 8079, 8102, 8113, 8153, 8167, 8186, 8209, 8342, 8405, 8445, 8450, 8469, 8521, 8557, 8563, 8642, 8657, 8671, 8748, 8814, 8818, 8889, 8890, 8899, 8959, 8976, 9082, 9135, 9158, 9287, 9302, 9306, 9316, 9377, 9429, 9434, 9457, 9501, 9594, 9628, 9637, 9698, 9718, 9768, 9947, 9952, 10019, 10058, 10071, 10096]
197 SVs (with labels):
Training time for 1.0-vs-5.0: 533.354777098 seconds
Begin training classifier for label 1.0 and label 6.0 at 2016-05-19, 23:57:24
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10532, 784) (10532,)
(10532, 784) (10532,)
     pcost       dcost       gap    pres   dres
 0: -5.4964e+02 -2.0273e+04  1e+05  3e+00  6e-12
 1: -3.3156e+02 -1.0993e+04  2e+04  4e-01  6e-12
 2: -1.5706e+02 -3.4584e+03  6e+03  1e-01  4e-12
 3: -9.1158e+01 -1.8855e+03  3e+03  5e-02  3e-12
 4: -4.9164e+01 -1.0675e+03  2e+03  2e-02  1e-12
 5: -3.1129e+01 -6.9528e+02  1e+03  1e-02  9e-13
 6: -1.7577e+01 -5.2601e+02  8e+02  9e-03  6e-13
 7: -9.1964e+00 -2.2886e+02  4e+02  3e-03  4e-13
 8: -3.8041e+00 -1.6326e+02  2e+02  2e-03  3e-13
 9: -2.6177e+00 -6.1079e+01  8e+01  5e-04  3e-13
10: -8.9535e-01 -5.6117e+01  7e+01  3e-04  2e-13
11: -3.4180e+00 -2.6286e+01  3e+01  6e-05  3e-13
12: -4.9280e+00 -1.9048e+01  1e+01  2e-06  3e-13
13: -6.5896e+00 -1.5336e+01  9e+00  1e-06  3e-13
14: -7.3449e+00 -1.3565e+01  6e+00  2e-07  3e-13
15: -8.8346e+00 -1.0802e+01  2e+00  4e-14  4e-13
16: -9.2995e+00 -1.0123e+01  8e-01  6e-14  3e-13
17: -9.5362e+00 -9.8093e+00  3e-01  3e-14  4e-13
18: -9.6642e+00 -9.6722e+00  8e-03  5e-14  4e-13
19: -9.6680e+00 -9.6681e+00  9e-05  7e-14  4e-13
20: -9.6680e+00 -9.6680e+00  9e-07  3e-14  4e-13
Optimal solution found.
sv_indices: [17, 345, 418, 499, 529, 654, 715, 764, 1074, 1110, 1149, 1183, 1340, 1372, 1506, 1539, 1806, 1848, 1911, 2100, 2159, 2260, 2368, 2465, 2488, 2510, 2619, 2636, 2663, 2712, 3025, 3068, 3331, 3439, 3615, 3626, 3711, 3745, 3746, 3832, 3918, 4162, 4261, 4287, 4339, 4399, 4434, 4537, 4843, 4876, 4949, 5017, 5155, 5157, 5216, 5260, 5615, 5677, 5755, 5924, 5928, 6041, 6043, 6046, 6305, 6307, 6314, 6537, 6616, 6671, 6680, 6871, 6981, 7080, 7168, 7179, 7187, 7296, 7356, 7363, 7429, 7556, 7560, 7575, 7605, 7772, 7835, 7836, 7898, 7903, 7944, 7952, 7982, 8087, 8220, 8290, 8299, 8314, 8340, 8531, 8554, 8597, 8697, 8718, 8749, 8799, 8865, 8871, 8975, 9065, 9135, 9190, 9224, 9255, 9309, 9367, 9376, 9470, 9497, 9702, 9764, 9896, 10089, 10269, 10285, 10363]
126 SVs (with labels):
Training time for 1.0-vs-6.0: 629.158419132 seconds
Begin training classifier for label 1.0 and label 7.0 at 2016-05-20, 00:07:53
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10848, 784) (10848,)
(10848, 784) (10848,)
     pcost       dcost       gap    pres   dres
 0: -6.2018e+02 -2.2928e+04  1e+05  3e+00  7e-12
 1: -3.8244e+02 -1.2975e+04  3e+04  4e-01  6e-12
 2: -2.2734e+02 -5.5143e+03  9e+03  1e-01  4e-12
 3: -1.5736e+02 -3.3114e+03  6e+03  7e-02  3e-12
 4: -1.0232e+02 -1.9976e+03  3e+03  4e-02  2e-12
 5: -6.9004e+01 -1.3303e+03  2e+03  2e-02  2e-12
 6: -4.4095e+01 -9.0153e+02  1e+03  1e-02  1e-12
 7: -2.8988e+01 -6.1813e+02  9e+02  7e-03  9e-13
 8: -2.0564e+01 -3.9390e+02  6e+02  4e-03  8e-13
 9: -1.5720e+01 -2.5286e+02  3e+02  2e-03  7e-13
10: -1.6139e+01 -1.3655e+02  2e+02  7e-04  7e-13
11: -1.9826e+01 -7.7899e+01  7e+01  2e-04  7e-13
12: -2.2856e+01 -6.1744e+01  4e+01  6e-05  7e-13
13: -2.4980e+01 -5.0534e+01  3e+01  6e-14  8e-13
14: -2.9140e+01 -4.2721e+01  1e+01  2e-14  7e-13
15: -3.2395e+01 -3.6718e+01  4e+00  1e-13  9e-13
16: -3.3471e+01 -3.5072e+01  2e+00  2e-13  9e-13
17: -3.4064e+01 -3.4367e+01  3e-01  2e-13  9e-13
18: -3.4208e+01 -3.4213e+01  4e-03  5e-14  9e-13
19: -3.4210e+01 -3.4210e+01  5e-05  4e-14  9e-13
20: -3.4210e+01 -3.4210e+01  6e-07  2e-13  9e-13
Optimal solution found.
sv_indices: [6, 10, 53, 62, 163, 178, 397, 454, 527, 574, 644, 784, 843, 1155, 1273, 1287, 1290, 1425, 1488, 1506, 1593, 1642, 1940, 2122, 2159, 2182, 2250, 2283, 2347, 2428, 2460, 2465, 2522, 2561, 2660, 2675, 2862, 2883, 2901, 2943, 3141, 3189, 3223, 3248, 3348, 3499, 3626, 3745, 3832, 3863, 3944, 4168, 4176, 4182, 4198, 4244, 4253, 4306, 4416, 4431, 4435, 4565, 4755, 4810, 4854, 4876, 4977, 5107, 5216, 5387, 5457, 5474, 5499, 5590, 5774, 5863, 5918, 5945, 6070, 6095, 6251, 6267, 6284, 6405, 6471, 6479, 6550, 6556, 6619, 6652, 6724, 6730, 6761, 6923, 6960, 6974, 7204, 7228, 7257, 7273, 7290, 7339, 7380, 7384, 7446, 7502, 7631, 7666, 7737, 7852, 8065, 8128, 8308, 8351, 8376, 8379, 8422, 8444, 8463, 8525, 8539, 8551, 8557, 8572, 8620, 8621, 8631, 8659, 8715, 8716, 8787, 8835, 8871, 8947, 8986, 9089, 9119, 9138, 9369, 9409, 9555, 9692, 9695, 9704, 9756, 9775, 9808, 9834, 9846, 9910, 9928, 10081, 10196, 10241, 10253, 10311, 10322, 10370, 10376, 10652, 10672, 10712, 10749, 10800, 10814]
165 SVs (with labels):
Training time for 1.0-vs-7.0: 744.00991106 seconds
Begin training classifier for label 1.0 and label 8.0 at 2016-05-20, 00:20:18
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10460, 784) (10460,)
(10460, 784) (10460,)
     pcost       dcost       gap    pres   dres
 0: -1.4650e+03 -2.2892e+04  1e+05  3e+00  3e-11
 1: -9.4467e+02 -1.3803e+04  3e+04  5e-01  2e-11
 2: -6.5927e+02 -7.3286e+03  1e+04  2e-01  1e-11
 3: -5.1409e+02 -4.7002e+03  8e+03  1e-01  1e-11
 4: -3.8960e+02 -3.0651e+03  5e+03  7e-02  8e-12
 5: -2.9996e+02 -2.1086e+03  3e+03  4e-02  6e-12
 6: -2.3640e+02 -1.6050e+03  2e+03  2e-02  5e-12
 7: -1.8899e+02 -1.2405e+03  2e+03  1e-02  4e-12
 8: -1.6199e+02 -9.4422e+02  1e+03  9e-03  4e-12
 9: -1.4279e+02 -6.2254e+02  7e+02  4e-03  4e-12
10: -1.3752e+02 -3.4078e+02  2e+02  4e-04  4e-12
11: -1.4981e+02 -2.8528e+02  1e+02  1e-04  4e-12
12: -1.6172e+02 -2.4430e+02  8e+01  3e-05  4e-12
13: -1.7054e+02 -2.2419e+02  5e+01  1e-05  4e-12
14: -1.7433e+02 -2.1289e+02  4e+01  3e-06  4e-12
15: -1.8226e+02 -1.9988e+02  2e+01  1e-06  4e-12
16: -1.8617e+02 -1.9292e+02  7e+00  3e-10  5e-12
17: -1.8797e+02 -1.9069e+02  3e+00  7e-12  5e-12
18: -1.8908e+02 -1.8946e+02  4e-01  2e-13  5e-12
19: -1.8926e+02 -1.8927e+02  9e-03  2e-13  5e-12
20: -1.8926e+02 -1.8926e+02  2e-04  2e-13  5e-12
21: -1.8926e+02 -1.8926e+02  2e-06  2e-13  5e-12
Optimal solution found.
sv_indices: [26, 35, 36, 74, 91, 98, 143, 261, 295, 350, 351, 365, 371, 397, 418, 454, 520, 608, 637, 654, 705, 707, 715, 764, 766, 767, 788, 794, 948, 990, 1002, 1013, 1019, 1020, 1067, 1087, 1140, 1340, 1371, 1376, 1410, 1441, 1467, 1502, 1506, 1511, 1525, 1532, 1534, 1536, 1546, 1593, 1623, 1642, 1659, 1673, 1728, 1746, 1752, 1777, 1796, 1801, 1807, 1840, 1845, 1848, 1900, 2003, 2008, 2021, 2055, 2060, 2078, 2119, 2161, 2164, 2271, 2337, 2354, 2368, 2372, 2399, 2415, 2417, 2449, 2510, 2589, 2635, 2659, 2660, 2675, 2712, 2743, 2744, 2785, 2831, 2880, 2901, 2943, 2945, 2970, 3025, 3084, 3141, 3160, 3192, 3202, 3374, 3392, 3405, 3424, 3597, 3609, 3615, 3626, 3660, 3746, 3776, 3777, 3782, 3789, 3806, 3812, 3832, 3853, 3981, 3983, 4005, 4071, 4075, 4112, 4113, 4182, 4258, 4261, 4347, 4365, 4376, 4398, 4434, 4435, 4469, 4493, 4537, 4540, 4654, 4658, 4690, 4720, 4724, 4741, 4763, 4810, 4876, 4949, 4961, 4965, 5017, 5107, 5129, 5144, 5151, 5155, 5161, 5216, 5217, 5248, 5259, 5295, 5317, 5385, 5387, 5517, 5654, 5688, 5712, 5749, 5753, 5766, 5777, 5799, 5859, 5874, 5903, 5912, 5921, 5932, 5942, 5962, 6026, 6054, 6096, 6103, 6127, 6169, 6228, 6244, 6259, 6296, 6314, 6332, 6340, 6342, 6369, 6372, 6382, 6387, 6402, 6422, 6437, 6463, 6484, 6491, 6501, 6512, 6530, 6539, 6552, 6563, 6607, 6655, 6686, 6706, 6749, 6781, 6784, 6844, 6865, 6944, 6945, 6946, 6962, 6963, 6995, 7030, 7051, 7079, 7098, 7123, 7155, 7161, 7162, 7170, 7195, 7264, 7276, 7364, 7462, 7481, 7524, 7545, 7582, 7598, 7632, 7657, 7694, 7701, 7710, 7713, 7728, 7736, 7750, 7777, 7781, 7810, 7819, 7838, 7851, 7865, 7909, 7944, 7980, 8013, 8033, 8048, 8080, 8108, 8110, 8135, 8137, 8185, 8198, 8206, 8224, 8236, 8268, 8269, 8284, 8302, 8322, 8425, 8436, 8454, 8472, 8489, 8535, 8567, 8571, 8594, 8603, 8605, 8629, 8653, 8677, 8715, 8726, 8728, 8791, 8811, 8812, 8833, 8835, 8849, 8870, 8915, 8940, 8950, 8995, 9028, 9044, 9071, 9076, 9079, 9117, 9137, 9216, 9242, 9279, 9304, 9397, 9405, 9411, 9412, 9422, 9431, 9443, 9450, 9491, 9492, 9504, 9506, 9597, 9598, 9613, 9644, 9647, 9668, 9682, 9693, 9733, 9810, 9831, 9893, 9923, 9955, 9996, 10047, 10056, 10088, 10098, 10103, 10117, 10146, 10147, 10159, 10162, 10174, 10199, 10207, 10220, 10228, 10289, 10295, 10313, 10315, 10340, 10356, 10363, 10428, 10457]
380 SVs (with labels):
Training time for 1.0-vs-8.0: 638.630812168 seconds
Begin training classifier for label 1.0 and label 9.0 at 2016-05-20, 00:30:56
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10627, 784) (10627,)
(10627, 784) (10627,)
     pcost       dcost       gap    pres   dres
 0: -4.5940e+02 -2.4582e+04  2e+05  3e+00  5e-12
 1: -2.8094e+02 -1.4259e+04  3e+04  4e-01  5e-12
 2: -1.4890e+02 -4.7589e+03  8e+03  1e-01  3e-12
 3: -8.8106e+01 -1.8202e+03  3e+03  4e-02  2e-12
 4: -6.0801e+01 -1.0427e+03  2e+03  2e-02  1e-12
 5: -4.2152e+01 -7.6682e+02  1e+03  1e-02  1e-12
 6: -2.8090e+01 -4.0993e+02  6e+02  5e-03  9e-13
 7: -2.1462e+01 -2.4526e+02  3e+02  2e-03  7e-13
 8: -2.1773e+01 -1.2246e+02  1e+02  8e-04  7e-13
 9: -1.9049e+01 -9.6984e+01  9e+01  4e-04  7e-13
10: -2.3668e+01 -6.6781e+01  5e+01  2e-04  7e-13
11: -2.6251e+01 -5.1566e+01  3e+01  3e-05  8e-13
12: -2.8909e+01 -4.4008e+01  2e+01  1e-05  8e-13
13: -3.0844e+01 -3.9312e+01  9e+00  3e-06  8e-13
14: -3.2446e+01 -3.6126e+01  4e+00  8e-08  9e-13
15: -3.3236e+01 -3.4966e+01  2e+00  9e-09  9e-13
16: -3.3855e+01 -3.4201e+01  3e-01  9e-14  1e-12
17: -3.3985e+01 -3.4058e+01  7e-02  1e-13  1e-12
18: -3.4020e+01 -3.4022e+01  2e-03  5e-14  1e-12
19: -3.4021e+01 -3.4021e+01  3e-05  6e-14  1e-12
Optimal solution found.
sv_indices: [6, 10, 17, 36, 115, 163, 178, 454, 527, 608, 649, 677, 684, 703, 705, 724, 764, 788, 791, 799, 1087, 1178, 1186, 1287, 1340, 1441, 1488, 1506, 1593, 1631, 1642, 1673, 1738, 1753, 1777, 1801, 2122, 2164, 2266, 2347, 2465, 2660, 2902, 2915, 2943, 2945, 3053, 3166, 3230, 3411, 3613, 3694, 3745, 3789, 3821, 3832, 3863, 3903, 4112, 4176, 4182, 4244, 4253, 4416, 4434, 4435, 4537, 4565, 4697, 4854, 4876, 4949, 4977, 5050, 5069, 5107, 5166, 5214, 5216, 5235, 5360, 5590, 5658, 5703, 5843, 5886, 5914, 6026, 6072, 6163, 6221, 6287, 6326, 6392, 6452, 6487, 6678, 6682, 6706, 6764, 6770, 6887, 6974, 7039, 7098, 7149, 7219, 7230, 7291, 7394, 7431, 7507, 7515, 7548, 7601, 7626, 7650, 7751, 7766, 7796, 8009, 8110, 8121, 8190, 8207, 8213, 8225, 8235, 8273, 8298, 8334, 8350, 8409, 8539, 8615, 8622, 8740, 8746, 8851, 8861, 8931, 9008, 9035, 9072, 9099, 9122, 9170, 9267, 9306, 9484, 9502, 9513, 9551, 9563, 9591, 9682, 9718, 9915, 10013, 10041, 10150, 10214, 10257, 10295, 10441, 10509, 10590, 10606]
168 SVs (with labels):
Training time for 1.0-vs-9.0: 614.619117975 seconds
Begin training classifier for label 2.0 and label 3.0 at 2016-05-20, 00:41:11
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10043, 784) (10043,)
(10043, 784) (10043,)
     pcost       dcost       gap    pres   dres
 0: -1.6797e+03 -2.5701e+04  2e+05  3e+00  4e-11
 1: -1.0713e+03 -1.6104e+04  3e+04  5e-01  3e-11
 2: -7.2402e+02 -5.9078e+03  9e+03  1e-01  2e-11
 3: -5.6169e+02 -3.1775e+03  5e+03  6e-02  2e-11
 4: -4.5730e+02 -1.7537e+03  2e+03  3e-02  1e-11
 5: -3.9914e+02 -1.0307e+03  1e+03  1e-02  1e-11
 6: -3.9058e+02 -6.2203e+02  3e+02  2e-03  1e-11
 7: -4.0008e+02 -4.9430e+02  1e+02  3e-04  1e-11
 8: -4.1005e+02 -4.6309e+02  6e+01  1e-04  1e-11
 9: -4.1906e+02 -4.4450e+02  3e+01  3e-05  1e-11
10: -4.2342e+02 -4.3667e+02  1e+01  1e-05  1e-11
11: -4.2652e+02 -4.3127e+02  5e+00  2e-12  1e-11
12: -4.2818e+02 -4.2937e+02  1e+00  1e-12  1e-11
13: -4.2868e+02 -4.2881e+02  1e-01  1e-12  1e-11
14: -4.2874e+02 -4.2874e+02  6e-03  8e-15  1e-11
15: -4.2874e+02 -4.2874e+02  1e-04  9e-13  1e-11
Optimal solution found.
sv_indices: [6, 21, 23, 38, 81, 108, 112, 119, 127, 140, 149, 171, 191, 212, 225, 237, 272, 275, 277, 299, 327, 342, 343, 363, 380, 404, 411, 420, 430, 471, 485, 509, 536, 560, 567, 583, 592, 634, 644, 667, 693, 700, 740, 762, 770, 774, 789, 813, 819, 826, 829, 847, 851, 852, 860, 863, 866, 896, 933, 943, 965, 969, 972, 977, 1005, 1015, 1018, 1052, 1088, 1102, 1110, 1130, 1133, 1140, 1188, 1200, 1205, 1235, 1245, 1298, 1313, 1318, 1321, 1334, 1339, 1342, 1370, 1383, 1397, 1402, 1412, 1424, 1426, 1429, 1443, 1455, 1461, 1484, 1497, 1512, 1527, 1535, 1542, 1543, 1561, 1563, 1574, 1575, 1598, 1645, 1691, 1715, 1716, 1736, 1756, 1763, 1769, 1778, 1785, 1787, 1789, 1799, 1823, 1851, 1856, 1868, 1870, 1887, 1927, 1931, 1933, 1959, 1967, 1973, 1983, 2010, 2027, 2029, 2038, 2040, 2057, 2059, 2060, 2062, 2079, 2087, 2100, 2120, 2134, 2138, 2148, 2149, 2177, 2198, 2201, 2208, 2222, 2226, 2234, 2247, 2248, 2255, 2264, 2265, 2266, 2297, 2299, 2317, 2335, 2360, 2366, 2373, 2382, 2387, 2397, 2416, 2427, 2430, 2437, 2456, 2464, 2467, 2475, 2480, 2487, 2500, 2509, 2533, 2536, 2556, 2567, 2586, 2608, 2609, 2628, 2672, 2685, 2700, 2702, 2731, 2769, 2805, 2824, 2852, 2853, 2856, 2872, 2895, 2899, 2902, 2918, 2949, 2977, 2986, 2989, 3019, 3022, 3038, 3058, 3068, 3105, 3123, 3129, 3134, 3142, 3146, 3151, 3172, 3188, 3189, 3191, 3220, 3225, 3249, 3258, 3273, 3281, 3297, 3306, 3308, 3322, 3359, 3366, 3384, 3394, 3417, 3425, 3428, 3449, 3454, 3474, 3559, 3563, 3577, 3591, 3593, 3654, 3658, 3661, 3672, 3674, 3678, 3694, 3702, 3717, 3718, 3764, 3780, 3782, 3789, 3791, 3811, 3836, 3844, 3869, 3876, 3878, 3902, 3905, 3926, 3939, 3948, 3984, 3999, 4005, 4086, 4121, 4125, 4145, 4152, 4155, 4173, 4185, 4196, 4205, 4252, 4254, 4307, 4310, 4326, 4335, 4361, 4376, 4378, 4385, 4386, 4391, 4400, 4404, 4405, 4418, 4422, 4445, 4459, 4477, 4480, 4487, 4507, 4517, 4520, 4521, 4535, 4561, 4563, 4593, 4594, 4599, 4658, 4664, 4672, 4674, 4677, 4694, 4707, 4708, 4717, 4718, 4724, 4733, 4765, 4774, 4783, 4794, 4805, 4818, 4825, 4841, 4859, 4864, 4869, 4885, 4919, 4931, 4954, 4967, 5005, 5013, 5025, 5028, 5123, 5138, 5143, 5171, 5196, 5200, 5247, 5254, 5262, 5367, 5425, 5457, 5483, 5505, 5506, 5526, 5598, 5600, 5603, 5605, 5608, 5621, 5650, 5656, 5713, 5724, 5748, 5773, 5796, 5803, 5818, 5839, 5857, 5870, 5873, 5885, 5926, 5928, 5996, 6017, 6029, 6030, 6041, 6052, 6058, 6073, 6088, 6097, 6104, 6111, 6129, 6141, 6144, 6149, 6209, 6212, 6233, 6242, 6248, 6268, 6273, 6276, 6301, 6323, 6331, 6336, 6352, 6354, 6360, 6362, 6377, 6391, 6448, 6466, 6468, 6495, 6496, 6500, 6502, 6526, 6537, 6546, 6618, 6627, 6628, 6675, 6684, 6686, 6692, 6695, 6736, 6740, 6742, 6767, 6775, 6806, 6869, 6887, 6899, 6932, 6942, 6965, 6975, 6978, 6979, 6985, 7010, 7013, 7015, 7044, 7063, 7068, 7084, 7091, 7100, 7116, 7172, 7175, 7180, 7191, 7192, 7220, 7234, 7244, 7255, 7259, 7271, 7279, 7286, 7301, 7302, 7305, 7306, 7321, 7332, 7359, 7365, 7372, 7378, 7407, 7411, 7428, 7429, 7447, 7458, 7467, 7478, 7508, 7510, 7512, 7554, 7580, 7597, 7621, 7643, 7674, 7684, 7722, 7761, 7820, 7853, 7869, 7871, 7875, 7880, 7882, 7891, 7894, 7911, 7916, 7927, 7936, 7941, 7978, 7981, 7993, 8029, 8096, 8113, 8121, 8122, 8145, 8147, 8148, 8156, 8189, 8209, 8221, 8225, 8229, 8240, 8247, 8250, 8256, 8258, 8281, 8299, 8303, 8335, 8343, 8351, 8365, 8369, 8373, 8374, 8379, 8381, 8386, 8407, 8414, 8417, 8429, 8437, 8453, 8460, 8488, 8490, 8491, 8497, 8530, 8548, 8570, 8576, 8605, 8635, 8637, 8647, 8652, 8653, 8654, 8670, 8700, 8751, 8765, 8781, 8788, 8842, 8848, 8857, 8888, 8894, 8901, 8919, 8928, 8933, 8964, 8986, 8989, 9046, 9047, 9064, 9088, 9111, 9115, 9118, 9132, 9193, 9196, 9198, 9207, 9210, 9214, 9218, 9230, 9235, 9241, 9243, 9250, 9257, 9279, 9310, 9313, 9323, 9327, 9341, 9374, 9381, 9411, 9417, 9433, 9496, 9510, 9542, 9544, 9548, 9610, 9618, 9646, 9653, 9662, 9663, 9671, 9689, 9696, 9704, 9730, 9743, 9758, 9760, 9769, 9772, 9785, 9805, 9812, 9824, 9831, 9853, 9860, 9862, 9881, 9886, 9890, 9891, 9893, 9901, 9905, 9919, 9957, 9959, 9962, 9964, 10000, 10006, 10010, 10011, 10033, 10036]
686 SVs (with labels):
Training time for 2.0-vs-3.0: 416.267652988 seconds
Begin training classifier for label 2.0 and label 4.0 at 2016-05-20, 00:48:07
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9845, 784) (9845,)
(9845, 784) (9845,)
     pcost       dcost       gap    pres   dres
 0: -1.1719e+03 -2.4503e+04  2e+05  3e+00  2e-11
 1: -7.2090e+02 -1.5135e+04  3e+04  5e-01  2e-11
 2: -4.2578e+02 -5.6585e+03  9e+03  1e-01  1e-11
 3: -2.9471e+02 -3.0036e+03  5e+03  7e-02  7e-12
 4: -2.1504e+02 -1.7458e+03  3e+03  3e-02  5e-12
 5: -1.6700e+02 -1.0189e+03  1e+03  2e-02  4e-12
 6: -1.3558e+02 -5.8350e+02  7e+02  6e-03  3e-12
 7: -1.2151e+02 -3.8792e+02  4e+02  3e-03  3e-12
 8: -1.2605e+02 -2.3082e+02  1e+02  7e-04  3e-12
 9: -1.2431e+02 -1.9698e+02  8e+01  1e-04  3e-12
10: -1.3694e+02 -1.6913e+02  3e+01  3e-05  3e-12
11: -1.4254e+02 -1.5704e+02  1e+01  5e-06  4e-12
12: -1.4588e+02 -1.5154e+02  6e+00  1e-07  4e-12
13: -1.4809e+02 -1.4882e+02  7e-01  1e-08  4e-12
14: -1.4841e+02 -1.4844e+02  3e-02  4e-10  4e-12
15: -1.4843e+02 -1.4843e+02  5e-04  7e-12  4e-12
16: -1.4843e+02 -1.4843e+02  6e-06  2e-13  4e-12
Optimal solution found.
sv_indices: [6, 32, 85, 112, 116, 140, 240, 245, 264, 272, 284, 316, 319, 324, 362, 377, 448, 493, 497, 500, 507, 548, 556, 579, 583, 619, 663, 668, 700, 706, 708, 714, 740, 749, 773, 793, 806, 813, 896, 926, 972, 977, 1018, 1052, 1058, 1137, 1157, 1170, 1179, 1214, 1283, 1301, 1356, 1366, 1421, 1429, 1471, 1497, 1518, 1551, 1556, 1577, 1598, 1617, 1657, 1666, 1691, 1735, 1740, 1746, 1752, 1763, 1770, 1798, 1841, 1850, 1862, 1930, 1938, 1948, 1965, 1997, 2010, 2027, 2038, 2049, 2062, 2240, 2248, 2259, 2266, 2340, 2360, 2375, 2386, 2405, 2439, 2487, 2496, 2539, 2541, 2556, 2576, 2609, 2614, 2650, 2715, 2755, 2808, 2824, 2835, 2895, 2899, 2918, 2921, 2928, 2986, 3022, 3056, 3070, 3107, 3132, 3142, 3166, 3220, 3225, 3246, 3281, 3322, 3324, 3342, 3376, 3378, 3392, 3494, 3510, 3604, 3678, 3693, 3715, 3738, 3764, 3780, 3792, 3806, 3849, 3851, 3854, 3895, 3905, 3938, 3940, 3990, 3996, 4106, 4125, 4170, 4173, 4181, 4196, 4217, 4258, 4320, 4335, 4359, 4391, 4397, 4400, 4405, 4459, 4480, 4485, 4535, 4581, 4585, 4593, 4617, 4644, 4708, 4761, 4765, 4774, 4775, 4797, 4805, 4859, 4885, 4893, 4919, 4922, 4931, 4974, 5009, 5043, 5055, 5063, 5088, 5089, 5091, 5095, 5107, 5111, 5176, 5201, 5207, 5208, 5229, 5269, 5300, 5305, 5345, 5371, 5372, 5374, 5382, 5422, 5429, 5455, 5476, 5479, 5497, 5507, 5554, 5561, 5580, 5667, 5691, 5727, 5749, 5766, 5793, 5803, 5812, 5816, 5855, 5864, 5879, 5880, 5896, 5927, 5945, 5966, 5968, 5985, 6008, 6073, 6098, 6103, 6204, 6241, 6339, 6347, 6384, 6389, 6415, 6423, 6425, 6426, 6457, 6467, 6470, 6479, 6531, 6550, 6587, 6612, 6620, 6640, 6650, 6679, 6700, 6738, 6764, 6776, 6835, 6843, 6857, 6878, 6880, 6917, 6988, 7048, 7072, 7145, 7184, 7198, 7205, 7207, 7215, 7236, 7238, 7284, 7285, 7296, 7439, 7442, 7449, 7462, 7515, 7517, 7526, 7528, 7541, 7592, 7639, 7653, 7683, 7688, 7717, 7721, 7735, 7768, 7775, 7782, 7795, 7805, 7824, 7834, 7915, 7922, 7954, 7984, 7992, 8012, 8025, 8051, 8062, 8065, 8076, 8084, 8099, 8100, 8126, 8127, 8129, 8141, 8152, 8153, 8171, 8175, 8243, 8267, 8304, 8383, 8388, 8422, 8453, 8464, 8493, 8511, 8537, 8584, 8588, 8694, 8747, 8807, 8815, 8833, 8842, 8875, 8882, 8886, 8905, 8906, 8949, 8955, 8985, 8986, 9028, 9036, 9078, 9147, 9160, 9178, 9179, 9200, 9219, 9266, 9292, 9311, 9332, 9414, 9489, 9498, 9544, 9557, 9576, 9628, 9687, 9702, 9750, 9759, 9772, 9820]
394 SVs (with labels):
Training time for 2.0-vs-4.0: 434.206374884 seconds
Begin training classifier for label 2.0 and label 5.0 at 2016-05-20, 00:55:22
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9505, 784) (9505,)
(9505, 784) (9505,)
     pcost       dcost       gap    pres   dres
 0: -1.3215e+03 -2.2890e+04  1e+05  3e+00  2e-11
 1: -8.2361e+02 -1.4000e+04  3e+04  5e-01  2e-11
 2: -5.0203e+02 -5.1297e+03  8e+03  1e-01  1e-11
 3: -3.5719e+02 -2.7880e+03  4e+03  7e-02  8e-12
 4: -2.5769e+02 -1.5614e+03  2e+03  3e-02  6e-12
 5: -2.1339e+02 -1.1300e+03  2e+03  2e-02  5e-12
 6: -1.7430e+02 -7.7392e+02  1e+03  1e-02  4e-12
 7: -1.5448e+02 -3.8813e+02  4e+02  3e-03  4e-12
 8: -1.5369e+02 -2.1258e+02  7e+01  3e-04  4e-12
 9: -1.6179e+02 -1.8562e+02  3e+01  5e-05  4e-12
10: -1.6564e+02 -1.7752e+02  1e+01  2e-05  4e-12
11: -1.6824e+02 -1.7233e+02  4e+00  8e-13  5e-12
12: -1.6978e+02 -1.7053e+02  8e-01  6e-13  4e-12
13: -1.7013e+02 -1.7014e+02  2e-02  2e-14  5e-12
14: -1.7013e+02 -1.7013e+02  3e-04  6e-13  5e-12
15: -1.7013e+02 -1.7013e+02  4e-06  2e-13  5e-12
Optimal solution found.
sv_indices: [6, 54, 90, 91, 110, 112, 116, 192, 228, 254, 264, 272, 273, 277, 349, 371, 448, 485, 490, 511, 538, 583, 625, 628, 634, 663, 667, 673, 704, 708, 718, 722, 740, 770, 773, 784, 793, 806, 817, 819, 829, 847, 849, 996, 1007, 1018, 1052, 1110, 1120, 1130, 1179, 1214, 1223, 1245, 1261, 1268, 1298, 1369, 1397, 1406, 1429, 1480, 1495, 1512, 1518, 1534, 1535, 1551, 1556, 1564, 1577, 1600, 1607, 1634, 1639, 1669, 1712, 1714, 1716, 1735, 1736, 1763, 1785, 1799, 1800, 1838, 1857, 1858, 1862, 1910, 1930, 1933, 1963, 1973, 1989, 2010, 2027, 2038, 2048, 2049, 2137, 2140, 2194, 2201, 2230, 2241, 2255, 2259, 2265, 2281, 2294, 2379, 2381, 2386, 2397, 2418, 2474, 2475, 2496, 2498, 2618, 2677, 2685, 2700, 2702, 2774, 2808, 2824, 2832, 2872, 2886, 2899, 2900, 2915, 2925, 2958, 2986, 2998, 3019, 3037, 3070, 3123, 3142, 3188, 3225, 3297, 3313, 3317, 3324, 3357, 3366, 3378, 3429, 3494, 3540, 3545, 3586, 3665, 3677, 3678, 3703, 3717, 3746, 3759, 3780, 3792, 3806, 3836, 3844, 3895, 3898, 3905, 3926, 3938, 3940, 3948, 3976, 3990, 4002, 4106, 4121, 4125, 4170, 4173, 4196, 4198, 4225, 4239, 4258, 4335, 4361, 4376, 4389, 4400, 4428, 4436, 4485, 4502, 4512, 4555, 4563, 4581, 4593, 4654, 4656, 4694, 4707, 4708, 4713, 4735, 4737, 4761, 4765, 4783, 4787, 4794, 4817, 4825, 4919, 4931, 4952, 4957, 5007, 5014, 5052, 5053, 5066, 5070, 5090, 5094, 5096, 5128, 5139, 5152, 5159, 5161, 5168, 5204, 5214, 5246, 5276, 5277, 5318, 5330, 5382, 5511, 5568, 5584, 5627, 5636, 5650, 5667, 5687, 5701, 5721, 5737, 5765, 5787, 5793, 5839, 5859, 5864, 5907, 5932, 5933, 5950, 5978, 6009, 6065, 6074, 6083, 6099, 6102, 6105, 6185, 6211, 6232, 6238, 6293, 6331, 6332, 6337, 6361, 6379, 6421, 6436, 6439, 6489, 6493, 6505, 6540, 6557, 6562, 6571, 6588, 6594, 6599, 6670, 6698, 6712, 6722, 6725, 6747, 6763, 6784, 6791, 6795, 6801, 6835, 6839, 6842, 6861, 6918, 6945, 6949, 7003, 7012, 7019, 7052, 7137, 7177, 7233, 7259, 7273, 7294, 7303, 7305, 7321, 7341, 7345, 7385, 7386, 7405, 7423, 7437, 7463, 7480, 7492, 7502, 7552, 7563, 7571, 7592, 7594, 7620, 7661, 7663, 7673, 7683, 7693, 7702, 7736, 7835, 7842, 7854, 7864, 7898, 7906, 7913, 7919, 7942, 7946, 7956, 7971, 7994, 8028, 8034, 8065, 8071, 8100, 8156, 8168, 8186, 8199, 8214, 8230, 8237, 8240, 8244, 8249, 8262, 8263, 8274, 8277, 8282, 8284, 8361, 8431, 8436, 8458, 8464, 8469, 8540, 8546, 8562, 8584, 8591, 8613, 8638, 8657, 8691, 8766, 8772, 8784, 8819, 8820, 8886, 8900, 8979, 8990, 9013, 9039, 9058, 9064, 9082, 9103, 9140, 9153, 9162, 9327, 9330, 9332, 9355, 9372, 9390, 9398, 9410, 9417, 9443, 9444, 9453, 9455, 9499, 9501]
434 SVs (with labels):
Training time for 2.0-vs-5.0: 366.429894924 seconds
Begin training classifier for label 2.0 and label 6.0 at 2016-05-20, 01:01:28
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9917, 784) (9917,)
(9917, 784) (9917,)
     pcost       dcost       gap    pres   dres
 0: -1.2530e+03 -2.7279e+04  2e+05  4e+00  2e-11
 1: -7.7454e+02 -1.7593e+04  4e+04  6e-01  2e-11
 2: -4.6497e+02 -6.5925e+03  1e+04  2e-01  1e-11
 3: -3.1662e+02 -3.5156e+03  6e+03  7e-02  8e-12
 4: -2.3224e+02 -2.3149e+03  4e+03  4e-02  6e-12
 5: -1.7728e+02 -1.3689e+03  2e+03  2e-02  5e-12
 6: -1.3810e+02 -1.0407e+03  1e+03  1e-02  4e-12
 7: -1.1901e+02 -6.3037e+02  7e+02  5e-03  4e-12
 8: -1.2306e+02 -3.3231e+02  3e+02  1e-03  4e-12
 9: -1.2538e+02 -2.6719e+02  2e+02  4e-04  4e-12
10: -1.3838e+02 -2.1696e+02  8e+01  1e-04  4e-12
11: -1.4461e+02 -1.9524e+02  5e+01  3e-05  4e-12
12: -1.5327e+02 -1.7700e+02  2e+01  8e-06  4e-12
13: -1.5736e+02 -1.6939e+02  1e+01  1e-06  5e-12
14: -1.6101e+02 -1.6435e+02  3e+00  2e-07  5e-12
15: -1.6225e+02 -1.6278e+02  5e-01  1e-08  5e-12
16: -1.6249e+02 -1.6251e+02  2e-02  3e-10  5e-12
17: -1.6250e+02 -1.6250e+02  3e-04  4e-12  5e-12
18: -1.6250e+02 -1.6250e+02  4e-06  2e-13  5e-12
Optimal solution found.
sv_indices: [28, 30, 54, 59, 85, 91, 112, 131, 140, 272, 277, 298, 316, 322, 341, 350, 404, 419, 448, 493, 497, 537, 538, 556, 612, 628, 668, 704, 708, 714, 770, 773, 784, 794, 802, 806, 836, 847, 849, 896, 953, 971, 1003, 1014, 1034, 1058, 1074, 1110, 1130, 1142, 1152, 1179, 1181, 1208, 1214, 1245, 1339, 1356, 1480, 1518, 1527, 1534, 1539, 1551, 1556, 1567, 1577, 1657, 1669, 1702, 1712, 1735, 1775, 1784, 1798, 1799, 1862, 1907, 1966, 1996, 1997, 2057, 2061, 2149, 2172, 2228, 2240, 2248, 2259, 2264, 2295, 2343, 2360, 2366, 2373, 2379, 2386, 2397, 2405, 2428, 2459, 2487, 2496, 2498, 2576, 2618, 2685, 2715, 2808, 2824, 2849, 2872, 2895, 2899, 2900, 2916, 2928, 2958, 2986, 2992, 3022, 3037, 3166, 3191, 3195, 3250, 3256, 3313, 3324, 3352, 3366, 3414, 3532, 3586, 3665, 3678, 3686, 3703, 3712, 3720, 3724, 3758, 3761, 3764, 3770, 3780, 3783, 3802, 3866, 3868, 3895, 3923, 3938, 3940, 3947, 3978, 3989, 4006, 4064, 4106, 4117, 4121, 4170, 4173, 4198, 4203, 4225, 4230, 4239, 4245, 4252, 4270, 4313, 4320, 4323, 4335, 4395, 4436, 4459, 4480, 4488, 4491, 4555, 4558, 4571, 4581, 4585, 4618, 4654, 4667, 4678, 4707, 4761, 4765, 4766, 4787, 4853, 4869, 4952, 4974, 5015, 5017, 5018, 5033, 5101, 5140, 5157, 5165, 5177, 5182, 5203, 5206, 5309, 5313, 5348, 5365, 5456, 5462, 5492, 5513, 5518, 5604, 5606, 5607, 5641, 5663, 5690, 5697, 5699, 5721, 5742, 5793, 5805, 5839, 5841, 5852, 5880, 5912, 5933, 5936, 5942, 5980, 6014, 6040, 6046, 6055, 6056, 6065, 6143, 6149, 6183, 6223, 6242, 6310, 6314, 6322, 6351, 6369, 6384, 6405, 6441, 6509, 6538, 6564, 6588, 6599, 6612, 6654, 6688, 6691, 6735, 6741, 6745, 6748, 6824, 6871, 6878, 6897, 6900, 6941, 6945, 6953, 6957, 6983, 6986, 6990, 7052, 7074, 7101, 7102, 7109, 7131, 7157, 7167, 7221, 7225, 7270, 7322, 7323, 7324, 7329, 7346, 7350, 7367, 7372, 7403, 7412, 7468, 7472, 7493, 7496, 7534, 7598, 7605, 7643, 7649, 7675, 7684, 7730, 7750, 7758, 7801, 7850, 7887, 7939, 7948, 7972, 7975, 7976, 8012, 8039, 8047, 8054, 8064, 8075, 8091, 8112, 8140, 8165, 8166, 8184, 8188, 8216, 8226, 8250, 8256, 8285, 8304, 8388, 8405, 8409, 8426, 8450, 8463, 8497, 8506, 8516, 8522, 8535, 8555, 8577, 8609, 8640, 8642, 8644, 8661, 8693, 8758, 8761, 8780, 8802, 8855, 8870, 8889, 8933, 8938, 8976, 8982, 8985, 8993, 9026, 9118, 9119, 9133, 9227, 9257, 9265, 9283, 9301, 9329, 9343, 9355, 9371, 9458, 9474, 9489, 9508, 9511, 9544, 9600, 9670, 9684, 9707, 9742, 9813, 9826, 9853, 9858, 9879, 9895]
410 SVs (with labels):
Training time for 2.0-vs-6.0: 493.8933599 seconds
Begin training classifier for label 2.0 and label 7.0 at 2016-05-20, 01:09:42
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10233, 784) (10233,)
(10233, 784) (10233,)
     pcost       dcost       gap    pres   dres
 0: -1.1940e+03 -2.4276e+04  2e+05  3e+00  2e-11
 1: -7.4627e+02 -1.4792e+04  3e+04  5e-01  2e-11
 2: -4.4478e+02 -5.1623e+03  8e+03  1e-01  1e-11
 3: -3.3037e+02 -2.8719e+03  4e+03  6e-02  7e-12
 4: -2.5738e+02 -1.5585e+03  2e+03  3e-02  5e-12
 5: -2.1383e+02 -1.0543e+03  1e+03  2e-02  5e-12
 6: -1.8712e+02 -7.7496e+02  1e+03  1e-02  4e-12
 7: -1.5958e+02 -6.2605e+02  7e+02  6e-03  4e-12
 8: -1.5380e+02 -3.8178e+02  3e+02  2e-03  4e-12
 9: -1.5516e+02 -2.3770e+02  1e+02  4e-04  4e-12
10: -1.6360e+02 -1.9755e+02  4e+01  1e-04  4e-12
11: -1.6724e+02 -1.8283e+02  2e+01  8e-13  5e-12
12: -1.7133e+02 -1.7722e+02  6e+00  8e-14  4e-12
13: -1.7324e+02 -1.7467e+02  1e+00  6e-14  5e-12
14: -1.7378e+02 -1.7406e+02  3e-01  2e-13  5e-12
15: -1.7391e+02 -1.7392e+02  4e-03  2e-13  5e-12
16: -1.7391e+02 -1.7391e+02  6e-05  9e-13  5e-12
Optimal solution found.
sv_indices: [59, 116, 127, 140, 227, 240, 241, 245, 256, 275, 278, 324, 362, 368, 377, 485, 556, 558, 583, 604, 616, 619, 663, 683, 700, 740, 757, 789, 806, 813, 863, 866, 896, 902, 913, 932, 996, 998, 1005, 1018, 1058, 1081, 1086, 1088, 1094, 1140, 1150, 1157, 1163, 1165, 1169, 1182, 1206, 1214, 1245, 1247, 1253, 1318, 1366, 1368, 1370, 1421, 1426, 1429, 1464, 1468, 1473, 1497, 1518, 1541, 1561, 1577, 1657, 1669, 1699, 1744, 1752, 1763, 1770, 1779, 1785, 1793, 1802, 1816, 1848, 1855, 1856, 1862, 1868, 1966, 1968, 1973, 1989, 2010, 2029, 2059, 2097, 2100, 2147, 2201, 2204, 2248, 2251, 2334, 2335, 2375, 2382, 2415, 2439, 2446, 2464, 2536, 2547, 2566, 2576, 2650, 2685, 2700, 2715, 2755, 2785, 2808, 2853, 2863, 2872, 2895, 2921, 3022, 3038, 3129, 3223, 3225, 3271, 3322, 3324, 3343, 3348, 3376, 3378, 3392, 3418, 3494, 3510, 3516, 3619, 3629, 3654, 3681, 3682, 3764, 3780, 3792, 3844, 3849, 3850, 3869, 3905, 3926, 3938, 3965, 3973, 4035, 4116, 4125, 4149, 4169, 4173, 4214, 4262, 4281, 4303, 4307, 4310, 4320, 4335, 4359, 4376, 4378, 4400, 4405, 4447, 4459, 4465, 4486, 4520, 4521, 4539, 4555, 4561, 4585, 4593, 4599, 4708, 4743, 4745, 4774, 4775, 4805, 4817, 4820, 4825, 4835, 4859, 4868, 4885, 4893, 4919, 4954, 5028, 5098, 5107, 5109, 5184, 5229, 5289, 5294, 5308, 5345, 5364, 5418, 5427, 5494, 5511, 5515, 5537, 5585, 5588, 5594, 5630, 5636, 5658, 5665, 5669, 5690, 5708, 5750, 5753, 5803, 5805, 5810, 5817, 5856, 5961, 5963, 5990, 6037, 6039, 6100, 6115, 6146, 6158, 6192, 6197, 6198, 6222, 6228, 6236, 6262, 6304, 6308, 6309, 6330, 6345, 6434, 6482, 6509, 6514, 6543, 6544, 6547, 6589, 6643, 6648, 6681, 6691, 6724, 6757, 6763, 6806, 6808, 6822, 6831, 6893, 6936, 6939, 7004, 7038, 7047, 7049, 7115, 7207, 7217, 7303, 7335, 7409, 7425, 7429, 7450, 7478, 7495, 7500, 7506, 7518, 7539, 7552, 7573, 7599, 7620, 7623, 7662, 7693, 7706, 7719, 7735, 7736, 7746, 7769, 7802, 7807, 7876, 7936, 7960, 7964, 7978, 8005, 8016, 8076, 8101, 8134, 8142, 8165, 8188, 8190, 8213, 8220, 8366, 8371, 8397, 8415, 8437, 8452, 8483, 8543, 8544, 8548, 8550, 8567, 8575, 8577, 8654, 8686, 8722, 8754, 8884, 8885, 8891, 8933, 8944, 8985, 9006, 9017, 9109, 9141, 9167, 9180, 9193, 9219, 9225, 9228, 9251, 9252, 9293, 9295, 9300, 9321, 9336, 9392, 9421, 9473, 9493, 9513, 9595, 9596, 9638, 9654, 9664, 9687, 9696, 9698, 9704, 9707, 9710, 9845, 9862, 9875, 9910, 9911, 9936, 9956, 9962, 9983, 9985, 10022, 10031, 10037, 10061, 10063, 10095, 10105, 10110, 10171, 10185]
412 SVs (with labels):
Training time for 2.0-vs-7.0: 467.341724157 seconds
Begin training classifier for label 2.0 and label 8.0 at 2016-05-20, 01:17:30
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9845, 784) (9845,)
(9845, 784) (9845,)
     pcost       dcost       gap    pres   dres
 0: -1.7097e+03 -2.8320e+04  2e+05  4e+00  5e-11
 1: -1.0839e+03 -1.8730e+04  4e+04  6e-01  4e-11
 2: -7.1063e+02 -7.4006e+03  1e+04  2e-01  2e-11
 3: -5.3741e+02 -3.8038e+03  6e+03  7e-02  1e-11
 4: -4.3495e+02 -2.2080e+03  3e+03  3e-02  1e-11
 5: -3.8052e+02 -1.4109e+03  2e+03  2e-02  1e-11
 6: -3.5378e+02 -8.2727e+02  7e+02  6e-03  1e-11
 7: -3.5711e+02 -5.6052e+02  3e+02  2e-03  1e-11
 8: -3.6633e+02 -4.7310e+02  1e+02  5e-04  1e-11
 9: -3.7660e+02 -4.2949e+02  6e+01  9e-05  1e-11
10: -3.8389e+02 -4.1077e+02  3e+01  2e-06  1e-11
11: -3.9077e+02 -4.0128e+02  1e+01  3e-07  1e-11
12: -3.9412e+02 -3.9691e+02  3e+00  2e-09  1e-11
13: -3.9530e+02 -3.9556e+02  3e-01  4e-11  1e-11
14: -3.9542e+02 -3.9543e+02  1e-02  1e-12  1e-11
15: -3.9542e+02 -3.9542e+02  2e-04  5e-13  1e-11
Optimal solution found.
sv_indices: [23, 38, 54, 110, 112, 116, 127, 177, 192, 226, 237, 240, 245, 254, 256, 264, 272, 277, 289, 291, 309, 313, 316, 349, 375, 404, 430, 467, 485, 497, 505, 511, 534, 548, 556, 579, 583, 589, 609, 632, 670, 683, 684, 716, 731, 740, 770, 784, 806, 813, 844, 852, 860, 891, 896, 919, 956, 986, 1005, 1018, 1022, 1052, 1064, 1088, 1110, 1122, 1130, 1137, 1140, 1158, 1163, 1171, 1179, 1184, 1188, 1214, 1223, 1235, 1237, 1245, 1298, 1309, 1321, 1339, 1342, 1370, 1396, 1397, 1401, 1406, 1429, 1455, 1471, 1512, 1524, 1527, 1535, 1542, 1556, 1561, 1577, 1657, 1671, 1712, 1716, 1735, 1740, 1763, 1764, 1784, 1785, 1799, 1824, 1838, 1847, 1853, 1855, 1857, 1862, 1874, 1910, 1914, 1915, 1933, 1959, 1966, 1983, 1989, 1997, 2029, 2038, 2049, 2057, 2059, 2060, 2062, 2068, 2087, 2099, 2113, 2137, 2140, 2149, 2194, 2230, 2241, 2248, 2270, 2294, 2299, 2330, 2339, 2360, 2366, 2386, 2477, 2487, 2490, 2496, 2500, 2509, 2566, 2567, 2583, 2586, 2605, 2608, 2609, 2618, 2643, 2678, 2685, 2702, 2723, 2747, 2749, 2758, 2769, 2785, 2788, 2808, 2832, 2833, 2895, 2899, 2902, 2928, 2943, 2986, 2989, 2995, 3015, 3019, 3038, 3049, 3068, 3107, 3123, 3129, 3142, 3151, 3157, 3172, 3248, 3250, 3271, 3297, 3302, 3329, 3342, 3366, 3372, 3378, 3384, 3417, 3444, 3474, 3477, 3487, 3515, 3559, 3561, 3563, 3565, 3566, 3591, 3593, 3634, 3652, 3678, 3685, 3718, 3728, 3748, 3764, 3770, 3780, 3844, 3876, 3891, 3895, 3898, 3907, 3932, 3939, 3948, 4035, 4073, 4089, 4106, 4121, 4124, 4125, 4143, 4170, 4173, 4185, 4205, 4223, 4225, 4252, 4275, 4307, 4313, 4315, 4326, 4335, 4347, 4361, 4395, 4397, 4400, 4405, 4436, 4459, 4464, 4480, 4485, 4487, 4502, 4507, 4512, 4517, 4521, 4547, 4555, 4563, 4585, 4593, 4599, 4618, 4654, 4664, 4667, 4674, 4677, 4687, 4697, 4707, 4708, 4717, 4732, 4735, 4737, 4761, 4765, 4775, 4787, 4794, 4795, 4835, 4841, 4859, 4868, 4869, 4871, 4885, 4893, 4919, 4931, 4952, 4954, 4992, 5006, 5033, 5037, 5039, 5043, 5053, 5061, 5085, 5086, 5088, 5092, 5135, 5146, 5148, 5158, 5196, 5221, 5233, 5278, 5288, 5313, 5352, 5376, 5383, 5396, 5405, 5411, 5429, 5431, 5442, 5446, 5447, 5460, 5483, 5488, 5519, 5524, 5538, 5548, 5551, 5554, 5603, 5623, 5642, 5669, 5671, 5705, 5712, 5733, 5749, 5771, 5782, 5786, 5794, 5829, 5831, 5880, 5886, 5898, 5902, 5935, 5948, 5950, 5961, 5979, 5985, 5996, 6013, 6019, 6038, 6045, 6070, 6072, 6087, 6096, 6119, 6123, 6150, 6162, 6164, 6193, 6211, 6214, 6250, 6258, 6261, 6270, 6297, 6309, 6315, 6321, 6326, 6344, 6348, 6382, 6397, 6402, 6416, 6419, 6436, 6454, 6472, 6475, 6482, 6515, 6546, 6591, 6612, 6616, 6617, 6655, 6657, 6682, 6713, 6748, 6774, 6793, 6806, 6846, 6847, 6853, 6859, 6875, 6886, 6887, 6909, 6930, 6986, 6990, 6999, 7002, 7032, 7034, 7065, 7067, 7082, 7083, 7098, 7123, 7135, 7137, 7144, 7147, 7150, 7156, 7199, 7201, 7225, 7235, 7250, 7278, 7307, 7315, 7316, 7320, 7325, 7351, 7364, 7377, 7398, 7405, 7410, 7417, 7433, 7436, 7448, 7480, 7483, 7485, 7488, 7505, 7531, 7561, 7569, 7600, 7606, 7609, 7612, 7620, 7627, 7630, 7656, 7669, 7670, 7695, 7699, 7710, 7735, 7759, 7760, 7765, 7772, 7788, 7810, 7820, 7821, 7828, 7836, 7839, 7846, 7854, 7856, 7864, 7880, 7893, 7921, 7924, 7931, 7932, 7939, 7949, 7956, 7959, 7963, 7976, 7988, 8002, 8003, 8004, 8016, 8034, 8036, 8037, 8038, 8062, 8100, 8107, 8110, 8113, 8143, 8151, 8156, 8176, 8195, 8229, 8234, 8250, 8338, 8350, 8353, 8389, 8398, 8406, 8428, 8434, 8443, 8450, 8455, 8458, 8461, 8464, 8492, 8493, 8517, 8556, 8574, 8623, 8624, 8626, 8632, 8656, 8677, 8710, 8755, 8763, 8766, 8774, 8790, 8803, 8812, 8816, 8835, 8859, 8870, 8889, 8894, 8914, 8964, 8970, 8982, 9009, 9010, 9011, 9018, 9029, 9053, 9063, 9084, 9086, 9094, 9108, 9128, 9157, 9174, 9187, 9191, 9245, 9250, 9254, 9255, 9266, 9283, 9293, 9311, 9349, 9367, 9370, 9378, 9381, 9385, 9407, 9413, 9422, 9429, 9443, 9469, 9477, 9480, 9502, 9519, 9520, 9538, 9547, 9550, 9559, 9574, 9602, 9641, 9646, 9661, 9664, 9674, 9678, 9698, 9700, 9712, 9733, 9735, 9745, 9748, 9762, 9821, 9832, 9842]
667 SVs (with labels):
Training time for 2.0-vs-8.0: 407.535525084 seconds
Begin training classifier for label 2.0 and label 9.0 at 2016-05-20, 01:24:17
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10012, 784) (10012,)
(10012, 784) (10012,)
     pcost       dcost       gap    pres   dres
 0: -1.0651e+03 -2.2762e+04  1e+05  3e+00  2e-11
 1: -6.4998e+02 -1.3552e+04  3e+04  4e-01  1e-11
 2: -3.6317e+02 -4.4649e+03  7e+03  1e-01  9e-12
 3: -2.3517e+02 -2.5725e+03  4e+03  5e-02  6e-12
 4: -1.7546e+02 -1.8063e+03  3e+03  3e-02  5e-12
 5: -1.2726e+02 -1.2652e+03  2e+03  2e-02  4e-12
 6: -9.5143e+01 -7.9143e+02  1e+03  9e-03  3e-12
 7: -7.4207e+01 -4.8385e+02  6e+02  4e-03  3e-12
 8: -6.8833e+01 -3.4770e+02  4e+02  2e-03  2e-12
 9: -7.5241e+01 -1.9411e+02  1e+02  6e-04  2e-12
10: -8.1128e+01 -1.2916e+02  5e+01  2e-13  3e-12
11: -8.7371e+01 -1.1595e+02  3e+01  1e-13  3e-12
12: -9.2680e+01 -1.0573e+02  1e+01  2e-13  3e-12
13: -9.4869e+01 -1.0202e+02  7e+00  3e-14  3e-12
14: -9.6735e+01 -9.9355e+01  3e+00  7e-14  3e-12
15: -9.7518e+01 -9.8231e+01  7e-01  2e-13  3e-12
16: -9.7846e+01 -9.7872e+01  3e-02  4e-13  3e-12
17: -9.7858e+01 -9.7859e+01  4e-04  7e-13  3e-12
18: -9.7859e+01 -9.7859e+01  9e-06  5e-13  3e-12
Optimal solution found.
sv_indices: [50, 54, 90, 116, 140, 177, 256, 284, 289, 324, 365, 497, 500, 556, 558, 567, 583, 663, 667, 731, 740, 789, 956, 972, 996, 1052, 1058, 1093, 1137, 1148, 1206, 1207, 1212, 1214, 1223, 1237, 1247, 1283, 1313, 1340, 1412, 1420, 1429, 1468, 1488, 1518, 1535, 1577, 1645, 1657, 1691, 1699, 1735, 1740, 1752, 1763, 1785, 1808, 1837, 1862, 1868, 1887, 1910, 1938, 1948, 1965, 1966, 1973, 1989, 1997, 2027, 2038, 2049, 2068, 2100, 2113, 2229, 2230, 2248, 2281, 2386, 2397, 2426, 2487, 2570, 2576, 2597, 2685, 2715, 2808, 2824, 2852, 2872, 2895, 3022, 3038, 3129, 3170, 3201, 3250, 3285, 3302, 3324, 3418, 3494, 3517, 3678, 3764, 3849, 3869, 3895, 3905, 3926, 3938, 4073, 4106, 4121, 4125, 4173, 4223, 4256, 4320, 4335, 4356, 4359, 4363, 4397, 4400, 4405, 4459, 4485, 4520, 4521, 4578, 4593, 4595, 4599, 4636, 4644, 4708, 4715, 4765, 4774, 4825, 4859, 4868, 4893, 4919, 5009, 5021, 5045, 5051, 5070, 5088, 5089, 5095, 5237, 5252, 5271, 5299, 5411, 5438, 5455, 5457, 5497, 5506, 5548, 5571, 5584, 5693, 5720, 5777, 5878, 5905, 5926, 5937, 5964, 5968, 5987, 5988, 5993, 6030, 6049, 6063, 6068, 6079, 6138, 6155, 6174, 6185, 6191, 6271, 6272, 6292, 6330, 6334, 6359, 6365, 6386, 6408, 6457, 6493, 6534, 6551, 6575, 6615, 6638, 6644, 6650, 6699, 6707, 6725, 6729, 6768, 6779, 6812, 6816, 6830, 6882, 6908, 6921, 6924, 6933, 6992, 7035, 7083, 7107, 7141, 7175, 7181, 7194, 7211, 7384, 7396, 7401, 7415, 7438, 7470, 7506, 7574, 7592, 7594, 7598, 7683, 7700, 7702, 7737, 7746, 7794, 7833, 7849, 7890, 7911, 7914, 7957, 7999, 8020, 8049, 8055, 8125, 8130, 8137, 8141, 8148, 8186, 8188, 8225, 8243, 8246, 8312, 8320, 8393, 8427, 8495, 8507, 8524, 8526, 8574, 8608, 8730, 8776, 8812, 8863, 8870, 8950, 8952, 8965, 8976, 9073, 9103, 9117, 9146, 9201, 9222, 9255, 9289, 9300, 9313, 9340, 9353, 9408, 9411, 9421, 9430, 9437, 9444, 9445, 9458, 9459, 9497, 9499, 9519, 9557, 9580, 9595, 9615, 9660, 9678, 9680, 9686, 9690, 9753, 9770, 9775, 9776, 9825, 9834, 9909, 9937, 9966, 9975, 9986, 10005, 10008]
334 SVs (with labels):
Training time for 2.0-vs-9.0: 488.00591898 seconds
Begin training classifier for label 3.0 and label 4.0 at 2016-05-20, 01:32:26
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9916, 784) (9916,)
(9916, 784) (9916,)
     pcost       dcost       gap    pres   dres
 0: -9.3234e+02 -2.0492e+04  1e+05  3e+00  1e-11
 1: -5.5807e+02 -1.1475e+04  2e+04  4e-01  1e-11
 2: -2.8664e+02 -4.1031e+03  7e+03  1e-01  8e-12
 3: -1.8547e+02 -2.3407e+03  4e+03  6e-02  5e-12
 4: -1.1464e+02 -1.5179e+03  2e+03  3e-02  3e-12
 5: -7.0392e+01 -8.4969e+02  1e+03  2e-02  2e-12
 6: -4.6470e+01 -5.2165e+02  8e+02  8e-03  1e-12
 7: -3.1038e+01 -3.1376e+02  4e+02  4e-03  1e-12
 8: -2.5948e+01 -2.0535e+02  3e+02  2e-03  9e-13
 9: -2.3173e+01 -9.1100e+01  9e+01  6e-04  9e-13
10: -2.1609e+01 -6.5223e+01  5e+01  2e-04  9e-13
11: -2.6172e+01 -4.6133e+01  2e+01  7e-05  9e-13
12: -2.7945e+01 -3.7370e+01  9e+00  9e-14  1e-12
13: -3.0247e+01 -3.3894e+01  4e+00  1e-13  1e-12
14: -3.1255e+01 -3.2441e+01  1e+00  2e-13  1e-12
15: -3.1633e+01 -3.2008e+01  4e-01  2e-14  1e-12
16: -3.1756e+01 -3.1863e+01  1e-01  5e-14  1e-12
17: -3.1808e+01 -3.1809e+01  2e-03  1e-13  1e-12
18: -3.1808e+01 -3.1808e+01  2e-05  3e-14  1e-12
Optimal solution found.
sv_indices: [19, 42, 152, 229, 333, 373, 381, 439, 472, 507, 548, 578, 616, 617, 626, 635, 642, 644, 664, 817, 886, 887, 888, 984, 999, 1085, 1087, 1111, 1188, 1202, 1281, 1331, 1337, 1368, 1404, 1405, 1434, 1482, 1551, 1560, 1633, 1693, 1706, 1725, 1743, 2009, 2020, 2053, 2124, 2293, 2440, 2443, 2449, 2509, 2529, 2568, 2606, 2657, 2688, 2751, 2827, 2848, 2930, 3085, 3261, 3264, 3299, 3313, 3406, 3427, 3443, 3495, 3505, 3514, 3544, 3608, 3707, 3740, 3904, 3915, 3956, 4109, 4125, 4293, 4425, 4538, 4624, 4744, 4767, 4783, 4785, 4799, 4835, 4838, 4845, 4904, 5014, 5047, 5049, 5085, 5096, 5162, 5239, 5240, 5247, 5249, 5254, 5255, 5267, 5272, 5273, 5288, 5300, 5371, 5376, 5442, 5547, 5550, 5651, 5676, 5728, 5820, 5837, 5920, 5930, 5996, 6016, 6064, 6169, 6218, 6265, 6307, 6321, 6396, 6455, 6486, 6496, 6538, 6662, 6691, 6750, 6835, 6882, 6900, 6916, 6928, 6951, 7005, 7023, 7056, 7119, 7158, 7255, 7276, 7296, 7309, 7341, 7513, 7588, 7699, 7710, 7754, 7791, 7792, 7839, 7866, 7944, 7953, 7954, 7986, 8044, 8052, 8055, 8063, 8101, 8167, 8197, 8223, 8224, 8375, 8393, 8404, 8430, 8459, 8477, 8487, 8493, 8564, 8595, 8796, 8802, 8819, 8913, 9044, 9050, 9057, 9105, 9131, 9233, 9249, 9290, 9327, 9341, 9404, 9422, 9430, 9452, 9505, 9539, 9560, 9737, 9830]
212 SVs (with labels):
Training time for 3.0-vs-4.0: 490.74740386 seconds
Begin training classifier for label 3.0 and label 5.0 at 2016-05-20, 01:40:36
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9576, 784) (9576,)
(9576, 784) (9576,)
     pcost       dcost       gap    pres   dres
 0: -2.1105e+03 -2.7919e+04  2e+05  4e+00  6e-11
 1: -1.3406e+03 -1.8860e+04  4e+04  6e-01  3e-11
 2: -9.4192e+02 -8.4632e+03  1e+04  2e-01  2e-11
 3: -7.1545e+02 -3.8399e+03  5e+03  7e-02  2e-11
 4: -6.0778e+02 -2.2283e+03  3e+03  3e-02  1e-11
 5: -5.5271e+02 -1.4367e+03  1e+03  1e-02  1e-11
 6: -5.4368e+02 -1.0304e+03  7e+02  6e-03  1e-11
 7: -5.6253e+02 -7.7637e+02  3e+02  2e-03  1e-11
 8: -5.7784e+02 -6.9482e+02  1e+02  5e-04  1e-11
 9: -5.8157e+02 -6.5600e+02  7e+01  5e-13  2e-11
10: -5.9819e+02 -6.3183e+02  3e+01  3e-12  1e-11
11: -6.0205e+02 -6.2559e+02  2e+01  2e-12  1e-11
12: -6.0855e+02 -6.1682e+02  8e+00  1e-12  2e-11
13: -6.1137e+02 -6.1351e+02  2e+00  2e-12  1e-11
14: -6.1225e+02 -6.1249e+02  2e-01  2e-13  2e-11
15: -6.1236e+02 -6.1237e+02  2e-02  3e-12  1e-11
16: -6.1237e+02 -6.1237e+02  3e-04  2e-12  2e-11
Optimal solution found.
sv_indices: [9, 25, 42, 48, 65, 76, 141, 149, 170, 196, 210, 229, 231, 239, 241, 255, 263, 279, 280, 321, 326, 339, 342, 355, 358, 359, 361, 375, 384, 409, 419, 426, 437, 439, 446, 463, 464, 469, 490, 500, 507, 530, 537, 540, 544, 546, 548, 558, 567, 573, 580, 586, 587, 597, 608, 612, 613, 616, 617, 619, 622, 629, 632, 642, 644, 658, 664, 670, 698, 738, 748, 775, 781, 794, 812, 813, 817, 835, 837, 849, 857, 860, 861, 871, 883, 899, 900, 907, 917, 937, 950, 978, 984, 987, 1015, 1031, 1041, 1042, 1073, 1085, 1087, 1090, 1100, 1111, 1116, 1136, 1139, 1144, 1157, 1178, 1196, 1202, 1211, 1232, 1237, 1247, 1257, 1262, 1280, 1287, 1296, 1314, 1325, 1327, 1331, 1337, 1358, 1387, 1393, 1395, 1406, 1451, 1471, 1475, 1486, 1487, 1496, 1499, 1505, 1520, 1536, 1543, 1560, 1591, 1606, 1616, 1621, 1625, 1634, 1647, 1651, 1660, 1661, 1695, 1699, 1700, 1701, 1706, 1710, 1745, 1750, 1787, 1789, 1798, 1801, 1807, 1829, 1832, 1835, 1836, 1840, 1845, 1854, 1855, 1865, 1903, 1922, 1956, 1959, 1985, 1989, 1993, 2004, 2005, 2009, 2018, 2021, 2024, 2025, 2036, 2049, 2054, 2062, 2077, 2085, 2091, 2098, 2107, 2109, 2129, 2142, 2168, 2178, 2186, 2205, 2215, 2245, 2246, 2257, 2264, 2278, 2293, 2307, 2314, 2316, 2319, 2325, 2348, 2350, 2351, 2370, 2371, 2388, 2403, 2437, 2440, 2469, 2490, 2509, 2513, 2524, 2542, 2551, 2561, 2566, 2570, 2571, 2582, 2583, 2585, 2610, 2630, 2631, 2660, 2688, 2708, 2711, 2723, 2730, 2741, 2780, 2783, 2797, 2802, 2804, 2829, 2854, 2862, 2863, 2886, 2898, 2907, 2908, 2911, 2930, 2934, 2950, 2976, 2994, 3000, 3019, 3029, 3036, 3071, 3092, 3105, 3141, 3150, 3154, 3162, 3163, 3177, 3181, 3212, 3216, 3217, 3246, 3261, 3270, 3289, 3294, 3295, 3297, 3312, 3313, 3318, 3320, 3325, 3326, 3365, 3385, 3389, 3404, 3412, 3421, 3434, 3461, 3466, 3478, 3483, 3505, 3517, 3528, 3560, 3571, 3582, 3586, 3589, 3601, 3610, 3620, 3630, 3633, 3649, 3663, 3672, 3677, 3696, 3700, 3724, 3731, 3736, 3740, 3774, 3795, 3800, 3801, 3802, 3808, 3809, 3812, 3819, 3830, 3868, 3877, 3881, 3886, 3899, 3904, 3938, 3956, 3964, 3974, 3976, 3978, 3996, 4007, 4011, 4014, 4017, 4036, 4100, 4109, 4141, 4169, 4176, 4182, 4189, 4210, 4224, 4227, 4249, 4267, 4271, 4276, 4279, 4300, 4303, 4342, 4372, 4383, 4389, 4428, 4435, 4443, 4451, 4506, 4512, 4514, 4524, 4537, 4538, 4541, 4629, 4654, 4660, 4672, 4673, 4674, 4675, 4687, 4688, 4689, 4700, 4702, 4729, 4742, 4745, 4748, 4765, 4767, 4772, 4774, 4779, 4782, 4783, 4786, 4790, 4799, 4811, 4815, 4827, 4836, 4837, 4838, 4840, 4843, 4845, 4851, 4890, 4904, 4907, 4919, 4925, 4931, 4933, 4938, 4951, 4964, 4966, 4973, 4974, 4976, 4984, 4990, 5012, 5014, 5015, 5022, 5047, 5049, 5057, 5062, 5087, 5095, 5097, 5108, 5125, 5126, 5129, 5135, 5138, 5141, 5160, 5199, 5210, 5217, 5218, 5222, 5230, 5268, 5271, 5275, 5276, 5278, 5285, 5306, 5308, 5317, 5347, 5361, 5369, 5372, 5385, 5390, 5401, 5408, 5427, 5443, 5453, 5462, 5470, 5473, 5492, 5508, 5525, 5530, 5538, 5550, 5555, 5571, 5578, 5586, 5587, 5613, 5614, 5623, 5625, 5627, 5635, 5637, 5650, 5669, 5689, 5692, 5707, 5708, 5710, 5721, 5723, 5742, 5746, 5752, 5754, 5764, 5767, 5771, 5785, 5792, 5808, 5815, 5816, 5820, 5836, 5841, 5849, 5863, 5864, 5865, 5869, 5880, 5881, 5883, 5910, 5911, 5944, 5949, 5960, 5972, 5978, 5985, 5999, 6028, 6038, 6049, 6054, 6071, 6077, 6102, 6127, 6129, 6135, 6149, 6157, 6173, 6178, 6190, 6191, 6205, 6213, 6217, 6230, 6240, 6241, 6256, 6260, 6282, 6293, 6296, 6309, 6321, 6335, 6374, 6376, 6392, 6399, 6400, 6408, 6451, 6456, 6460, 6466, 6475, 6489, 6492, 6495, 6504, 6521, 6538, 6549, 6558, 6560, 6570, 6576, 6602, 6611, 6628, 6632, 6642, 6644, 6651, 6670, 6695, 6698, 6705, 6715, 6735, 6754, 6756, 6786, 6793, 6805, 6814, 6834, 6861, 6864, 6866, 6867, 6872, 6874, 6888, 6890, 6897, 6913, 6915, 6918, 6926, 6931, 6942, 6945, 6946, 6957, 6959, 6962, 6968, 7019, 7020, 7032, 7056, 7065, 7066, 7072, 7084, 7092, 7094, 7098, 7104, 7124, 7128, 7165, 7166, 7169, 7171, 7198, 7199, 7204, 7208, 7210, 7219, 7228, 7248, 7256, 7268, 7296, 7300, 7304, 7330, 7353, 7362, 7363, 7364, 7365, 7369, 7385, 7392, 7401, 7412, 7421, 7429, 7431, 7439, 7456, 7457, 7463, 7468, 7472, 7476, 7494, 7496, 7501, 7508, 7534, 7535, 7537, 7551, 7558, 7563, 7586, 7592, 7603, 7622, 7624, 7634, 7636, 7642, 7648, 7665, 7683, 7684, 7703, 7704, 7712, 7736, 7764, 7770, 7773, 7779, 7798, 7807, 7808, 7812, 7816, 7837, 7841, 7857, 7877, 7900, 7901, 7906, 7913, 7925, 7927, 7933, 7936, 7939, 7957, 7970, 7977, 7990, 7994, 8001, 8010, 8013, 8017, 8071, 8085, 8099, 8100, 8105, 8106, 8117, 8122, 8127, 8136, 8142, 8197, 8203, 8215, 8238, 8246, 8248, 8266, 8270, 8274, 8287, 8292, 8304, 8308, 8315, 8320, 8331, 8353, 8372, 8382, 8383, 8394, 8396, 8399, 8400, 8414, 8415, 8422, 8440, 8458, 8480, 8482, 8483, 8494, 8502, 8512, 8514, 8516, 8535, 8542, 8545, 8591, 8602, 8611, 8614, 8624, 8625, 8639, 8660, 8677, 8679, 8684, 8688, 8692, 8717, 8725, 8742, 8743, 8747, 8758, 8762, 8769, 8772, 8796, 8807, 8840, 8848, 8849, 8855, 8873, 8890, 8898, 8900, 8902, 8905, 8913, 8942, 8957, 8976, 8991, 9011, 9015, 9040, 9044, 9049, 9050, 9060, 9084, 9093, 9101, 9102, 9109, 9120, 9166, 9170, 9179, 9195, 9198, 9211, 9214, 9220, 9224, 9238, 9244, 9259, 9263, 9269, 9277, 9287, 9304, 9329, 9334, 9345, 9358, 9373, 9381, 9398, 9403, 9407, 9408, 9419, 9424, 9426, 9430, 9443, 9461, 9475, 9481, 9482, 9493, 9494, 9516, 9524, 9526, 9529, 9552, 9571]
901 SVs (with labels):
Training time for 3.0-vs-5.0: 394.155445099 seconds
Begin training classifier for label 3.0 and label 6.0 at 2016-05-20, 01:47:11
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9988, 784) (9988,)
(9988, 784) (9988,)
     pcost       dcost       gap    pres   dres
 0: -9.5409e+02 -2.1409e+04  1e+05  3e+00  1e-11
 1: -5.7919e+02 -1.2324e+04  2e+04  4e-01  1e-11
 2: -3.0052e+02 -4.5807e+03  8e+03  1e-01  8e-12
 3: -1.7126e+02 -2.3869e+03  4e+03  6e-02  5e-12
 4: -9.0263e+01 -1.1510e+03  2e+03  3e-02  3e-12
 5: -4.6828e+01 -7.6873e+02  1e+03  1e-02  2e-12
 6: -2.6279e+01 -4.7953e+02  8e+02  8e-03  1e-12
 7: -1.4761e+01 -3.8536e+02  6e+02  5e-03  9e-13
 8: -5.1086e+00 -1.6014e+02  2e+02  2e-03  6e-13
 9: -3.5450e+00 -6.5165e+01  8e+01  5e-04  4e-13
10: -4.8713e+00 -2.5795e+01  2e+01  2e-14  4e-13
11: -6.8941e+00 -2.1186e+01  1e+01  5e-14  4e-13
12: -9.0407e+00 -1.6577e+01  8e+00  1e-14  5e-13
13: -1.0571e+01 -1.3457e+01  3e+00  1e-14  5e-13
14: -1.1185e+01 -1.2459e+01  1e+00  5e-15  5e-13
15: -1.1689e+01 -1.1860e+01  2e-01  5e-16  6e-13
16: -1.1769e+01 -1.1772e+01  3e-03  2e-14  6e-13
17: -1.1770e+01 -1.1770e+01  3e-05  7e-14  6e-13
18: -1.1770e+01 -1.1770e+01  4e-07  9e-14  6e-13
Optimal solution found.
sv_indices: [152, 229, 241, 321, 409, 426, 439, 612, 613, 617, 670, 849, 886, 899, 1031, 1073, 1087, 1102, 1130, 1247, 1376, 1405, 1434, 1463, 1509, 1514, 1706, 1886, 1956, 2020, 2098, 2115, 2189, 2314, 2319, 2439, 2440, 2509, 2524, 2551, 2561, 2657, 2658, 2660, 2675, 2730, 2885, 2950, 3085, 3159, 3162, 3216, 3227, 3269, 3312, 3313, 3478, 3543, 3544, 3661, 3772, 3821, 4003, 4061, 4125, 4210, 4240, 4249, 4261, 4271, 4450, 4475, 4524, 4538, 4556, 4624, 4660, 4674, 4683, 4779, 4783, 4838, 4845, 4904, 4915, 4933, 4973, 5014, 5047, 5071, 5211, 5218, 5236, 5272, 5315, 5380, 5473, 5497, 5498, 5502, 5598, 5607, 5677, 5712, 5715, 5923, 5933, 5945, 5993, 6013, 6072, 6117, 6136, 6148, 6184, 6211, 6360, 6381, 6394, 6410, 6512, 6583, 6609, 6643, 6699, 6759, 6762, 6791, 6812, 6819, 6820, 6885, 7016, 7021, 7024, 7057, 7134, 7202, 7267, 7292, 7354, 7359, 7399, 7421, 7438, 7664, 7755, 7817, 8125, 8127, 8237, 8294, 8321, 8327, 8382, 8405, 8431, 8480, 8521, 8587, 8650, 8780, 8788, 8832, 8960, 9116, 9168, 9247, 9377, 9414, 9426, 9442, 9464, 9579, 9672, 9741, 9884]
177 SVs (with labels):
Training time for 3.0-vs-6.0: 501.645792961 seconds
Begin training classifier for label 3.0 and label 7.0 at 2016-05-20, 01:55:32
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10304, 784) (10304,)
(10304, 784) (10304,)
     pcost       dcost       gap    pres   dres
 0: -1.1074e+03 -2.8084e+04  2e+05  4e+00  2e-11
 1: -6.9322e+02 -1.7711e+04  4e+04  5e-01  1e-11
 2: -3.9592e+02 -6.1232e+03  1e+04  1e-01  9e-12
 3: -2.8044e+02 -3.2940e+03  5e+03  6e-02  6e-12
 4: -2.0425e+02 -2.0905e+03  3e+03  3e-02  5e-12
 5: -1.5071e+02 -1.5143e+03  2e+03  2e-02  4e-12
 6: -1.2314e+02 -8.5564e+02  1e+03  8e-03  3e-12
 7: -1.0764e+02 -5.9271e+02  7e+02  4e-03  3e-12
 8: -1.0761e+02 -3.1873e+02  2e+02  8e-04  3e-12
 9: -1.1718e+02 -2.5348e+02  1e+02  3e-04  3e-12
10: -1.2419e+02 -2.1876e+02  1e+02  1e-04  3e-12
11: -1.3089e+02 -1.9372e+02  6e+01  3e-05  3e-12
12: -1.4035e+02 -1.7016e+02  3e+01  4e-06  4e-12
13: -1.4432e+02 -1.6217e+02  2e+01  8e-07  4e-12
14: -1.4847e+02 -1.5577e+02  7e+00  3e-07  4e-12
15: -1.5025e+02 -1.5291e+02  3e+00  6e-13  4e-12
16: -1.5126e+02 -1.5175e+02  5e-01  2e-15  4e-12
17: -1.5148e+02 -1.5150e+02  2e-02  7e-13  4e-12
18: -1.5149e+02 -1.5149e+02  2e-04  5e-13  4e-12
19: -1.5149e+02 -1.5149e+02  3e-06  3e-13  4e-12
Optimal solution found.
sv_indices: [97, 124, 126, 149, 197, 280, 337, 348, 363, 373, 375, 381, 385, 394, 417, 436, 437, 439, 507, 508, 546, 578, 617, 626, 635, 644, 652, 776, 794, 817, 854, 862, 886, 887, 906, 913, 965, 984, 1001, 1022, 1065, 1075, 1078, 1092, 1111, 1202, 1249, 1262, 1281, 1287, 1290, 1319, 1330, 1331, 1453, 1461, 1462, 1515, 1551, 1646, 1703, 1706, 1713, 1743, 1831, 1865, 1868, 1883, 1929, 1992, 2020, 2053, 2055, 2059, 2071, 2072, 2096, 2097, 2098, 2102, 2107, 2124, 2174, 2246, 2257, 2273, 2290, 2293, 2345, 2366, 2371, 2379, 2413, 2430, 2449, 2454, 2456, 2469, 2472, 2485, 2498, 2526, 2536, 2557, 2592, 2594, 2646, 2671, 2725, 2741, 2848, 2862, 2930, 3000, 3105, 3136, 3159, 3161, 3217, 3219, 3227, 3231, 3251, 3261, 3283, 3323, 3335, 3388, 3395, 3406, 3443, 3466, 3506, 3544, 3581, 3608, 3619, 3653, 3665, 3808, 3827, 3904, 3956, 4029, 4054, 4057, 4061, 4141, 4212, 4244, 4265, 4271, 4293, 4322, 4327, 4342, 4354, 4364, 4411, 4538, 4544, 4546, 4660, 4685, 4705, 4744, 4752, 4756, 4762, 4779, 4783, 4799, 4819, 4835, 4838, 4860, 4904, 4916, 4919, 4957, 4978, 5007, 5014, 5050, 5080, 5154, 5156, 5197, 5227, 5230, 5258, 5298, 5367, 5401, 5422, 5456, 5476, 5527, 5579, 5585, 5599, 5707, 5718, 5729, 5733, 5736, 5753, 5761, 5820, 5821, 5835, 5886, 5888, 5906, 5927, 5954, 5972, 5977, 6006, 6016, 6031, 6032, 6033, 6062, 6125, 6138, 6148, 6158, 6171, 6176, 6180, 6186, 6225, 6246, 6259, 6333, 6355, 6374, 6375, 6416, 6427, 6474, 6513, 6561, 6575, 6647, 6660, 6680, 6702, 6726, 6737, 6748, 6752, 6815, 6823, 6834, 6841, 6847, 6873, 6889, 6896, 6902, 6923, 6935, 6958, 6964, 7055, 7120, 7143, 7176, 7187, 7191, 7196, 7255, 7280, 7375, 7416, 7482, 7496, 7505, 7521, 7566, 7577, 7586, 7623, 7652, 7694, 7714, 7738, 7764, 7774, 7777, 7790, 7835, 7848, 7878, 7885, 7887, 7906, 7917, 7947, 7955, 7995, 7997, 8007, 8035, 8049, 8085, 8127, 8171, 8172, 8216, 8261, 8284, 8313, 8317, 8403, 8508, 8513, 8526, 8543, 8545, 8575, 8611, 8615, 8617, 8619, 8638, 8648, 8659, 8681, 8682, 8698, 8706, 8708, 8788, 8793, 8870, 8876, 8888, 8919, 8956, 8959, 8962, 8988, 9055, 9065, 9121, 9144, 9212, 9290, 9296, 9299, 9366, 9521, 9535, 9595, 9653, 9709, 9754, 9761, 9781, 9812, 9828, 9885, 9981, 10056, 10061, 10093, 10102, 10107, 10147, 10166, 10168, 10204, 10205, 10259, 10270, 10271]
379 SVs (with labels):
Training time for 3.0-vs-7.0: 630.374405146 seconds
Begin training classifier for label 3.0 and label 8.0 at 2016-05-20, 02:06:03
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9916, 784) (9916,)
(9916, 784) (9916,)
     pcost       dcost       gap    pres   dres
 0: -1.9850e+03 -2.6297e+04  2e+05  3e+00  4e-11
 1: -1.2559e+03 -1.7001e+04  3e+04  5e-01  4e-11
 2: -8.6172e+02 -6.8181e+03  1e+04  1e-01  3e-11
 3: -7.1062e+02 -4.4541e+03  6e+03  8e-02  2e-11
 4: -5.8482e+02 -2.8365e+03  4e+03  4e-02  2e-11
 5: -5.2279e+02 -1.9996e+03  2e+03  2e-02  1e-11
 6: -5.0889e+02 -1.1467e+03  8e+02  6e-03  1e-11
 7: -5.2653e+02 -9.0101e+02  4e+02  2e-03  1e-11
 8: -5.4837e+02 -7.6436e+02  2e+02  6e-04  1e-11
 9: -5.6706e+02 -7.0377e+02  1e+02  2e-04  1e-11
10: -5.8548e+02 -6.5538e+02  7e+01  5e-05  2e-11
11: -5.9045e+02 -6.4325e+02  5e+01  2e-05  2e-11
12: -6.0203e+02 -6.2547e+02  2e+01  6e-06  2e-11
13: -6.0677e+02 -6.1815e+02  1e+01  2e-06  2e-11
14: -6.0992e+02 -6.1371e+02  4e+00  3e-07  2e-11
15: -6.1125e+02 -6.1209e+02  8e-01  6e-08  2e-11
16: -6.1160e+02 -6.1166e+02  6e-02  3e-09  2e-11
17: -6.1163e+02 -6.1163e+02  2e-03  9e-11  2e-11
18: -6.1163e+02 -6.1163e+02  4e-05  2e-12  2e-11
Optimal solution found.
sv_indices: [6, 9, 31, 33, 39, 40, 42, 66, 86, 98, 104, 128, 152, 159, 210, 213, 242, 253, 255, 261, 262, 302, 355, 361, 363, 373, 374, 398, 409, 426, 430, 439, 446, 466, 472, 491, 507, 519, 523, 537, 547, 586, 594, 597, 604, 608, 614, 617, 622, 626, 635, 642, 644, 664, 670, 682, 706, 721, 738, 740, 742, 746, 755, 776, 813, 817, 886, 887, 941, 942, 950, 957, 978, 981, 984, 993, 1031, 1037, 1042, 1044, 1066, 1071, 1085, 1087, 1102, 1132, 1144, 1146, 1161, 1168, 1202, 1208, 1214, 1241, 1247, 1256, 1262, 1281, 1282, 1287, 1290, 1296, 1323, 1331, 1358, 1366, 1391, 1421, 1463, 1482, 1492, 1494, 1498, 1499, 1509, 1510, 1514, 1515, 1520, 1523, 1528, 1536, 1540, 1546, 1551, 1560, 1565, 1576, 1582, 1625, 1633, 1646, 1647, 1663, 1682, 1688, 1689, 1706, 1725, 1740, 1750, 1801, 1813, 1822, 1836, 1840, 1855, 1865, 1875, 1883, 1889, 1892, 1894, 1939, 1946, 1956, 1979, 1988, 1989, 1993, 1999, 2005, 2009, 2012, 2019, 2020, 2024, 2053, 2077, 2107, 2108, 2114, 2138, 2153, 2168, 2186, 2196, 2201, 2205, 2221, 2257, 2269, 2273, 2289, 2293, 2307, 2319, 2325, 2335, 2341, 2348, 2361, 2370, 2371, 2373, 2377, 2388, 2394, 2403, 2405, 2406, 2421, 2425, 2437, 2442, 2445, 2449, 2451, 2468, 2472, 2490, 2522, 2524, 2529, 2542, 2592, 2594, 2596, 2610, 2628, 2630, 2635, 2646, 2658, 2660, 2675, 2688, 2695, 2699, 2708, 2803, 2843, 2848, 2854, 2891, 2898, 2907, 2925, 2930, 2941, 2966, 3034, 3036, 3058, 3066, 3073, 3110, 3118, 3154, 3159, 3161, 3175, 3207, 3218, 3219, 3223, 3242, 3243, 3261, 3299, 3318, 3331, 3338, 3379, 3383, 3387, 3388, 3414, 3427, 3428, 3431, 3440, 3459, 3462, 3469, 3478, 3483, 3505, 3511, 3543, 3544, 3555, 3557, 3563, 3581, 3584, 3586, 3610, 3664, 3667, 3668, 3672, 3696, 3709, 3716, 3759, 3766, 3769, 3771, 3772, 3856, 3862, 3865, 3868, 3886, 3895, 3947, 3964, 3976, 3978, 3993, 4003, 4011, 4022, 4029, 4054, 4060, 4072, 4076, 4082, 4102, 4125, 4134, 4138, 4141, 4161, 4166, 4175, 4207, 4210, 4212, 4221, 4224, 4225, 4227, 4231, 4244, 4249, 4251, 4264, 4267, 4271, 4276, 4293, 4296, 4324, 4337, 4341, 4355, 4383, 4389, 4431, 4435, 4438, 4443, 4447, 4455, 4481, 4523, 4526, 4534, 4550, 4556, 4562, 4624, 4637, 4666, 4672, 4674, 4676, 4677, 4689, 4698, 4700, 4702, 4725, 4726, 4732, 4744, 4756, 4761, 4774, 4779, 4785, 4786, 4790, 4799, 4819, 4827, 4837, 4838, 4845, 4857, 4861, 4868, 4884, 4890, 4898, 4919, 4940, 4951, 4955, 4962, 4973, 4976, 4978, 4995, 5012, 5014, 5024, 5025, 5047, 5049, 5050, 5076, 5104, 5110, 5114, 5144, 5150, 5156, 5169, 5181, 5194, 5202, 5206, 5227, 5229, 5232, 5233, 5249, 5256, 5266, 5277, 5287, 5301, 5302, 5304, 5315, 5355, 5366, 5377, 5383, 5384, 5403, 5410, 5414, 5418, 5430, 5461, 5464, 5494, 5497, 5513, 5518, 5523, 5524, 5534, 5541, 5554, 5561, 5606, 5612, 5619, 5623, 5625, 5655, 5676, 5678, 5684, 5692, 5700, 5727, 5740, 5752, 5758, 5759, 5783, 5804, 5815, 5824, 5832, 5835, 5842, 5849, 5853, 5858, 5866, 5873, 5878, 5879, 5880, 5887, 5900, 5902, 5924, 5968, 5973, 5983, 5996, 6000, 6010, 6033, 6066, 6069, 6070, 6080, 6109, 6111, 6112, 6120, 6130, 6139, 6158, 6167, 6178, 6194, 6208, 6221, 6225, 6236, 6241, 6246, 6249, 6256, 6268, 6276, 6288, 6292, 6297, 6300, 6301, 6321, 6324, 6341, 6344, 6382, 6390, 6394, 6397, 6416, 6419, 6433, 6441, 6443, 6451, 6452, 6462, 6476, 6500, 6503, 6509, 6524, 6538, 6553, 6554, 6568, 6611, 6616, 6626, 6631, 6676, 6683, 6719, 6720, 6721, 6725, 6730, 6762, 6798, 6799, 6804, 6827, 6836, 6845, 6857, 6886, 6889, 6909, 6917, 6930, 6931, 6937, 6945, 6946, 6948, 6957, 6975, 6980, 6992, 7005, 7010, 7021, 7075, 7087, 7091, 7119, 7121, 7136, 7153, 7180, 7181, 7187, 7194, 7206, 7215, 7221, 7235, 7236, 7267, 7288, 7297, 7299, 7311, 7329, 7333, 7342, 7347, 7350, 7365, 7375, 7380, 7386, 7390, 7400, 7405, 7410, 7434, 7435, 7445, 7457, 7467, 7469, 7471, 7481, 7504, 7507, 7514, 7518, 7519, 7551, 7552, 7554, 7555, 7564, 7568, 7576, 7582, 7591, 7612, 7629, 7643, 7646, 7654, 7658, 7664, 7665, 7675, 7682, 7683, 7692, 7701, 7717, 7725, 7726, 7734, 7750, 7758, 7760, 7770, 7778, 7783, 7820, 7829, 7854, 7859, 7866, 7880, 7881, 7890, 7891, 7899, 7908, 7910, 7927, 7951, 7987, 7992, 7995, 8003, 8010, 8016, 8027, 8032, 8047, 8059, 8067, 8100, 8125, 8133, 8138, 8148, 8154, 8160, 8165, 8173, 8176, 8181, 8213, 8235, 8247, 8262, 8273, 8299, 8300, 8309, 8310, 8322, 8327, 8341, 8346, 8357, 8365, 8377, 8403, 8421, 8448, 8454, 8460, 8469, 8471, 8474, 8480, 8511, 8517, 8519, 8521, 8532, 8535, 8541, 8543, 8556, 8558, 8588, 8609, 8617, 8641, 8647, 8683, 8716, 8727, 8739, 8744, 8750, 8760, 8761, 8785, 8790, 8802, 8811, 8812, 8826, 8830, 8848, 8859, 8861, 8866, 8876, 8878, 8887, 8889, 8892, 8893, 8900, 8902, 8908, 8948, 8962, 8971, 8973, 8976, 9049, 9051, 9053, 9064, 9066, 9082, 9100, 9103, 9111, 9124, 9134, 9155, 9157, 9199, 9202, 9209, 9255, 9256, 9258, 9354, 9362, 9369, 9373, 9382, 9388, 9436, 9452, 9456, 9472, 9497, 9500, 9539, 9549, 9555, 9556, 9572, 9573, 9577, 9587, 9590, 9598, 9601, 9612, 9627, 9640, 9644, 9652, 9656, 9663, 9670, 9673, 9674, 9680, 9684, 9698, 9704, 9708, 9724, 9751, 9756, 9792, 9796, 9804, 9816, 9833, 9844, 9848, 9879, 9892, 9897, 9903, 9913]
853 SVs (with labels):
Training time for 3.0-vs-8.0: 493.968806028 seconds
Begin training classifier for label 3.0 and label 9.0 at 2016-05-20, 02:14:17
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10083, 784) (10083,)
(10083, 784) (10083,)
     pcost       dcost       gap    pres   dres
 0: -1.2982e+03 -2.5464e+04  2e+05  3e+00  2e-11
 1: -8.1193e+02 -1.5857e+04  3e+04  5e-01  2e-11
 2: -5.1926e+02 -6.2470e+03  1e+04  2e-01  1e-11
 3: -3.7620e+02 -3.3154e+03  5e+03  7e-02  9e-12
 4: -2.6775e+02 -1.8471e+03  3e+03  3e-02  7e-12
 5: -2.0678e+02 -1.3096e+03  2e+03  2e-02  5e-12
 6: -1.5921e+02 -8.4524e+02  1e+03  9e-03  5e-12
 7: -1.4837e+02 -4.8292e+02  5e+02  3e-03  5e-12
 8: -1.5216e+02 -3.0706e+02  2e+02  6e-04  5e-12
 9: -1.6487e+02 -2.5323e+02  1e+02  2e-04  5e-12
10: -1.6980e+02 -2.2997e+02  6e+01  5e-05  5e-12
11: -1.7840e+02 -2.0868e+02  3e+01  4e-06  5e-12
12: -1.8499e+02 -1.9849e+02  1e+01  1e-06  5e-12
13: -1.8761e+02 -1.9401e+02  6e+00  9e-15  6e-12
14: -1.8987e+02 -1.9135e+02  1e+00  3e-13  6e-12
15: -1.9049e+02 -1.9065e+02  2e-01  2e-13  6e-12
16: -1.9057e+02 -1.9057e+02  4e-03  6e-13  6e-12
17: -1.9057e+02 -1.9057e+02  5e-05  5e-13  6e-12
Optimal solution found.
sv_indices: [6, 9, 17, 91, 92, 158, 169, 242, 255, 337, 342, 348, 361, 375, 437, 439, 460, 507, 537, 546, 547, 548, 578, 616, 626, 632, 635, 644, 658, 687, 794, 856, 857, 860, 862, 886, 887, 978, 981, 984, 1022, 1031, 1037, 1042, 1065, 1111, 1132, 1146, 1202, 1203, 1232, 1237, 1281, 1287, 1290, 1325, 1331, 1368, 1382, 1395, 1434, 1462, 1482, 1499, 1515, 1520, 1523, 1525, 1529, 1536, 1556, 1560, 1576, 1646, 1669, 1693, 1696, 1706, 1752, 1801, 1831, 1840, 1865, 1868, 1889, 1894, 1992, 2012, 2053, 2091, 2102, 2105, 2107, 2142, 2221, 2230, 2246, 2273, 2293, 2307, 2319, 2339, 2345, 2348, 2408, 2443, 2445, 2449, 2469, 2484, 2509, 2524, 2526, 2529, 2557, 2592, 2646, 2675, 2688, 2715, 2741, 2751, 2789, 2827, 2843, 2848, 2862, 2930, 2994, 3000, 3016, 3039, 3050, 3070, 3073, 3161, 3217, 3219, 3225, 3245, 3261, 3299, 3312, 3335, 3388, 3395, 3406, 3428, 3440, 3443, 3448, 3505, 3514, 3517, 3541, 3544, 3560, 3563, 3581, 3604, 3619, 3630, 3692, 3734, 3745, 3750, 3770, 3802, 3818, 3843, 3851, 3904, 3933, 3945, 3956, 3964, 4009, 4054, 4153, 4210, 4212, 4221, 4265, 4279, 4293, 4337, 4364, 4389, 4443, 4485, 4538, 4547, 4551, 4574, 4629, 4660, 4673, 4675, 4702, 4732, 4744, 4756, 4767, 4779, 4783, 4785, 4786, 4799, 4819, 4838, 4847, 4898, 4919, 4978, 4984, 4995, 5014, 5018, 5033, 5114, 5120, 5172, 5227, 5261, 5277, 5278, 5308, 5323, 5342, 5370, 5411, 5455, 5496, 5523, 5528, 5536, 5568, 5588, 5617, 5619, 5655, 5677, 5692, 5764, 5813, 5816, 5848, 5943, 5949, 5952, 5972, 5982, 5984, 5994, 6008, 6029, 6039, 6059, 6064, 6097, 6113, 6174, 6181, 6186, 6193, 6204, 6209, 6220, 6225, 6226, 6257, 6262, 6301, 6337, 6391, 6430, 6475, 6479, 6519, 6520, 6591, 6605, 6628, 6675, 6680, 6686, 6698, 6713, 6747, 6749, 6823, 6837, 6850, 6867, 6883, 6887, 6985, 6992, 6995, 7057, 7063, 7116, 7127, 7135, 7136, 7154, 7159, 7164, 7178, 7207, 7222, 7246, 7269, 7274, 7282, 7331, 7339, 7357, 7362, 7386, 7395, 7400, 7465, 7472, 7525, 7544, 7577, 7595, 7646, 7647, 7651, 7663, 7727, 7754, 7784, 7824, 7825, 7831, 7858, 7860, 7861, 7874, 7904, 7918, 7921, 7968, 7995, 8000, 8009, 8020, 8060, 8063, 8070, 8075, 8078, 8107, 8119, 8126, 8135, 8147, 8196, 8219, 8260, 8264, 8282, 8293, 8307, 8317, 8371, 8387, 8520, 8550, 8578, 8580, 8595, 8626, 8686, 8705, 8723, 8762, 8829, 8848, 8874, 8876, 8915, 8920, 8945, 8958, 8964, 8970, 9007, 9063, 9069, 9078, 9097, 9106, 9153, 9248, 9272, 9280, 9298, 9301, 9328, 9360, 9371, 9384, 9419, 9501, 9508, 9514, 9520, 9522, 9523, 9529, 9570, 9606, 9609, 9665, 9668, 9670, 9694, 9749, 9751, 9768, 9806, 9847, 9899, 9950, 9952, 10046, 10055, 10079]
432 SVs (with labels):
Training time for 3.0-vs-9.0: 480.613436937 seconds
Begin training classifier for label 4.0 and label 5.0 at 2016-05-20, 02:22:18
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9378, 784) (9378,)
(9378, 784) (9378,)
     pcost       dcost       gap    pres   dres
 0: -1.0249e+03 -2.3044e+04  1e+05  3e+00  1e-11
 1: -6.1620e+02 -1.4100e+04  3e+04  5e-01  1e-11
 2: -3.2183e+02 -4.4544e+03  7e+03  1e-01  6e-12
 3: -2.0984e+02 -2.4270e+03  4e+03  6e-02  4e-12
 4: -1.2958e+02 -1.3162e+03  2e+03  3e-02  3e-12
 5: -8.7358e+01 -9.1702e+02  1e+03  1e-02  2e-12
 6: -6.5787e+01 -6.5595e+02  1e+03  9e-03  2e-12
 7: -4.1334e+01 -4.6818e+02  7e+02  5e-03  1e-12
 8: -3.3363e+01 -1.7674e+02  2e+02  9e-04  1e-12
 9: -4.1221e+01 -1.0786e+02  8e+01  3e-04  1e-12
10: -4.1177e+01 -8.7210e+01  5e+01  2e-06  2e-12
11: -4.8464e+01 -7.3943e+01  3e+01  1e-06  1e-12
12: -5.4266e+01 -6.3323e+01  9e+00  1e-07  2e-12
13: -5.6622e+01 -5.9718e+01  3e+00  2e-08  2e-12
14: -5.7428e+01 -5.8566e+01  1e+00  1e-13  2e-12
15: -5.7939e+01 -5.8007e+01  7e-02  7e-14  2e-12
16: -5.7971e+01 -5.7972e+01  1e-03  2e-13  2e-12
17: -5.7971e+01 -5.7971e+01  1e-05  1e-13  2e-12
Optimal solution found.
sv_indices: [28, 103, 105, 182, 190, 198, 216, 222, 231, 295, 298, 314, 426, 443, 487, 493, 619, 620, 681, 705, 741, 763, 768, 873, 971, 1007, 1022, 1077, 1090, 1121, 1133, 1165, 1264, 1282, 1349, 1398, 1411, 1439, 1454, 1481, 1493, 1545, 1564, 1634, 1664, 1677, 1778, 1780, 1790, 1792, 1859, 1877, 1888, 1892, 1894, 1896, 2062, 2084, 2087, 2140, 2229, 2252, 2267, 2295, 2390, 2409, 2447, 2469, 2489, 2531, 2574, 2614, 2626, 2642, 2653, 2731, 2742, 2782, 2785, 2796, 2819, 2975, 3076, 3119, 3140, 3167, 3318, 3325, 3333, 3365, 3402, 3467, 3468, 3478, 3494, 3507, 3563, 3584, 3616, 3637, 3645, 3656, 3868, 3959, 4045, 4176, 4192, 4201, 4233, 4253, 4280, 4286, 4424, 4447, 4461, 4503, 4558, 4680, 4831, 4859, 4887, 4914, 4925, 4928, 4967, 4969, 5005, 5020, 5050, 5077, 5108, 5143, 5150, 5384, 5441, 5442, 5445, 5514, 5541, 5560, 5573, 5594, 5598, 5610, 5617, 5656, 5722, 5755, 5766, 5791, 5823, 5882, 5887, 5915, 5978, 6029, 6058, 6081, 6110, 6124, 6154, 6166, 6205, 6229, 6309, 6324, 6352, 6360, 6362, 6383, 6450, 6475, 6503, 6526, 6543, 6597, 6598, 6666, 6672, 6689, 6712, 6726, 6752, 6777, 6821, 6866, 6876, 6959, 6980, 6982, 6996, 7005, 7038, 7050, 7101, 7132, 7171, 7197, 7203, 7223, 7280, 7298, 7344, 7425, 7444, 7465, 7472, 7489, 7540, 7610, 7626, 7652, 7695, 7708, 7715, 7747, 7779, 7814, 7829, 7867, 7885, 7916, 7944, 8015, 8087, 8135, 8148, 8151, 8172, 8234, 8266, 8315, 8316, 8346, 8376, 8416, 8424, 8442, 8472, 8478, 8511, 8553, 8605, 8657, 8659, 8729, 8844, 8863, 8886, 8912, 9004, 9020, 9040, 9086, 9099, 9106, 9120, 9183, 9198, 9203, 9238, 9283, 9326, 9329, 9349]
265 SVs (with labels):
Training time for 4.0-vs-5.0: 395.376960993 seconds
Begin training classifier for label 4.0 and label 6.0 at 2016-05-20, 02:28:53
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9790, 784) (9790,)
(9790, 784) (9790,)
     pcost       dcost       gap    pres   dres
 0: -7.9044e+02 -2.0329e+04  1e+05  3e+00  1e-11
 1: -4.8299e+02 -1.1382e+04  2e+04  4e-01  1e-11
 2: -2.8055e+02 -4.5846e+03  8e+03  1e-01  7e-12
 3: -1.6182e+02 -1.7324e+03  3e+03  4e-02  5e-12
 4: -1.1346e+02 -9.7373e+02  1e+03  2e-02  3e-12
 5: -8.4024e+01 -5.8133e+02  8e+02  1e-02  3e-12
 6: -6.7854e+01 -3.2731e+02  4e+02  4e-03  2e-12
 7: -6.3974e+01 -1.5599e+02  1e+02  1e-03  2e-12
 8: -6.7112e+01 -9.6608e+01  3e+01  8e-05  2e-12
 9: -6.9914e+01 -8.7995e+01  2e+01  2e-05  2e-12
10: -7.3508e+01 -8.1136e+01  8e+00  3e-06  2e-12
11: -7.5226e+01 -7.8340e+01  3e+00  3e-07  3e-12
12: -7.6290e+01 -7.6961e+01  7e-01  1e-08  3e-12
13: -7.6538e+01 -7.6677e+01  1e-01  8e-14  3e-12
14: -7.6604e+01 -7.6606e+01  2e-03  6e-14  3e-12
15: -7.6605e+01 -7.6605e+01  3e-05  3e-16  3e-12
Optimal solution found.
sv_indices: [81, 102, 103, 105, 125, 181, 190, 201, 204, 222, 225, 255, 292, 314, 401, 402, 485, 486, 493, 562, 575, 577, 579, 596, 620, 635, 656, 763, 830, 863, 893, 961, 980, 1009, 1010, 1087, 1097, 1102, 1151, 1208, 1270, 1291, 1342, 1353, 1399, 1411, 1439, 1455, 1475, 1493, 1545, 1615, 1640, 1664, 1674, 1684, 1747, 1754, 1778, 1835, 1871, 1896, 2044, 2086, 2091, 2125, 2150, 2174, 2218, 2219, 2221, 2229, 2235, 2238, 2252, 2267, 2272, 2291, 2310, 2313, 2409, 2413, 2419, 2453, 2497, 2530, 2531, 2534, 2542, 2584, 2599, 2634, 2642, 2667, 2731, 2782, 2796, 2858, 2877, 2936, 2938, 3026, 3037, 3051, 3098, 3114, 3137, 3167, 3212, 3318, 3325, 3333, 3365, 3392, 3402, 3405, 3433, 3435, 3445, 3454, 3602, 3619, 3621, 3686, 3688, 3697, 3739, 3765, 3819, 3896, 3904, 4020, 4115, 4127, 4174, 4192, 4193, 4282, 4367, 4489, 4499, 4512, 4595, 4716, 4834, 4857, 4904, 4987, 5038, 5099, 5152, 5180, 5299, 5335, 5365, 5377, 5379, 5391, 5504, 5507, 5514, 5543, 5562, 5621, 5650, 5666, 5685, 5692, 5712, 5714, 5785, 5806, 5860, 5871, 5919, 5956, 5964, 6004, 6104, 6111, 6129, 6144, 6159, 6182, 6224, 6253, 6257, 6278, 6345, 6385, 6496, 6501, 6527, 6647, 6697, 6750, 6770, 6806, 6815, 6820, 6830, 6846, 6863, 6903, 6948, 7003, 7004, 7040, 7058, 7059, 7069, 7098, 7116, 7154, 7182, 7188, 7219, 7223, 7284, 7345, 7366, 7376, 7393, 7417, 7471, 7516, 7524, 7548, 7564, 7589, 7613, 7674, 7686, 7754, 7787, 7803, 7839, 7920, 7937, 7983, 8043, 8057, 8163, 8177, 8207, 8233, 8282, 8292, 8323, 8356, 8370, 8428, 8433, 8459, 8472, 8482, 8513, 8515, 8540, 8567, 8631, 8670, 8728, 8743, 8746, 8755, 8762, 8806, 8856, 8872, 8918, 8924, 8946, 8995, 9006, 9049, 9190, 9195, 9202, 9216, 9256, 9266, 9329, 9347, 9376, 9414, 9417, 9612, 9632, 9687, 9785]
291 SVs (with labels):
Training time for 4.0-vs-6.0: 400.033046961 seconds
Begin training classifier for label 4.0 and label 7.0 at 2016-05-20, 02:35:33
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10106, 784) (10106,)
(10106, 784) (10106,)
     pcost       dcost       gap    pres   dres
 0: -1.3047e+03 -2.4958e+04  2e+05  3e+00  2e-11
 1: -8.1234e+02 -1.5341e+04  3e+04  5e-01  2e-11
 2: -4.8034e+02 -5.2848e+03  9e+03  1e-01  1e-11
 3: -3.1995e+02 -2.8490e+03  4e+03  6e-02  7e-12
 4: -2.2845e+02 -1.6769e+03  3e+03  3e-02  5e-12
 5: -1.6195e+02 -1.3020e+03  2e+03  2e-02  4e-12
 6: -1.1949e+02 -9.1633e+02  1e+03  1e-02  3e-12
 7: -1.0133e+02 -4.7655e+02  6e+02  4e-03  3e-12
 8: -9.3810e+01 -2.4066e+02  2e+02  1e-03  3e-12
 9: -9.8179e+01 -1.5113e+02  5e+01  4e-13  3e-12
10: -1.0706e+02 -1.3463e+02  3e+01  1e-13  3e-12
11: -1.1191e+02 -1.2523e+02  1e+01  1e-14  3e-12
12: -1.1442e+02 -1.2088e+02  6e+00  2e-13  3e-12
13: -1.1669e+02 -1.1822e+02  2e+00  5e-13  3e-12
14: -1.1735e+02 -1.1747e+02  1e-01  3e-14  3e-12
15: -1.1740e+02 -1.1740e+02  2e-03  3e-13  3e-12
16: -1.1740e+02 -1.1740e+02  3e-05  6e-14  3e-12
Optimal solution found.
sv_indices: [35, 36, 52, 57, 77, 109, 174, 183, 192, 197, 243, 260, 283, 289, 294, 314, 322, 332, 347, 384, 385, 402, 415, 469, 472, 492, 493, 594, 616, 619, 633, 634, 649, 665, 744, 759, 783, 794, 803, 807, 858, 863, 892, 1001, 1090, 1094, 1103, 1112, 1174, 1189, 1204, 1258, 1264, 1315, 1339, 1342, 1383, 1439, 1453, 1456, 1461, 1462, 1467, 1481, 1498, 1500, 1501, 1608, 1616, 1634, 1641, 1649, 1677, 1727, 1825, 1843, 1849, 1871, 1903, 1966, 1991, 2004, 2061, 2120, 2155, 2164, 2186, 2239, 2272, 2299, 2310, 2312, 2318, 2369, 2375, 2392, 2394, 2416, 2428, 2456, 2459, 2473, 2499, 2516, 2572, 2653, 2734, 2770, 2773, 2785, 2791, 2862, 2894, 2896, 2904, 2936, 2987, 3015, 3044, 3056, 3063, 3076, 3079, 3098, 3110, 3136, 3213, 3254, 3287, 3303, 3318, 3347, 3377, 3425, 3435, 3497, 3516, 3536, 3604, 3607, 3618, 3621, 3656, 3721, 3766, 3803, 3816, 3844, 3856, 3959, 3969, 4035, 4038, 4041, 4048, 4082, 4083, 4121, 4131, 4167, 4168, 4253, 4299, 4306, 4365, 4376, 4401, 4463, 4464, 4465, 4512, 4537, 4542, 4579, 4623, 4624, 4626, 4646, 4682, 4702, 4762, 4772, 4773, 4831, 4836, 4904, 4998, 5051, 5053, 5057, 5064, 5071, 5131, 5184, 5236, 5329, 5387, 5401, 5530, 5541, 5623, 5625, 5626, 5630, 5706, 5732, 5779, 5863, 5890, 5910, 6045, 6048, 6070, 6071, 6107, 6109, 6129, 6176, 6177, 6181, 6278, 6355, 6385, 6417, 6429, 6548, 6554, 6638, 6643, 6675, 6679, 6694, 6698, 6728, 6852, 6903, 6922, 6924, 6989, 7010, 7080, 7114, 7119, 7121, 7155, 7157, 7170, 7351, 7359, 7392, 7495, 7521, 7566, 7581, 7609, 7615, 7634, 7761, 7809, 7844, 7846, 7851, 7868, 7889, 7930, 7944, 7964, 7973, 7981, 8036, 8047, 8050, 8058, 8129, 8158, 8207, 8228, 8253, 8259, 8296, 8371, 8483, 8577, 8591, 8595, 8658, 8688, 8806, 8890, 9008, 9014, 9033, 9049, 9065, 9092, 9120, 9124, 9168, 9173, 9186, 9209, 9232, 9322, 9431, 9495, 9511, 9545, 9577, 9583, 9606, 9745, 9754, 9777, 9811, 9904, 9905, 9914, 9936, 9970, 10044, 10058, 10072, 10073]
323 SVs (with labels):
Training time for 4.0-vs-7.0: 448.788909912 seconds
Begin training classifier for label 4.0 and label 8.0 at 2016-05-20, 02:43:02
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9718, 784) (9718,)
(9718, 784) (9718,)
     pcost       dcost       gap    pres   dres
 0: -9.7875e+02 -2.2355e+04  1e+05  3e+00  2e-11
 1: -5.9084e+02 -1.3200e+04  3e+04  4e-01  1e-11
 2: -3.0880e+02 -4.4078e+03  7e+03  1e-01  8e-12
 3: -1.7812e+02 -1.9427e+03  3e+03  5e-02  5e-12
 4: -1.2599e+02 -1.3085e+03  2e+03  3e-02  4e-12
 5: -8.7931e+01 -9.5463e+02  1e+03  2e-02  3e-12
 6: -5.8760e+01 -6.8442e+02  1e+03  1e-02  2e-12
 7: -3.8909e+01 -4.2362e+02  6e+02  5e-03  2e-12
 8: -2.6246e+01 -3.2504e+02  5e+02  3e-03  1e-12
 9: -2.3180e+01 -1.3138e+02  1e+02  7e-04  1e-12
10: -2.7827e+01 -7.7810e+01  5e+01  9e-05  1e-12
11: -3.4033e+01 -6.0340e+01  3e+01  3e-05  1e-12
12: -3.6424e+01 -5.2493e+01  2e+01  3e-06  2e-12
13: -4.0029e+01 -4.6727e+01  7e+00  8e-07  2e-12
14: -4.1987e+01 -4.3684e+01  2e+00  2e-08  2e-12
15: -4.2630e+01 -4.2920e+01  3e-01  1e-09  2e-12
16: -4.2764e+01 -4.2770e+01  6e-03  1e-11  2e-12
17: -4.2767e+01 -4.2767e+01  8e-05  1e-13  2e-12
18: -4.2767e+01 -4.2767e+01  9e-07  3e-13  2e-12
Optimal solution found.
sv_indices: [77, 103, 105, 124, 164, 182, 197, 208, 222, 314, 326, 347, 352, 385, 410, 469, 485, 493, 612, 660, 674, 677, 744, 763, 769, 863, 873, 959, 963, 1208, 1264, 1345, 1347, 1411, 1414, 1429, 1439, 1454, 1483, 1493, 1699, 1778, 1780, 1790, 1843, 1871, 1957, 1990, 2062, 2155, 2197, 2219, 2229, 2295, 2305, 2456, 2489, 2570, 2572, 2637, 2642, 2667, 2734, 2735, 2751, 2809, 2832, 2929, 2958, 3039, 3044, 3079, 3113, 3167, 3220, 3318, 3325, 3333, 3377, 3383, 3402, 3430, 3478, 3507, 3550, 3563, 3700, 3729, 3758, 3816, 3889, 3896, 3904, 3919, 3920, 4050, 4084, 4127, 4174, 4192, 4233, 4280, 4284, 4316, 4365, 4423, 4458, 4491, 4499, 4503, 4577, 4799, 4831, 4878, 4879, 4889, 4927, 4929, 4930, 4932, 4966, 4970, 4993, 4996, 5002, 5024, 5090, 5152, 5185, 5193, 5207, 5286, 5318, 5414, 5508, 5554, 5570, 5622, 5640, 5668, 5689, 5803, 5847, 5872, 6044, 6057, 6090, 6097, 6217, 6239, 6269, 6278, 6330, 6411, 6423, 6433, 6447, 6532, 6640, 6782, 6794, 6907, 6968, 7007, 7057, 7058, 7098, 7099, 7215, 7237, 7295, 7347, 7442, 7549, 7562, 7568, 7629, 7654, 7682, 7719, 7772, 7800, 7832, 7887, 7950, 8021, 8064, 8078, 8143, 8170, 8193, 8198, 8226, 8247, 8266, 8279, 8297, 8305, 8329, 8363, 8440, 8522, 8592, 8605, 8658, 8676, 8689, 8695, 8701, 8748, 8750, 8762, 8775, 8905, 8967, 8978, 9004, 9019, 9047, 9064, 9133, 9134, 9141, 9166, 9201, 9207, 9266, 9270, 9286, 9331, 9346, 9357, 9429, 9510, 9520, 9534, 9559, 9642, 9644]
239 SVs (with labels):
Training time for 4.0-vs-8.0: 461.739077091 seconds
Begin training classifier for label 4.0 and label 9.0 at 2016-05-20, 02:50:44
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9885, 784) (9885,)
(9885, 784) (9885,)
     pcost       dcost       gap    pres   dres
 0: -1.8170e+03 -2.6549e+04  2e+05  4e+00  3e-11
 1: -1.1549e+03 -1.7392e+04  4e+04  6e-01  3e-11
 2: -7.9500e+02 -7.3762e+03  1e+04  2e-01  2e-11
 3: -6.0783e+02 -4.1237e+03  6e+03  8e-02  1e-11
 4: -4.8957e+02 -2.3593e+03  3e+03  3e-02  1e-11
 5: -4.5001e+02 -1.6368e+03  2e+03  2e-02  1e-11
 6: -4.3064e+02 -1.1052e+03  9e+02  7e-03  1e-11
 7: -4.5436e+02 -7.9290e+02  4e+02  3e-03  1e-11
 8: -4.6653e+02 -6.6463e+02  2e+02  8e-04  1e-11
 9: -4.8201e+02 -5.9742e+02  1e+02  2e-04  1e-11
10: -4.9431e+02 -5.6912e+02  8e+01  8e-05  1e-11
11: -5.0605e+02 -5.4248e+02  4e+01  3e-13  1e-11
12: -5.1392e+02 -5.3183e+02  2e+01  1e-12  1e-11
13: -5.1745e+02 -5.2681e+02  9e+00  8e-13  1e-11
14: -5.2036e+02 -5.2326e+02  3e+00  1e-13  1e-11
15: -5.2144e+02 -5.2205e+02  6e-01  5e-13  1e-11
16: -5.2169e+02 -5.2178e+02  1e-01  5e-14  1e-11
17: -5.2173e+02 -5.2173e+02  3e-03  7e-13  1e-11
18: -5.2173e+02 -5.2173e+02  4e-05  4e-13  1e-11
Optimal solution found.
sv_indices: [23, 77, 84, 91, 105, 109, 116, 153, 154, 167, 174, 183, 197, 198, 216, 221, 231, 243, 248, 250, 283, 289, 309, 311, 314, 322, 339, 343, 347, 364, 365, 375, 384, 385, 396, 414, 419, 420, 426, 436, 438, 469, 472, 490, 493, 520, 536, 548, 590, 598, 612, 616, 619, 633, 634, 660, 671, 738, 742, 750, 759, 797, 798, 802, 816, 826, 838, 873, 892, 903, 909, 931, 939, 941, 958, 959, 966, 968, 969, 972, 981, 1009, 1068, 1104, 1112, 1131, 1133, 1149, 1153, 1171, 1192, 1204, 1208, 1218, 1226, 1256, 1258, 1264, 1280, 1293, 1297, 1304, 1315, 1341, 1352, 1353, 1368, 1383, 1385, 1406, 1412, 1421, 1429, 1439, 1443, 1467, 1481, 1482, 1483, 1493, 1497, 1498, 1501, 1545, 1596, 1601, 1608, 1616, 1627, 1631, 1634, 1641, 1656, 1668, 1669, 1726, 1739, 1780, 1801, 1802, 1813, 1814, 1825, 1827, 1840, 1843, 1857, 1858, 1859, 1867, 1871, 1884, 1898, 1918, 1924, 1940, 1943, 1963, 1964, 1966, 1991, 2003, 2004, 2010, 2012, 2026, 2043, 2048, 2059, 2072, 2077, 2088, 2130, 2150, 2155, 2219, 2239, 2262, 2295, 2298, 2301, 2312, 2316, 2350, 2363, 2369, 2375, 2395, 2406, 2411, 2416, 2426, 2428, 2430, 2448, 2456, 2461, 2463, 2473, 2476, 2479, 2490, 2499, 2516, 2543, 2550, 2553, 2572, 2574, 2580, 2631, 2639, 2649, 2653, 2658, 2660, 2697, 2701, 2703, 2725, 2734, 2735, 2751, 2770, 2779, 2785, 2809, 2830, 2832, 2840, 2848, 2851, 2868, 2882, 2897, 2904, 2910, 2922, 2926, 2946, 2965, 2968, 3028, 3039, 3044, 3056, 3079, 3110, 3117, 3123, 3137, 3140, 3166, 3167, 3175, 3195, 3198, 3213, 3220, 3221, 3233, 3244, 3251, 3254, 3257, 3303, 3317, 3318, 3325, 3333, 3345, 3357, 3358, 3386, 3394, 3408, 3425, 3426, 3430, 3473, 3477, 3478, 3494, 3507, 3516, 3523, 3572, 3589, 3599, 3607, 3618, 3621, 3623, 3646, 3648, 3655, 3656, 3662, 3666, 3702, 3706, 3709, 3739, 3746, 3747, 3748, 3757, 3761, 3766, 3775, 3781, 3798, 3803, 3825, 3826, 3833, 3840, 3844, 3848, 3853, 3884, 3896, 3931, 3941, 4002, 4030, 4037, 4059, 4082, 4083, 4096, 4099, 4115, 4120, 4122, 4137, 4153, 4157, 4162, 4167, 4174, 4176, 4177, 4211, 4231, 4243, 4277, 4284, 4295, 4297, 4315, 4325, 4334, 4349, 4365, 4370, 4376, 4385, 4395, 4408, 4418, 4434, 4441, 4442, 4457, 4461, 4463, 4464, 4468, 4476, 4481, 4503, 4510, 4512, 4535, 4561, 4579, 4584, 4628, 4669, 4672, 4678, 4680, 4682, 4702, 4704, 4712, 4719, 4734, 4762, 4773, 4784, 4792, 4808, 4819, 4825, 4831, 4838, 4873, 4887, 4894, 4908, 4914, 4917, 4919, 4920, 4924, 4943, 4956, 4986, 4996, 5000, 5007, 5012, 5020, 5026, 5028, 5034, 5049, 5073, 5101, 5106, 5127, 5187, 5190, 5199, 5243, 5268, 5270, 5273, 5276, 5277, 5280, 5301, 5318, 5351, 5377, 5384, 5399, 5409, 5427, 5438, 5443, 5453, 5457, 5472, 5483, 5499, 5500, 5506, 5515, 5539, 5544, 5545, 5548, 5561, 5575, 5584, 5601, 5603, 5619, 5632, 5658, 5689, 5691, 5709, 5710, 5717, 5720, 5735, 5736, 5750, 5771, 5793, 5803, 5824, 5827, 5835, 5839, 5843, 5851, 5857, 5881, 5915, 5931, 5938, 5939, 5961, 5962, 5964, 5974, 5988, 6002, 6011, 6042, 6047, 6055, 6061, 6083, 6091, 6104, 6107, 6117, 6120, 6133, 6135, 6142, 6151, 6162, 6163, 6170, 6175, 6179, 6195, 6207, 6226, 6246, 6259, 6267, 6269, 6285, 6292, 6319, 6399, 6425, 6467, 6482, 6489, 6490, 6498, 6570, 6573, 6588, 6591, 6594, 6598, 6602, 6642, 6653, 6661, 6698, 6708, 6759, 6765, 6772, 6773, 6781, 6797, 6806, 6808, 6811, 6816, 6819, 6859, 6862, 6889, 6901, 6953, 6994, 7007, 7012, 7034, 7050, 7054, 7083, 7085, 7088, 7094, 7129, 7146, 7178, 7238, 7259, 7267, 7269, 7293, 7306, 7310, 7311, 7312, 7335, 7339, 7358, 7367, 7398, 7409, 7433, 7440, 7447, 7453, 7465, 7471, 7493, 7517, 7527, 7528, 7542, 7544, 7575, 7592, 7610, 7626, 7667, 7679, 7702, 7705, 7716, 7717, 7736, 7747, 7763, 7769, 7770, 7772, 7777, 7798, 7830, 7831, 7832, 7833, 7846, 7855, 7860, 7864, 7869, 7880, 7884, 7887, 7893, 7895, 7910, 7912, 7919, 7927, 7940, 7945, 7987, 7999, 8003, 8004, 8005, 8010, 8014, 8032, 8033, 8049, 8070, 8083, 8124, 8126, 8127, 8157, 8169, 8180, 8181, 8184, 8201, 8209, 8213, 8230, 8240, 8250, 8258, 8262, 8289, 8300, 8330, 8337, 8349, 8356, 8367, 8368, 8372, 8380, 8399, 8416, 8418, 8431, 8448, 8510, 8543, 8549, 8561, 8578, 8602, 8608, 8614, 8638, 8664, 8683, 8688, 8691, 8711, 8736, 8738, 8742, 8760, 8761, 8774, 8806, 8816, 8823, 8838, 8849, 8858, 8862, 8871, 8900, 8920, 8931, 8940, 8946, 8947, 8953, 8958, 8960, 8972, 8973, 8980, 8989, 8997, 9006, 9013, 9050, 9069, 9079, 9111, 9123, 9128, 9132, 9151, 9169, 9170, 9179, 9183, 9201, 9208, 9211, 9214, 9220, 9234, 9238, 9240, 9271, 9306, 9313, 9318, 9327, 9331, 9333, 9362, 9372, 9381, 9396, 9406, 9414, 9426, 9436, 9444, 9446, 9467, 9473, 9481, 9488, 9493, 9515, 9560, 9586, 9601, 9613, 9617, 9625, 9626, 9644, 9660, 9663, 9699, 9706, 9712, 9739, 9750, 9751, 9757, 9780, 9789, 9802, 9804, 9805, 9810, 9835, 9840, 9841, 9842, 9849, 9862, 9864]
796 SVs (with labels):
Training time for 4.0-vs-9.0: 488.841407061 seconds
Begin training classifier for label 5.0 and label 6.0 at 2016-05-20, 02:58:53
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9450, 784) (9450,)
(9450, 784) (9450,)
     pcost       dcost       gap    pres   dres
 0: -1.3842e+03 -2.4268e+04  2e+05  3e+00  2e-11
 1: -8.6978e+02 -1.5293e+04  3e+04  5e-01  2e-11
 2: -5.9050e+02 -6.4820e+03  1e+04  2e-01  1e-11
 3: -4.4841e+02 -3.7859e+03  6e+03  9e-02  1e-11
 4: -3.2746e+02 -2.2196e+03  3e+03  4e-02  7e-12
 5: -2.7793e+02 -1.6961e+03  2e+03  3e-02  6e-12
 6: -2.2855e+02 -1.1430e+03  1e+03  1e-02  5e-12
 7: -1.9917e+02 -8.8589e+02  1e+03  8e-03  5e-12
 8: -1.9569e+02 -4.8154e+02  4e+02  3e-03  5e-12
 9: -2.0384e+02 -3.1047e+02  1e+02  3e-04  6e-12
10: -2.0886e+02 -2.8710e+02  8e+01  1e-04  5e-12
11: -2.2306e+02 -2.5693e+02  3e+01  3e-05  6e-12
12: -2.2839e+02 -2.4582e+02  2e+01  6e-06  6e-12
13: -2.3353e+02 -2.3799e+02  4e+00  1e-07  6e-12
14: -2.3480e+02 -2.3639e+02  2e+00  7e-13  7e-12
15: -2.3552e+02 -2.3560e+02  9e-02  4e-13  6e-12
16: -2.3555e+02 -2.3556e+02  2e-03  8e-14  6e-12
17: -2.3556e+02 -2.3556e+02  4e-05  7e-14  6e-12
Optimal solution found.
sv_indices: [27, 63, 66, 67, 146, 173, 175, 188, 218, 250, 300, 310, 375, 399, 448, 449, 455, 477, 509, 515, 525, 565, 582, 583, 586, 600, 650, 655, 657, 664, 674, 685, 694, 696, 704, 714, 725, 731, 739, 776, 779, 804, 807, 841, 842, 851, 855, 861, 922, 961, 964, 983, 992, 1001, 1020, 1023, 1037, 1055, 1065, 1081, 1088, 1097, 1113, 1116, 1119, 1129, 1131, 1157, 1170, 1178, 1189, 1197, 1222, 1307, 1345, 1380, 1393, 1399, 1412, 1440, 1450, 1451, 1482, 1503, 1507, 1534, 1544, 1551, 1554, 1563, 1588, 1590, 1591, 1592, 1607, 1608, 1621, 1684, 1687, 1711, 1712, 1714, 1727, 1736, 1753, 1757, 1802, 1830, 1834, 1849, 1853, 1855, 1856, 1873, 1918, 1945, 1963, 1969, 1979, 1984, 2007, 2017, 2031, 2066, 2078, 2090, 2095, 2121, 2123, 2146, 2157, 2176, 2257, 2334, 2359, 2380, 2390, 2393, 2418, 2421, 2429, 2450, 2503, 2504, 2506, 2542, 2543, 2558, 2589, 2604, 2642, 2659, 2675, 2681, 2726, 2750, 2764, 2767, 2796, 2821, 2835, 2836, 2837, 2868, 2921, 2933, 2942, 2960, 2997, 3008, 3031, 3042, 3048, 3057, 3070, 3085, 3156, 3218, 3228, 3276, 3312, 3333, 3357, 3359, 3395, 3406, 3487, 3523, 3546, 3551, 3554, 3560, 3565, 3581, 3587, 3588, 3602, 3610, 3625, 3652, 3694, 3707, 3728, 3786, 3789, 3866, 3893, 3900, 3924, 3957, 3993, 4016, 4024, 4027, 4053, 4072, 4097, 4128, 4145, 4163, 4168, 4218, 4279, 4298, 4302, 4324, 4344, 4376, 4410, 4457, 4479, 4497, 4533, 4548, 4550, 4560, 4647, 4674, 4680, 4733, 4761, 4777, 4789, 4795, 4810, 4842, 4855, 4879, 4883, 4913, 4924, 4925, 4949, 4960, 4961, 4963, 4964, 4980, 4982, 5017, 5025, 5029, 5050, 5118, 5139, 5140, 5174, 5177, 5191, 5223, 5225, 5232, 5240, 5251, 5256, 5281, 5283, 5331, 5391, 5395, 5444, 5455, 5466, 5475, 5487, 5503, 5520, 5534, 5535, 5547, 5579, 5598, 5616, 5627, 5632, 5638, 5666, 5673, 5680, 5689, 5696, 5710, 5721, 5766, 5789, 5791, 5801, 5822, 5843, 5856, 5890, 5906, 5919, 5928, 5932, 5938, 5943, 6040, 6045, 6055, 6071, 6133, 6161, 6214, 6221, 6239, 6253, 6274, 6301, 6302, 6310, 6331, 6357, 6360, 6403, 6419, 6438, 6442, 6466, 6474, 6478, 6483, 6523, 6528, 6549, 6653, 6673, 6724, 6729, 6741, 6748, 6754, 6758, 6806, 6811, 6816, 6821, 6848, 6870, 6871, 6883, 6900, 6943, 6959, 6963, 6980, 6992, 7005, 7018, 7065, 7083, 7084, 7094, 7106, 7117, 7126, 7131, 7138, 7142, 7156, 7176, 7208, 7216, 7217, 7285, 7292, 7334, 7345, 7414, 7476, 7523, 7562, 7568, 7572, 7580, 7589, 7597, 7625, 7645, 7698, 7699, 7717, 7722, 7732, 7745, 7789, 7819, 7830, 7867, 7869, 7873, 7909, 7942, 7952, 7956, 7959, 7974, 7993, 8011, 8030, 8049, 8053, 8088, 8107, 8132, 8142, 8177, 8187, 8226, 8239, 8285, 8291, 8294, 8322, 8334, 8352, 8388, 8422, 8430, 8467, 8546, 8578, 8614, 8620, 8630, 8642, 8650, 8651, 8666, 8680, 8699, 8709, 8721, 8790, 8801, 8834, 8837, 8839, 8850, 8906, 8923, 8926, 8955, 9007, 9044, 9054, 9063, 9074, 9080, 9147, 9171, 9203, 9206, 9253, 9272, 9278, 9281, 9289, 9294, 9302, 9309, 9347, 9359, 9425, 9428, 9435]
486 SVs (with labels):
Training time for 5.0-vs-6.0: 405.053205967 seconds
Begin training classifier for label 5.0 and label 7.0 at 2016-05-20, 03:05:38
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9766, 784) (9766,)
(9766, 784) (9766,)
     pcost       dcost       gap    pres   dres
 0: -9.6196e+02 -2.2970e+04  1e+05  3e+00  9e-12
 1: -5.7172e+02 -1.3850e+04  3e+04  5e-01  1e-11
 2: -2.6574e+02 -3.8364e+03  6e+03  9e-02  6e-12
 3: -1.5703e+02 -1.9510e+03  3e+03  4e-02  3e-12
 4: -9.2830e+01 -9.9657e+02  2e+03  2e-02  2e-12
 5: -5.9373e+01 -5.6429e+02  8e+02  1e-02  1e-12
 6: -3.8741e+01 -3.4352e+02  5e+02  5e-03  1e-12
 7: -2.8654e+01 -1.5041e+02  2e+02  1e-03  1e-12
 8: -3.1021e+01 -6.5834e+01  4e+01  2e-04  1e-12
 9: -3.2197e+01 -4.9815e+01  2e+01  8e-14  1e-12
10: -3.5717e+01 -4.4043e+01  8e+00  4e-14  1e-12
11: -3.7679e+01 -4.0696e+01  3e+00  4e-14  1e-12
12: -3.8842e+01 -3.9237e+01  4e-01  1e-13  1e-12
13: -3.9019e+01 -3.9035e+01  2e-02  3e-14  1e-12
14: -3.9026e+01 -3.9026e+01  3e-04  8e-14  1e-12
15: -3.9026e+01 -3.9026e+01  3e-06  9e-14  1e-12
Optimal solution found.
sv_indices: [0, 21, 28, 56, 69, 140, 177, 191, 221, 260, 284, 470, 586, 598, 612, 689, 714, 735, 751, 758, 788, 896, 924, 947, 972, 1021, 1028, 1089, 1130, 1156, 1160, 1162, 1183, 1199, 1252, 1274, 1295, 1307, 1310, 1321, 1347, 1351, 1435, 1520, 1602, 1684, 1699, 1754, 1815, 1853, 1867, 1893, 1962, 1963, 2033, 2063, 2071, 2092, 2109, 2117, 2172, 2199, 2204, 2216, 2285, 2305, 2308, 2312, 2335, 2419, 2439, 2481, 2483, 2485, 2501, 2518, 2585, 2606, 2612, 2626, 2836, 2849, 2856, 2876, 2886, 2920, 3026, 3083, 3085, 3087, 3149, 3170, 3246, 3263, 3288, 3289, 3410, 3428, 3474, 3485, 3502, 3519, 3543, 3605, 3627, 3652, 3703, 3743, 3746, 3841, 3891, 3900, 3985, 4004, 4027, 4052, 4053, 4072, 4120, 4247, 4249, 4344, 4379, 4430, 4480, 4490, 4564, 4599, 4692, 4717, 4718, 4720, 4760, 4817, 4899, 4940, 4945, 4947, 4960, 4989, 5198, 5223, 5283, 5305, 5319, 5350, 5392, 5406, 5504, 5570, 5642, 5648, 5658, 5679, 5781, 5806, 5836, 5847, 5878, 5918, 5975, 6101, 6169, 6199, 6292, 6296, 6358, 6364, 6385, 6420, 6426, 6469, 6475, 6479, 6582, 6601, 6612, 6629, 6658, 6821, 6917, 6983, 6985, 7055, 7100, 7126, 7226, 7252, 7265, 7275, 7340, 7409, 7456, 7457, 7469, 7521, 7528, 7549, 7557, 7633, 7634, 7718, 7775, 7789, 7867, 7880, 7904, 8037, 8076, 8077, 8177, 8417, 8418, 8466, 8620, 8693, 8739, 8752, 8757, 8815, 8827, 8828, 8833, 8846, 8892, 8926, 8978, 8983, 9006, 9024, 9026, 9046, 9168, 9243, 9274, 9509, 9555, 9564, 9689, 9690, 9720]
241 SVs (with labels):
Training time for 5.0-vs-7.0: 395.385546923 seconds
Begin training classifier for label 5.0 and label 8.0 at 2016-05-20, 03:12:14
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9378, 784) (9378,)
(9378, 784) (9378,)
     pcost       dcost       gap    pres   dres
 0: -1.8489e+03 -2.3980e+04  1e+05  3e+00  3e-11
 1: -1.1710e+03 -1.5322e+04  3e+04  5e-01  3e-11
 2: -7.9510e+02 -6.2213e+03  1e+04  1e-01  2e-11
 3: -6.3276e+02 -3.2648e+03  4e+03  7e-02  2e-11
 4: -5.4837e+02 -1.7704e+03  2e+03  3e-02  1e-11
 5: -5.0531e+02 -1.1061e+03  8e+02  8e-03  1e-11
 6: -5.2538e+02 -8.1889e+02  4e+02  3e-03  1e-11
 7: -5.1130e+02 -7.5722e+02  3e+02  9e-04  1e-11
 8: -5.3510e+02 -6.7707e+02  1e+02  2e-04  1e-11
 9: -5.4883e+02 -6.4503e+02  1e+02  1e-04  1e-11
10: -5.6491e+02 -6.1117e+02  5e+01  3e-05  1e-11
11: -5.6809e+02 -6.0243e+02  3e+01  8e-06  1e-11
12: -5.7506e+02 -5.9259e+02  2e+01  3e-06  1e-11
13: -5.8020e+02 -5.8526e+02  5e+00  4e-07  1e-11
14: -5.8161e+02 -5.8341e+02  2e+00  8e-13  2e-11
15: -5.8239e+02 -5.8256e+02  2e-01  8e-13  1e-11
16: -5.8247e+02 -5.8247e+02  4e-03  9e-13  2e-11
17: -5.8247e+02 -5.8247e+02  7e-05  1e-12  2e-11
Optimal solution found.
sv_indices: [0, 13, 21, 23, 28, 63, 69, 77, 102, 104, 114, 140, 146, 150, 158, 161, 169, 218, 249, 260, 269, 271, 284, 291, 310, 324, 344, 363, 374, 393, 394, 436, 455, 471, 480, 493, 510, 516, 521, 522, 553, 558, 561, 562, 574, 582, 598, 610, 612, 635, 641, 650, 656, 659, 671, 685, 693, 696, 701, 710, 717, 722, 728, 731, 735, 751, 774, 778, 801, 803, 807, 810, 824, 827, 839, 841, 842, 873, 887, 909, 914, 921, 934, 940, 942, 951, 954, 980, 992, 1008, 1019, 1028, 1038, 1040, 1041, 1072, 1079, 1081, 1088, 1113, 1131, 1141, 1161, 1184, 1199, 1212, 1229, 1239, 1251, 1261, 1263, 1265, 1267, 1294, 1307, 1321, 1345, 1346, 1370, 1380, 1393, 1399, 1409, 1415, 1418, 1438, 1452, 1464, 1479, 1490, 1491, 1492, 1501, 1503, 1507, 1513, 1519, 1520, 1523, 1525, 1548, 1552, 1554, 1571, 1588, 1592, 1602, 1613, 1614, 1616, 1624, 1632, 1646, 1659, 1665, 1667, 1684, 1692, 1699, 1722, 1724, 1745, 1747, 1761, 1771, 1774, 1775, 1778, 1784, 1792, 1794, 1798, 1801, 1804, 1830, 1833, 1839, 1845, 1846, 1851, 1853, 1861, 1865, 1867, 1869, 1874, 1888, 1893, 1925, 1932, 1942, 1962, 1969, 2017, 2026, 2100, 2109, 2123, 2137, 2147, 2153, 2166, 2169, 2175, 2177, 2178, 2190, 2191, 2196, 2210, 2211, 2216, 2225, 2238, 2239, 2247, 2257, 2262, 2270, 2273, 2294, 2304, 2305, 2306, 2307, 2308, 2334, 2347, 2355, 2359, 2380, 2383, 2400, 2419, 2422, 2444, 2472, 2493, 2506, 2509, 2512, 2540, 2543, 2557, 2558, 2565, 2579, 2582, 2585, 2606, 2611, 2612, 2613, 2619, 2623, 2631, 2635, 2647, 2675, 2677, 2679, 2681, 2708, 2716, 2726, 2740, 2741, 2745, 2747, 2750, 2751, 2753, 2757, 2767, 2786, 2787, 2802, 2827, 2844, 2845, 2849, 2856, 2860, 2868, 2872, 2873, 2874, 2885, 2888, 2898, 2920, 2933, 2955, 2956, 2970, 2991, 2997, 3000, 3002, 3020, 3028, 3036, 3039, 3041, 3042, 3050, 3079, 3096, 3109, 3115, 3125, 3132, 3159, 3170, 3171, 3176, 3182, 3194, 3198, 3212, 3213, 3217, 3237, 3254, 3273, 3277, 3288, 3295, 3301, 3320, 3339, 3345, 3363, 3366, 3375, 3423, 3445, 3447, 3450, 3455, 3456, 3458, 3466, 3467, 3471, 3478, 3479, 3483, 3516, 3518, 3523, 3524, 3533, 3546, 3556, 3560, 3583, 3595, 3598, 3601, 3602, 3627, 3659, 3669, 3674, 3686, 3689, 3697, 3703, 3709, 3715, 3758, 3769, 3789, 3798, 3804, 3848, 3863, 3885, 3891, 3935, 3945, 3951, 3954, 3983, 3988, 3993, 4003, 4011, 4027, 4045, 4053, 4056, 4072, 4096, 4117, 4128, 4141, 4148, 4176, 4188, 4194, 4200, 4201, 4206, 4237, 4247, 4260, 4265, 4267, 4282, 4307, 4324, 4335, 4344, 4370, 4373, 4376, 4418, 4425, 4458, 4467, 4470, 4475, 4490, 4497, 4527, 4563, 4566, 4576, 4581, 4586, 4590, 4594, 4606, 4618, 4619, 4621, 4668, 4671, 4686, 4694, 4703, 4707, 4710, 4718, 4724, 4727, 4739, 4777, 4797, 4814, 4816, 4817, 4840, 4845, 4846, 4852, 4862, 4865, 4880, 4909, 4912, 4926, 4958, 4962, 4985, 4993, 5002, 5005, 5016, 5021, 5023, 5032, 5037, 5045, 5050, 5055, 5057, 5082, 5090, 5092, 5117, 5123, 5139, 5140, 5146, 5162, 5220, 5244, 5245, 5266, 5285, 5297, 5300, 5305, 5316, 5319, 5335, 5346, 5356, 5383, 5389, 5419, 5425, 5441, 5474, 5481, 5495, 5511, 5519, 5543, 5551, 5573, 5581, 5582, 5594, 5601, 5610, 5611, 5620, 5621, 5623, 5628, 5642, 5644, 5645, 5660, 5667, 5673, 5683, 5696, 5702, 5703, 5714, 5727, 5735, 5741, 5750, 5757, 5763, 5765, 5773, 5806, 5808, 5827, 5837, 5848, 5868, 5880, 5881, 5890, 5899, 5903, 5913, 5924, 5939, 5947, 5957, 5958, 5960, 5962, 5965, 5971, 5979, 6015, 6016, 6027, 6029, 6034, 6080, 6083, 6088, 6113, 6122, 6143, 6145, 6151, 6178, 6183, 6187, 6192, 6199, 6201, 6202, 6214, 6224, 6260, 6266, 6295, 6297, 6319, 6335, 6338, 6339, 6340, 6351, 6379, 6390, 6393, 6408, 6422, 6441, 6442, 6452, 6464, 6471, 6472, 6511, 6514, 6524, 6526, 6550, 6553, 6557, 6565, 6566, 6567, 6582, 6599, 6600, 6619, 6628, 6639, 6642, 6649, 6654, 6656, 6660, 6677, 6693, 6735, 6736, 6737, 6740, 6741, 6750, 6756, 6761, 6768, 6791, 6794, 6804, 6827, 6834, 6836, 6842, 6862, 6875, 6898, 6957, 6965, 6968, 6969, 6975, 6981, 6993, 7013, 7014, 7016, 7028, 7050, 7053, 7098, 7115, 7116, 7117, 7126, 7133, 7137, 7154, 7191, 7200, 7204, 7220, 7238, 7245, 7251, 7281, 7284, 7286, 7289, 7311, 7314, 7317, 7319, 7321, 7331, 7338, 7342, 7372, 7396, 7401, 7403, 7421, 7449, 7450, 7460, 7465, 7487, 7492, 7503, 7521, 7529, 7540, 7549, 7572, 7604, 7612, 7616, 7617, 7638, 7643, 7659, 7710, 7719, 7771, 7777, 7827, 7839, 7844, 7854, 7858, 7859, 7871, 7880, 7886, 7899, 7911, 7913, 7927, 7940, 7957, 7968, 7994, 8018, 8026, 8062, 8090, 8116, 8133, 8143, 8156, 8157, 8190, 8212, 8218, 8247, 8252, 8264, 8265, 8267, 8307, 8318, 8322, 8323, 8340, 8349, 8351, 8354, 8355, 8362, 8370, 8373, 8408, 8422, 8424, 8429, 8447, 8459, 8472, 8493, 8495, 8497, 8506, 8508, 8511, 8513, 8515, 8516, 8528, 8532, 8536, 8539, 8586, 8589, 8590, 8596, 8602, 8605, 8636, 8644, 8649, 8651, 8654, 8670, 8679, 8699, 8734, 8740, 8788, 8824, 8841, 8861, 8871, 8878, 8882, 8914, 8944, 8956, 8980, 9000, 9001, 9006, 9007, 9011, 9015, 9027, 9040, 9066, 9089, 9111, 9114, 9125, 9141, 9146, 9160, 9170, 9179, 9186, 9192, 9202, 9204, 9206, 9207, 9226, 9245, 9254, 9258, 9268, 9269, 9278, 9284, 9302, 9303, 9304, 9320, 9334, 9354]
849 SVs (with labels):
Training time for 5.0-vs-8.0: 395.619086981 seconds
Begin training classifier for label 5.0 and label 9.0 at 2016-05-20, 03:18:49
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9545, 784) (9545,)
(9545, 784) (9545,)
     pcost       dcost       gap    pres   dres
 0: -1.1894e+03 -2.1822e+04  1e+05  3e+00  2e-11
 1: -7.2302e+02 -1.3087e+04  3e+04  4e-01  2e-11
 2: -4.1764e+02 -4.9521e+03  8e+03  1e-01  1e-11
 3: -2.8602e+02 -2.5903e+03  4e+03  6e-02  6e-12
 4: -1.9839e+02 -1.4239e+03  2e+03  3e-02  5e-12
 5: -1.4700e+02 -8.0420e+02  1e+03  1e-02  4e-12
 6: -1.1731e+02 -6.5103e+02  8e+02  7e-03  3e-12
 7: -1.1387e+02 -3.2102e+02  3e+02  2e-03  3e-12
 8: -1.2060e+02 -2.1038e+02  1e+02  6e-04  3e-12
 9: -1.1748e+02 -1.8086e+02  7e+01  1e-04  3e-12
10: -1.2922e+02 -1.5702e+02  3e+01  3e-05  3e-12
11: -1.3268e+02 -1.4915e+02  2e+01  7e-06  3e-12
12: -1.3624e+02 -1.4322e+02  7e+00  3e-13  4e-12
13: -1.3845e+02 -1.4051e+02  2e+00  4e-13  3e-12
14: -1.3930e+02 -1.3950e+02  2e-01  3e-13  4e-12
15: -1.3939e+02 -1.3940e+02  5e-03  5e-13  4e-12
16: -1.3940e+02 -1.3940e+02  6e-05  2e-13  4e-12
Optimal solution found.
sv_indices: [0, 13, 19, 28, 69, 103, 104, 110, 132, 153, 154, 191, 249, 258, 260, 269, 271, 291, 393, 396, 468, 470, 475, 523, 586, 612, 623, 650, 656, 682, 701, 714, 725, 728, 735, 746, 751, 791, 808, 857, 870, 896, 956, 1021, 1038, 1060, 1089, 1094, 1122, 1160, 1162, 1183, 1199, 1212, 1251, 1252, 1265, 1274, 1300, 1307, 1398, 1463, 1501, 1519, 1591, 1644, 1684, 1689, 1699, 1739, 1754, 1815, 1821, 1867, 1888, 1893, 1932, 1936, 1962, 1963, 1983, 1997, 2026, 2047, 2056, 2114, 2117, 2137, 2147, 2153, 2172, 2204, 2262, 2273, 2324, 2344, 2345, 2355, 2364, 2380, 2419, 2421, 2485, 2491, 2501, 2566, 2567, 2585, 2631, 2633, 2635, 2672, 2679, 2681, 2742, 2751, 2780, 2794, 2800, 2836, 2849, 2856, 2860, 2870, 2888, 2956, 3026, 3087, 3114, 3129, 3170, 3182, 3189, 3213, 3217, 3228, 3239, 3246, 3251, 3263, 3288, 3289, 3292, 3336, 3339, 3343, 3350, 3370, 3372, 3410, 3428, 3487, 3528, 3548, 3557, 3560, 3572, 3602, 3605, 3627, 3652, 3668, 3669, 3699, 3715, 3791, 3827, 3856, 3891, 3985, 4004, 4027, 4053, 4056, 4072, 4127, 4138, 4181, 4183, 4191, 4194, 4243, 4244, 4247, 4249, 4260, 4282, 4316, 4324, 4344, 4345, 4424, 4459, 4470, 4478, 4480, 4490, 4506, 4544, 4556, 4584, 4680, 4831, 4836, 4922, 4944, 4953, 4990, 5081, 5102, 5132, 5154, 5161, 5172, 5175, 5205, 5208, 5275, 5288, 5303, 5310, 5327, 5389, 5396, 5405, 5434, 5446, 5470, 5495, 5497, 5500, 5521, 5559, 5574, 5598, 5604, 5688, 5718, 5763, 5780, 5817, 5853, 5867, 5886, 5941, 5982, 6054, 6142, 6150, 6175, 6211, 6253, 6285, 6320, 6335, 6345, 6349, 6439, 6455, 6525, 6529, 6544, 6551, 6622, 6684, 6704, 6708, 6727, 6744, 6762, 6819, 6824, 6838, 6852, 6910, 6929, 6934, 6952, 6962, 7002, 7006, 7012, 7027, 7028, 7109, 7125, 7212, 7286, 7293, 7341, 7366, 7380, 7383, 7457, 7506, 7525, 7532, 7536, 7540, 7552, 7588, 7611, 7663, 7664, 7749, 7770, 7779, 7817, 7849, 7890, 7907, 7940, 8040, 8057, 8084, 8104, 8113, 8184, 8185, 8217, 8224, 8234, 8297, 8307, 8323, 8336, 8338, 8377, 8398, 8420, 8421, 8426, 8591, 8600, 8650, 8701, 8713, 8734, 8755, 8811, 8829, 8833, 8836, 8881, 8894, 8934, 8936, 8954, 8970, 8976, 8982, 9068, 9084, 9107, 9141, 9163, 9213, 9241, 9309, 9320, 9359, 9374, 9431, 9470]
364 SVs (with labels):
Training time for 5.0-vs-9.0: 398.439325094 seconds
Begin training classifier for label 6.0 and label 7.0 at 2016-05-20, 03:25:28
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10178, 784) (10178,)
(10178, 784) (10178,)
     pcost       dcost       gap    pres   dres
 0: -5.4063e+02 -1.9262e+04  1e+05  3e+00  4e-12
 1: -3.1056e+02 -1.0128e+04  2e+04  3e-01  4e-12
 2: -1.1869e+02 -2.9884e+03  5e+03  8e-02  2e-12
 3: -4.7393e+01 -1.1468e+03  2e+03  3e-02  1e-12
 4: -2.4265e+01 -7.2999e+02  1e+03  2e-02  7e-13
 5: -9.2229e+00 -5.1220e+02  8e+02  9e-03  5e-13
 6: -2.7641e+00 -1.3661e+02  2e+02  2e-03  2e-13
 7: -1.1062e+00 -5.5281e+01  8e+01  7e-04  1e-13
 8: -1.0967e+00 -2.3784e+01  3e+01  2e-04  1e-13
 9: -1.7164e+00 -1.0534e+01  1e+01  4e-05  1e-13
10: -1.9317e+00 -8.9362e+00  8e+00  2e-05  1e-13
11: -2.7823e+00 -6.2431e+00  4e+00  7e-06  1e-13
12: -2.8666e+00 -5.5367e+00  3e+00  1e-06  1e-13
13: -3.4821e+00 -4.5152e+00  1e+00  3e-07  1e-13
14: -3.7203e+00 -4.1265e+00  4e-01  9e-08  1e-13
15: -3.8496e+00 -3.9305e+00  8e-02  4e-16  1e-13
16: -3.8877e+00 -3.8893e+00  2e-03  1e-14  1e-13
17: -3.8884e+00 -3.8885e+00  2e-05  1e-14  1e-13
18: -3.8884e+00 -3.8884e+00  3e-07  2e-15  1e-13
Optimal solution found.
sv_indices: [154, 179, 323, 337, 406, 440, 445, 506, 510, 527, 532, 620, 645, 648, 706, 888, 936, 1015, 1070, 1140, 1161, 1163, 1324, 1364, 1394, 1398, 1455, 1702, 1762, 1911, 1959, 1967, 2004, 2120, 2235, 2297, 2343, 2364, 2438, 2440, 2486, 2534, 2637, 2689, 2730, 2754, 2815, 2827, 2895, 3061, 3154, 3181, 3198, 3318, 3348, 3374, 3464, 3511, 3654, 3681, 3708, 3775, 3791, 3869, 3887, 3903, 4034, 4202, 4338, 4407, 4525, 4753, 4762, 4893, 5069, 5129, 5138, 5143, 5234, 5290, 5309, 5581, 5602, 5695, 5698, 5982, 6016, 6060, 6137, 6181, 6207, 6248, 6488, 6753, 6770, 6832, 6891, 7193, 7233, 7270, 7423, 7664, 7680, 7681, 7687, 7752, 7824, 7881, 7961, 8130, 8230, 8555, 8829, 8951, 8962, 9240, 9272, 9394, 9418, 9436, 9458, 9583, 9617, 9632, 9649, 9652, 10008, 10042, 10144]
129 SVs (with labels):
Training time for 6.0-vs-7.0: 512.383428097 seconds
Begin training classifier for label 6.0 and label 8.0 at 2016-05-20, 03:34:01
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9790, 784) (9790,)
(9790, 784) (9790,)
     pcost       dcost       gap    pres   dres
 0: -1.0200e+03 -1.9847e+04  1e+05  3e+00  2e-11
 1: -6.3268e+02 -1.1058e+04  2e+04  4e-01  2e-11
 2: -3.9602e+02 -4.7662e+03  8e+03  1e-01  1e-11
 3: -2.7000e+02 -2.5911e+03  4e+03  7e-02  7e-12
 4: -2.0483e+02 -1.7997e+03  3e+03  4e-02  6e-12
 5: -1.5440e+02 -1.0909e+03  2e+03  2e-02  4e-12
 6: -1.1723e+02 -6.9272e+02  1e+03  1e-02  4e-12
 7: -9.6276e+01 -4.7753e+02  6e+02  7e-03  3e-12
 8: -8.2603e+01 -3.7097e+02  5e+02  4e-03  3e-12
 9: -7.4637e+01 -1.8100e+02  2e+02  1e-03  3e-12
10: -7.4215e+01 -1.0162e+02  3e+01  1e-04  3e-12
11: -7.8906e+01 -8.7796e+01  1e+01  2e-05  3e-12
12: -8.0378e+01 -8.4205e+01  4e+00  2e-13  3e-12
13: -8.1922e+01 -8.2435e+01  5e-01  2e-13  3e-12
14: -8.2148e+01 -8.2178e+01  3e-02  3e-14  3e-12
15: -8.2162e+01 -8.2162e+01  5e-04  2e-13  3e-12
16: -8.2162e+01 -8.2162e+01  6e-06  4e-14  3e-12
Optimal solution found.
sv_indices: [29, 31, 41, 146, 262, 323, 327, 441, 442, 445, 494, 506, 531, 620, 621, 648, 677, 704, 706, 711, 713, 778, 807, 812, 839, 925, 926, 936, 947, 968, 1001, 1015, 1028, 1079, 1147, 1154, 1270, 1300, 1303, 1324, 1371, 1380, 1419, 1455, 1479, 1502, 1526, 1572, 1586, 1626, 1642, 1695, 1734, 1762, 1782, 1838, 1959, 1967, 1996, 2000, 2039, 2088, 2134, 2205, 2229, 2239, 2268, 2293, 2302, 2352, 2364, 2372, 2381, 2407, 2486, 2507, 2526, 2657, 2697, 2698, 2713, 2730, 2772, 2827, 2864, 2957, 3043, 3045, 3053, 3178, 3179, 3198, 3226, 3264, 3311, 3316, 3374, 3434, 3464, 3527, 3530, 3534, 3588, 3613, 3623, 3654, 3656, 3658, 3708, 3718, 3803, 3833, 3869, 3903, 3911, 4027, 4030, 4044, 4059, 4101, 4121, 4123, 4132, 4170, 4296, 4313, 4318, 4320, 4357, 4409, 4525, 4544, 4555, 4668, 4684, 4762, 4775, 4810, 4828, 4866, 4895, 4975, 4978, 4998, 5002, 5006, 5031, 5104, 5122, 5123, 5136, 5250, 5258, 5274, 5295, 5302, 5372, 5387, 5390, 5428, 5487, 5494, 5574, 5593, 5745, 5774, 5777, 5831, 5853, 5880, 5895, 5985, 6010, 6045, 6085, 6094, 6107, 6109, 6110, 6137, 6215, 6218, 6232, 6239, 6260, 6279, 6289, 6302, 6317, 6327, 6341, 6351, 6379, 6381, 6383, 6438, 6460, 6495, 6576, 6604, 6606, 6685, 6719, 6751, 6950, 6979, 7031, 7040, 7055, 7061, 7072, 7129, 7148, 7170, 7239, 7270, 7285, 7287, 7367, 7381, 7433, 7510, 7514, 7538, 7550, 7606, 7640, 7657, 7660, 7701, 7704, 7717, 7726, 7838, 7872, 7877, 7904, 7906, 7961, 8069, 8100, 8121, 8136, 8271, 8283, 8298, 8319, 8332, 8406, 8409, 8438, 8625, 8677, 8726, 8735, 8780, 8785, 8834, 8836, 8859, 8875, 8896, 8909, 8918, 8928, 8943, 8948, 8951, 8998, 9146, 9152, 9166, 9211, 9281, 9285, 9368, 9386, 9412, 9430, 9433, 9446, 9452, 9506, 9570, 9618, 9621, 9629, 9732]
288 SVs (with labels):
Training time for 6.0-vs-8.0: 423.367860079 seconds
Begin training classifier for label 6.0 and label 9.0 at 2016-05-20, 03:41:04
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9957, 784) (9957,)
(9957, 784) (9957,)
     pcost       dcost       gap    pres   dres
 0: -5.3586e+02 -1.9618e+04  1e+05  3e+00  1e-11
 1: -3.0873e+02 -1.0683e+04  2e+04  4e-01  7e-12
 2: -1.3807e+02 -3.4911e+03  6e+03  1e-01  4e-12
 3: -7.7465e+01 -1.8601e+03  3e+03  5e-02  2e-12
 4: -2.8642e+01 -1.2425e+03  2e+03  3e-02  1e-12
 5: -1.4496e+01 -8.6336e+02  1e+03  2e-02  8e-13
 6: -3.1919e+00 -5.6643e+02  9e+02  8e-03  5e-13
 7:  1.3418e+00 -1.5073e+02  2e+02  2e-03  3e-13
 8:  2.7445e-01 -5.5567e+01  7e+01  5e-04  2e-13
 9: -9.3445e-01 -2.4843e+01  3e+01  1e-04  2e-13
10: -2.4812e+00 -1.4948e+01  1e+01  3e-05  2e-13
11: -3.1804e+00 -1.2460e+01  1e+01  9e-06  2e-13
12: -4.5450e+00 -8.7755e+00  4e+00  3e-06  2e-13
13: -4.6874e+00 -8.4486e+00  4e+00  2e-06  2e-13
14: -5.3588e+00 -7.1896e+00  2e+00  7e-07  2e-13
15: -5.7011e+00 -6.4492e+00  7e-01  1e-14  3e-13
16: -5.9632e+00 -6.1200e+00  2e-01  3e-14  3e-13
17: -6.0359e+00 -6.0403e+00  4e-03  2e-15  3e-13
18: -6.0380e+00 -6.0380e+00  7e-05  9e-15  3e-13
19: -6.0380e+00 -6.0380e+00  9e-07  8e-15  3e-13
Optimal solution found.
sv_indices: [29, 406, 440, 442, 445, 465, 506, 527, 648, 703, 706, 740, 743, 853, 947, 1001, 1079, 1105, 1113, 1202, 1218, 1270, 1278, 1303, 1371, 1382, 1398, 1465, 1526, 1552, 1668, 1762, 1891, 1933, 1956, 1964, 2120, 2239, 2302, 2352, 2364, 2381, 2438, 2486, 2534, 2554, 2607, 2657, 2730, 2815, 2826, 2827, 2895, 2944, 2957, 3061, 3154, 3226, 3237, 3311, 3318, 3348, 3423, 3511, 3574, 3656, 3708, 3775, 3869, 3887, 4007, 4059, 4101, 4120, 4269, 4318, 4385, 4525, 4684, 4719, 4753, 4906, 4909, 5008, 5106, 5356, 5442, 5551, 5617, 5686, 5722, 5882, 5909, 5933, 6114, 6267, 6298, 6310, 6549, 6560, 6578, 6679, 6837, 6878, 6907, 6956, 6991, 7139, 7159, 7168, 7294, 7307, 7374, 7382, 7439, 7440, 7537, 7543, 7599, 7647, 7664, 7948, 7952, 8075, 8076, 8082, 8086, 8170, 8191, 8273, 8280, 8440, 8597, 8621, 8943, 8982, 9003, 9052, 9069, 9146, 9273, 9285, 9366, 9382, 9399, 9502, 9632, 9732, 9822, 9876, 9899, 9907]
152 SVs (with labels):
Training time for 6.0-vs-9.0: 527.876538992 seconds
Begin training classifier for label 7.0 and label 8.0 at 2016-05-20, 03:49:52
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10106, 784) (10106,)
(10106, 784) (10106,)
     pcost       dcost       gap    pres   dres
 0: -9.4801e+02 -2.1826e+04  1e+05  3e+00  3e-11
 1: -5.9232e+02 -1.2768e+04  3e+04  5e-01  1e-11
 2: -3.4173e+02 -4.8418e+03  8e+03  1e-01  8e-12
 3: -2.1570e+02 -2.2642e+03  4e+03  6e-02  6e-12
 4: -1.4434e+02 -1.3883e+03  2e+03  3e-02  4e-12
 5: -9.9645e+01 -8.6501e+02  1e+03  2e-02  3e-12
 6: -7.2740e+01 -5.6377e+02  8e+02  9e-03  2e-12
 7: -5.4092e+01 -3.8962e+02  6e+02  5e-03  2e-12
 8: -4.1837e+01 -2.8534e+02  4e+02  3e-03  2e-12
 9: -3.9684e+01 -1.2330e+02  1e+02  7e-04  2e-12
10: -4.2642e+01 -7.3287e+01  3e+01  2e-13  2e-12
11: -4.8611e+01 -6.1634e+01  1e+01  6e-14  2e-12
12: -5.1213e+01 -5.6725e+01  6e+00  4e-13  2e-12
13: -5.2316e+01 -5.5059e+01  3e+00  4e-13  2e-12
14: -5.3461e+01 -5.3746e+01  3e-01  8e-14  2e-12
15: -5.3592e+01 -5.3598e+01  5e-03  2e-13  2e-12
16: -5.3595e+01 -5.3595e+01  7e-05  3e-13  2e-12
17: -5.3595e+01 -5.3595e+01  8e-07  1e-13  2e-12
Optimal solution found.
sv_indices: [80, 173, 198, 199, 205, 243, 298, 428, 470, 512, 528, 599, 623, 656, 679, 683, 764, 776, 819, 831, 870, 882, 910, 1051, 1114, 1129, 1139, 1160, 1242, 1260, 1317, 1359, 1442, 1456, 1501, 1504, 1545, 1680, 1738, 1777, 1778, 1781, 1839, 1845, 1907, 1950, 1960, 2063, 2311, 2356, 2439, 2464, 2492, 2520, 2624, 2660, 2671, 2676, 2707, 2733, 2750, 2782, 2821, 2938, 2950, 2996, 3030, 3038, 3090, 3145, 3177, 3256, 3469, 3500, 3518, 3531, 3557, 3558, 3612, 3624, 3641, 3732, 3736, 3747, 3750, 3756, 3768, 3831, 3870, 3899, 3905, 4059, 4100, 4155, 4174, 4219, 4233, 4238, 4242, 4309, 4335, 4376, 4463, 4572, 4652, 4724, 4747, 4757, 4851, 4859, 4889, 4997, 5036, 5075, 5163, 5199, 5294, 5315, 5334, 5346, 5347, 5482, 5494, 5500, 5525, 5539, 5567, 5708, 5713, 5802, 5815, 5926, 5991, 6022, 6028, 6056, 6068, 6069, 6098, 6111, 6145, 6191, 6223, 6260, 6299, 6327, 6478, 6511, 6605, 6666, 6672, 6676, 6693, 6811, 6816, 6821, 7065, 7082, 7120, 7136, 7147, 7170, 7244, 7251, 7295, 7303, 7395, 7405, 7417, 7426, 7451, 7452, 7486, 7539, 7548, 7576, 7602, 7603, 7605, 7679, 7683, 7737, 7766, 7844, 7852, 7887, 7891, 7914, 7950, 7956, 8053, 8070, 8071, 8082, 8141, 8217, 8222, 8228, 8249, 8275, 8277, 8297, 8323, 8368, 8403, 8466, 8490, 8499, 8586, 8599, 8643, 8661, 8684, 8689, 8719, 8751, 8947, 8980, 9058, 9077, 9079, 9138, 9293, 9328, 9389, 9446, 9452, 9453, 9454, 9478, 9554, 9595, 9674, 9693, 9709, 9734, 9780, 9817, 9869, 9898, 9902, 9946, 9973, 9994, 10078]
245 SVs (with labels):
Training time for 7.0-vs-8.0: 479.051539898 seconds
Begin training classifier for label 7.0 and label 9.0 at 2016-05-20, 03:57:51
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(10273, 784) (10273,)
(10273, 784) (10273,)
     pcost       dcost       gap    pres   dres
 0: -2.1257e+03 -3.3264e+04  3e+05  4e+00  4e-11
 1: -1.3315e+03 -2.3433e+04  5e+04  7e-01  3e-11
 2: -9.5357e+02 -1.0788e+04  2e+04  2e-01  2e-11
 3: -7.9015e+02 -6.2702e+03  9e+03  1e-01  2e-11
 4: -6.8774e+02 -4.0356e+03  5e+03  6e-02  1e-11
 5: -6.2719e+02 -2.9200e+03  3e+03  3e-02  1e-11
 6: -6.0140e+02 -1.9812e+03  2e+03  1e-02  1e-11
 7: -6.2685e+02 -1.1852e+03  6e+02  3e-03  1e-11
 8: -6.5567e+02 -1.0449e+03  4e+02  1e-03  1e-11
 9: -6.8240e+02 -9.4004e+02  3e+02  6e-04  1e-11
10: -6.9922e+02 -8.7519e+02  2e+02  2e-04  1e-11
11: -7.1808e+02 -8.3008e+02  1e+02  9e-05  1e-11
12: -7.3073e+02 -8.0137e+02  7e+01  3e-05  2e-11
13: -7.4385e+02 -7.7691e+02  3e+01  2e-06  2e-11
14: -7.4994e+02 -7.6798e+02  2e+01  5e-07  2e-11
15: -7.5503e+02 -7.6152e+02  6e+00  9e-08  2e-11
16: -7.5726e+02 -7.5886e+02  2e+00  1e-08  2e-11
17: -7.5787e+02 -7.5817e+02  3e-01  2e-09  2e-11
18: -7.5800e+02 -7.5801e+02  1e-02  2e-11  2e-11
19: -7.5801e+02 -7.5801e+02  2e-04  3e-13  2e-11
Optimal solution found.
sv_indices: [5, 12, 40, 45, 57, 80, 102, 114, 121, 139, 140, 170, 173, 176, 192, 194, 198, 199, 201, 205, 207, 212, 231, 236, 237, 238, 241, 247, 255, 258, 272, 298, 299, 365, 371, 379, 392, 395, 405, 423, 426, 432, 463, 466, 470, 472, 507, 528, 529, 534, 540, 542, 583, 587, 591, 613, 614, 640, 655, 656, 661, 672, 673, 704, 705, 742, 764, 776, 777, 800, 818, 831, 847, 861, 870, 873, 874, 891, 897, 900, 904, 906, 920, 926, 927, 933, 944, 975, 976, 978, 988, 1004, 1006, 1018, 1047, 1074, 1096, 1101, 1104, 1114, 1123, 1139, 1159, 1162, 1168, 1174, 1186, 1191, 1204, 1211, 1226, 1246, 1248, 1270, 1276, 1304, 1317, 1318, 1322, 1323, 1346, 1359, 1370, 1375, 1399, 1423, 1442, 1456, 1457, 1485, 1489, 1501, 1511, 1513, 1514, 1526, 1527, 1545, 1563, 1565, 1570, 1582, 1590, 1623, 1629, 1656, 1680, 1685, 1689, 1695, 1705, 1773, 1775, 1777, 1778, 1779, 1783, 1784, 1797, 1816, 1820, 1831, 1835, 1839, 1845, 1862, 1865, 1878, 1890, 1891, 1901, 1909, 1945, 1952, 1956, 1960, 1961, 1991, 1995, 1998, 2011, 2013, 2018, 2020, 2035, 2038, 2044, 2049, 2052, 2062, 2063, 2072, 2077, 2082, 2085, 2092, 2094, 2110, 2119, 2133, 2134, 2139, 2162, 2166, 2169, 2172, 2192, 2203, 2218, 2223, 2245, 2255, 2256, 2262, 2287, 2296, 2305, 2311, 2318, 2320, 2324, 2337, 2349, 2350, 2356, 2367, 2371, 2400, 2401, 2426, 2440, 2457, 2460, 2464, 2466, 2480, 2485, 2492, 2533, 2536, 2566, 2581, 2612, 2624, 2636, 2637, 2647, 2657, 2661, 2683, 2687, 2702, 2707, 2710, 2733, 2750, 2756, 2775, 2776, 2778, 2783, 2789, 2791, 2823, 2828, 2830, 2834, 2845, 2856, 2883, 2890, 2893, 2900, 2902, 2920, 2928, 2938, 2940, 2946, 2948, 2950, 2952, 2969, 2980, 2985, 2987, 2992, 3006, 3009, 3020, 3030, 3060, 3071, 3085, 3103, 3105, 3106, 3114, 3122, 3131, 3139, 3154, 3156, 3157, 3159, 3177, 3179, 3183, 3199, 3204, 3217, 3226, 3254, 3256, 3270, 3303, 3331, 3335, 3346, 3348, 3361, 3369, 3379, 3380, 3383, 3391, 3394, 3400, 3411, 3433, 3437, 3445, 3461, 3491, 3494, 3500, 3502, 3518, 3531, 3553, 3557, 3558, 3561, 3566, 3570, 3591, 3624, 3625, 3642, 3657, 3658, 3705, 3727, 3732, 3736, 3740, 3743, 3751, 3756, 3768, 3782, 3785, 3794, 3799, 3804, 3808, 3829, 3849, 3862, 3876, 3895, 3899, 3947, 3951, 3955, 3979, 3987, 3998, 4014, 4024, 4031, 4033, 4041, 4047, 4049, 4056, 4092, 4094, 4123, 4124, 4149, 4155, 4174, 4181, 4190, 4207, 4219, 4224, 4233, 4238, 4239, 4246, 4252, 4260, 4261, 4265, 4286, 4307, 4308, 4309, 4315, 4317, 4327, 4335, 4345, 4373, 4388, 4400, 4404, 4409, 4420, 4424, 4463, 4464, 4474, 4483, 4493, 4499, 4509, 4513, 4527, 4538, 4543, 4553, 4569, 4595, 4610, 4617, 4625, 4629, 4636, 4642, 4672, 4674, 4678, 4682, 4683, 4685, 4686, 4704, 4710, 4716, 4718, 4724, 4740, 4741, 4747, 4755, 4757, 4771, 4775, 4802, 4815, 4817, 4839, 4841, 4854, 4859, 4863, 4868, 4885, 4886, 4895, 4897, 4898, 4913, 4915, 4926, 4952, 4968, 4970, 4973, 4997, 5010, 5036, 5043, 5045, 5046, 5082, 5085, 5104, 5110, 5111, 5147, 5164, 5169, 5171, 5185, 5199, 5202, 5213, 5214, 5251, 5269, 5277, 5285, 5312, 5334, 5339, 5345, 5353, 5363, 5391, 5411, 5427, 5438, 5441, 5451, 5456, 5461, 5468, 5470, 5471, 5474, 5479, 5480, 5501, 5512, 5520, 5532, 5535, 5540, 5544, 5575, 5582, 5591, 5604, 5607, 5628, 5631, 5648, 5649, 5652, 5654, 5659, 5672, 5685, 5695, 5716, 5717, 5726, 5747, 5760, 5761, 5768, 5775, 5780, 5789, 5805, 5811, 5836, 5841, 5850, 5853, 5858, 5863, 5894, 5907, 5908, 5917, 5918, 5925, 5965, 5999, 6003, 6008, 6031, 6038, 6041, 6046, 6057, 6071, 6077, 6081, 6084, 6086, 6105, 6111, 6114, 6149, 6162, 6165, 6166, 6193, 6198, 6215, 6223, 6225, 6227, 6228, 6233, 6235, 6263, 6268, 6271, 6277, 6287, 6291, 6294, 6295, 6299, 6305, 6309, 6319, 6320, 6325, 6352, 6366, 6371, 6393, 6394, 6411, 6421, 6424, 6425, 6426, 6428, 6435, 6443, 6455, 6476, 6484, 6509, 6510, 6520, 6523, 6530, 6543, 6553, 6564, 6568, 6576, 6593, 6597, 6620, 6669, 6690, 6701, 6712, 6716, 6723, 6729, 6740, 6744, 6748, 6752, 6773, 6792, 6793, 6795, 6798, 6803, 6827, 6835, 6850, 6856, 6861, 6865, 6889, 6891, 6896, 6906, 6909, 6916, 6940, 6990, 6998, 7040, 7041, 7073, 7076, 7077, 7086, 7130, 7135, 7155, 7166, 7172, 7173, 7175, 7180, 7182, 7183, 7209, 7218, 7220, 7229, 7247, 7252, 7261, 7272, 7300, 7317, 7340, 7344, 7360, 7385, 7397, 7403, 7432, 7437, 7448, 7459, 7486, 7490, 7496, 7509, 7528, 7538, 7556, 7558, 7566, 7572, 7574, 7578, 7579, 7585, 7597, 7600, 7604, 7611, 7617, 7626, 7633, 7645, 7675, 7680, 7685, 7706, 7717, 7734, 7749, 7760, 7765, 7767, 7821, 7823, 7828, 7848, 7853, 7860, 7871, 7876, 7893, 7895, 7897, 7899, 7906, 7917, 7944, 7967, 7976, 7996, 8011, 8014, 8020, 8021, 8024, 8025, 8026, 8028, 8046, 8048, 8049, 8051, 8078, 8081, 8085, 8086, 8094, 8104, 8107, 8113, 8117, 8138, 8140, 8147, 8149, 8153, 8157, 8159, 8163, 8179, 8185, 8208, 8209, 8231, 8239, 8250, 8254, 8260, 8262, 8270, 8281, 8291, 8295, 8314, 8323, 8325, 8328, 8337, 8340, 8344, 8349, 8362, 8375, 8382, 8386, 8387, 8391, 8402, 8404, 8411, 8415, 8419, 8435, 8449, 8454, 8458, 8463, 8470, 8476, 8482, 8483, 8487, 8497, 8510, 8512, 8514, 8527, 8535, 8536, 8538, 8561, 8563, 8568, 8588, 8589, 8590, 8605, 8623, 8627, 8630, 8646, 8653, 8691, 8701, 8740, 8761, 8795, 8803, 8816, 8824, 8838, 8839, 8848, 8856, 8877, 8895, 8898, 8903, 8923, 8931, 8940, 8947, 8958, 8960, 8962, 8963, 8981, 8993, 8995, 9006, 9017, 9025, 9038, 9040, 9045, 9063, 9064, 9087, 9100, 9110, 9126, 9127, 9131, 9133, 9140, 9149, 9156, 9159, 9160, 9163, 9174, 9177, 9194, 9197, 9209, 9211, 9237, 9243, 9244, 9245, 9257, 9260, 9272, 9274, 9298, 9308, 9319, 9339, 9341, 9364, 9366, 9377, 9378, 9384, 9385, 9393, 9435, 9437, 9443, 9445, 9447, 9465, 9483, 9491, 9493, 9502, 9511, 9516, 9518, 9532, 9536, 9539, 9547, 9551, 9561, 9596, 9597, 9603, 9605, 9609, 9610, 9614, 9637, 9659, 9667, 9670, 9682, 9687, 9691, 9698, 9704, 9715, 9719, 9722, 9726, 9758, 9772, 9775, 9776, 9787, 9796, 9810, 9815, 9828, 9856, 9892, 9929, 9930, 9941, 9982, 9990, 10005, 10014, 10030, 10037, 10041, 10043, 10049, 10060, 10061, 10087, 10089, 10102, 10108, 10122, 10128, 10153, 10159, 10162, 10173, 10180, 10184, 10198, 10210, 10211, 10230, 10245, 10252, 10258, 10263]
1013 SVs (with labels):
Training time for 7.0-vs-9.0: 553.618048906 seconds
Begin training classifier for label 8.0 and label 9.0 at 2016-05-20, 04:07:05
<type 'numpy.ndarray'> <type 'numpy.ndarray'>
(9885, 784) (9885,)
(9885, 784) (9885,)
     pcost       dcost       gap    pres   dres
 0: -1.2560e+03 -2.2681e+04  1e+05  3e+00  2e-11
 1: -7.8565e+02 -1.3749e+04  3e+04  5e-01  2e-11
 2: -5.0696e+02 -5.5575e+03  9e+03  1e-01  2e-11
 3: -3.5702e+02 -2.6544e+03  4e+03  6e-02  1e-11
 4: -2.7584e+02 -1.5541e+03  2e+03  3e-02  8e-12
 5: -2.1477e+02 -9.5753e+02  1e+03  1e-02  7e-12
 6: -1.8707e+02 -5.7816e+02  6e+02  5e-03  6e-12
 7: -1.8917e+02 -3.3920e+02  2e+02  2e-03  6e-12
 8: -1.9388e+02 -2.5375e+02  7e+01  3e-04  6e-12
 9: -2.0308e+02 -2.2726e+02  3e+01  7e-05  6e-12
10: -2.0463e+02 -2.1933e+02  1e+01  1e-13  7e-12
11: -2.0925e+02 -2.1371e+02  4e+00  4e-13  6e-12
12: -2.1100e+02 -2.1163e+02  6e-01  6e-14  7e-12
13: -2.1128e+02 -2.1131e+02  3e-02  9e-16  7e-12
14: -2.1130e+02 -2.1130e+02  5e-04  3e-13  7e-12
15: -2.1130e+02 -2.1130e+02  6e-06  3e-13  7e-12
Optimal solution found.
sv_indices: [0, 15, 21, 30, 44, 47, 73, 87, 100, 107, 143, 158, 231, 253, 278, 293, 314, 333, 334, 357, 386, 442, 459, 466, 467, 494, 504, 523, 530, 531, 549, 555, 568, 621, 649, 733, 744, 775, 796, 809, 821, 827, 830, 864, 893, 916, 926, 944, 964, 976, 992, 1013, 1021, 1023, 1024, 1052, 1055, 1062, 1080, 1139, 1211, 1228, 1240, 1243, 1314, 1359, 1395, 1410, 1419, 1420, 1425, 1426, 1441, 1443, 1446, 1467, 1471, 1510, 1559, 1561, 1564, 1567, 1570, 1574, 1588, 1626, 1677, 1682, 1779, 1804, 1817, 1874, 1889, 1903, 1923, 1997, 2034, 2048, 2064, 2081, 2123, 2149, 2179, 2188, 2204, 2240, 2242, 2288, 2293, 2329, 2355, 2356, 2400, 2485, 2490, 2511, 2519, 2597, 2605, 2640, 2677, 2703, 2713, 2726, 2729, 2730, 2759, 2762, 2790, 2795, 2798, 2802, 2823, 2844, 2864, 2894, 2913, 2941, 2952, 2959, 2973, 2975, 2981, 3002, 3005, 3030, 3043, 3050, 3097, 3174, 3205, 3214, 3219, 3308, 3320, 3325, 3330, 3352, 3388, 3396, 3414, 3446, 3470, 3504, 3590, 3639, 3658, 3713, 3728, 3733, 3746, 3802, 3816, 3830, 3832, 3835, 3836, 3843, 3845, 3851, 3891, 3904, 3928, 3959, 3976, 3978, 3996, 4007, 4009, 4019, 4059, 4065, 4119, 4145, 4160, 4170, 4198, 4206, 4224, 4230, 4231, 4264, 4282, 4307, 4318, 4333, 4344, 4348, 4399, 4407, 4427, 4443, 4455, 4487, 4499, 4534, 4570, 4595, 4616, 4651, 4660, 4694, 4698, 4699, 4700, 4747, 4750, 4785, 4822, 4835, 4872, 4919, 4924, 4929, 4961, 5008, 5012, 5034, 5110, 5125, 5144, 5172, 5176, 5179, 5213, 5214, 5291, 5293, 5318, 5326, 5330, 5331, 5419, 5421, 5457, 5479, 5545, 5566, 5567, 5582, 5593, 5619, 5627, 5631, 5650, 5751, 5774, 5786, 5810, 5860, 5861, 5863, 5936, 5995, 6006, 6022, 6042, 6103, 6139, 6144, 6195, 6196, 6238, 6276, 6281, 6304, 6321, 6325, 6353, 6436, 6438, 6488, 6506, 6515, 6523, 6551, 6575, 6625, 6639, 6652, 6668, 6685, 6787, 6797, 6806, 6825, 6859, 6908, 6918, 6929, 6938, 6956, 6962, 7014, 7024, 7028, 7048, 7049, 7084, 7164, 7190, 7250, 7254, 7257, 7269, 7274, 7292, 7301, 7368, 7397, 7453, 7467, 7471, 7515, 7529, 7581, 7626, 7662, 7663, 7700, 7706, 7714, 7760, 7779, 7797, 7802, 7819, 7833, 7872, 7877, 7880, 7893, 7928, 7935, 7946, 7998, 8014, 8021, 8059, 8076, 8109, 8119, 8157, 8163, 8171, 8208, 8211, 8252, 8266, 8277, 8300, 8368, 8380, 8382, 8397, 8399, 8416, 8423, 8428, 8485, 8525, 8549, 8564, 8606, 8631, 8637, 8676, 8685, 8717, 8736, 8760, 8771, 8833, 8836, 8837, 8871, 8880, 8932, 8980, 8990, 9035, 9074, 9093, 9114, 9151, 9162, 9173, 9175, 9209, 9213, 9214, 9221, 9294, 9331, 9392, 9408, 9424, 9425, 9429, 9430, 9437, 9447, 9466, 9472, 9488, 9503, 9509, 9551, 9553, 9590, 9592, 9642, 9660, 9697, 9699, 9716, 9739, 9740, 9754, 9796, 9810, 9819, 9827, 9848]
444 SVs (with labels):
Training time for 8.0-vs-9.0: 414.350733042 seconds
Training time:  22402.0374081
Predicting time:  6.43593597412
predicted classes: [7 6 8 ..., 9 3 7]


Classification report for classifier <svm.MultiSVM instance at 0x7f52eb40bc68>:
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97      1988
        1.0       0.96      0.98      0.97      2276
        2.0       0.92      0.93      0.93      2004
        3.0       0.91      0.93      0.92      2084
        4.0       0.93      0.94      0.94      1965
        5.0       0.91      0.89      0.90      1794
        6.0       0.96      0.96      0.96      1945
        7.0       0.95      0.94      0.95      2046
        8.0       0.94      0.90      0.92      1966
        9.0       0.93      0.91      0.92      1932

avg / total       0.94      0.94      0.94     20000


Confusion matrix:
[[1939    1    8    5    2   15   12    1    4    1]
 [   0 2233   10    9    5    3    1    6    8    1]
 [  11   18 1868   21   18   10   18   14   20    6]
 [   9   11   32 1929    1   49    3   11   28   11]
 [   9    4   20    0 1851    3   13   12    4   49]
 [  22    9   12   76   16 1600   19    3   31    6]
 [  12    3   24    1    6   21 1873    0    5    0]
 [   2    7   28   14   18    6    0 1930    5   36]
 [  11   30   23   54   10   36   10    8 1766   18]
 [   9   13    6   16   56   15    0   46   16 1755]]


For training set!


Classification report for classifier <svm.MultiSVM instance at 0x7f52eb40bc68>:
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99      4915
        1.0       0.98      1.00      0.99      5601
        2.0       0.97      0.98      0.97      4986
        3.0       0.96      0.96      0.96      5057
        4.0       0.97      0.98      0.97      4859
        5.0       0.96      0.95      0.96      4519
        6.0       0.99      0.99      0.99      4931
        7.0       0.98      0.97      0.98      5247
        8.0       0.97      0.95      0.96      4859
        9.0       0.97      0.95      0.96      5026

avg / total       0.97      0.97      0.97     50000


Confusion matrix:
[[4897    0    2    0    1    4    4    0    7    0]
 [   1 5581    6    0    0    1    0    1    9    2]
 [  10    9 4866   23   17    3   11   15   31    1]
 [   5    6   68 4835    1   67    1   13   43   18]
 [   2    9   10    0 4764    0    4    3    1   66]
 [  12   14   15   91    6 4313   25    0   38    5]
 [   6    3    7    0    4   27 4882    0    2    0]
 [   3    5   25   11   21    0    1 5109    4   68]
 [  10   29   28   65    5   56   11    6 4640    9]
 [   4   10    5   15   96    8    1   79   19 4789]]

Process finished with exit code 0
